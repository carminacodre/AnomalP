{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment on PFAM dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Preprocessing.ipynb\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import string\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Lambda, Conv1D\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy, mse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import NotebookLoader\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import load_model\n",
    "from tempfile import TemporaryFile\n",
    "import csv\n",
    "import Preprocessing as pre\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../dataset_pfam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../dataset_pfam/HCV(RdRP_3)_203.txt',\n",
       " '../dataset_pfam/TET(_JBP)_645.txt',\n",
       " '../dataset_pfam/NAD(_binding_1)_37979.txt',\n",
       " '../dataset_pfam/RVP_791.txt',\n",
       " '../dataset_pfam/Rub(redoxin)_4692.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(dataset_path + \"/*.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = []\n",
    "conformations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In ../dataset_pfam/HCV(RdRP_3)_203.txt there are 203 conf sequences\n",
      "In ../dataset_pfam/TET(_JBP)_645.txt there are 848 conf sequences\n",
      "In ../dataset_pfam/NAD(_binding_1)_37979.txt there are 38827 conf sequences\n",
      "In ../dataset_pfam/RVP_791.txt there are 39618 conf sequences\n",
      "In ../dataset_pfam/Rub(redoxin)_4692.txt there are 44310 conf sequences\n",
      "44310\n",
      "Counter({'L': 1900655, 'A': 1741473, 'G': 1528121, 'V': 1394313, 'E': 1315518, 'S': 1260737, 'P': 1182150, 'R': 1167869, 'D': 1145802, 'T': 1102951, 'I': 989159, 'K': 954768, 'F': 804154, 'Q': 750081, 'N': 638931, 'Y': 609620, 'H': 505377, 'M': 447121, 'C': 321851, 'W': 261180, 'X': 9658, 'Z': 1, 'O': 1})\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "for fl in glob.glob(dataset_path + \"/*.txt\"):\n",
    "    with open(fl) as f:\n",
    "        current_conf = []\n",
    "        f.readline() # skip first \">\"\n",
    "        for line in f:\n",
    "            if line.startswith(\">\"):\n",
    "                conformations += [current_conf]\n",
    "                lengths += [len(current_conf)]\n",
    "                current_conf = []\n",
    "            else:\n",
    "                current_conf += line.strip()\n",
    "        conformations += [current_conf]\n",
    "        print(\"In %s there are %d conf sequences\" %(fl, len(conformations)) )\n",
    "del current_conf\n",
    "all_letters = []\n",
    "print(len(conformations))\n",
    "for c in conformations:\n",
    "    all_letters +=c\n",
    "cnt = Counter(all_letters)\n",
    "print(cnt)\n",
    "print(len(cnt))\n",
    "del conformations\n",
    "del cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = ['L', 'A', 'G', 'V', 'E', 'S', 'P', 'R', 'D', 'T', 'I', 'K', 'F', 'Q', 'N', 'Y', 'H', 'M', 'C', 'W', 'X', 'Z', 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = sorted(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite this\n",
    "pre.letters_di= dict(zip(letters,range(0, len(letters))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'C': 1,\n",
       " 'D': 2,\n",
       " 'E': 3,\n",
       " 'F': 4,\n",
       " 'G': 5,\n",
       " 'H': 6,\n",
       " 'I': 7,\n",
       " 'K': 8,\n",
       " 'L': 9,\n",
       " 'M': 10,\n",
       " 'N': 11,\n",
       " 'O': 12,\n",
       " 'P': 13,\n",
       " 'Q': 14,\n",
       " 'R': 15,\n",
       " 'S': 16,\n",
       " 'T': 17,\n",
       " 'V': 18,\n",
       " 'W': 19,\n",
       " 'X': 20,\n",
       " 'Y': 21,\n",
       " 'Z': 22}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.letters_di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "num_bins = 1000\n",
    "n, bins, patches = plt.hist(lengths, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = True\n",
    "num_classes = 23\n",
    "categorical = True\n",
    "use_angles = False\n",
    "max_length = 2000\n",
    "flatten = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_set(nr):\n",
    "    train = []\n",
    "    validation = []\n",
    "    test= []\n",
    "    for i, fl in enumerate(glob.glob(dataset_path + \"/*.txt\")[:2]):\n",
    "        with open(fl) as f:\n",
    "            conformations = []\n",
    "            current_conf = []\n",
    "            f.readline() # skip first \">\"\n",
    "            for line in f:\n",
    "                if line.startswith(\">\"):\n",
    "                    conformations += [current_conf[:max_length]]\n",
    "                    current_conf = []\n",
    "                else:\n",
    "                    current_conf += line.strip()\n",
    "            conformations += [current_conf[:max_length]]\n",
    "            # decide set\n",
    "            if i == nr:\n",
    "                test = conformations\n",
    "                print(\"%d added to test from %s\" % (len(test), fl))\n",
    "            else:\n",
    "                # split val train 90 - 10\n",
    "                train_f, val_f = train_test_split(conformations, test_size=0.1, random_state=42)\n",
    "                print(\"%d added to train from %s\" % (len(train_f), fl))\n",
    "                print(\"%d added to validation from %s\" % (len(val_f), fl))\n",
    "                train += train_f\n",
    "                validation += val_f\n",
    "                del train_f\n",
    "                del val_f\n",
    "            del conformations\n",
    "    random.shuffle(train)\n",
    "    random.shuffle(validation)\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "intermediate_dim = 25\n",
    "epochs = 20\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkpoints(nr):\n",
    "    checkpoints_path = \"models\"\n",
    "    cp_cb = ModelCheckpoint(filepath=os.path.join(checkpoints_path, \"model\" + str(nr) + \".hdf5\"), monitor='val_loss',\n",
    "                            save_best_only=True)\n",
    "    return [cp_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder\n",
    "def get_ae():\n",
    "    if categorical:\n",
    "        if not flatten:\n",
    "            model_input = Input(shape=(None,num_classes))\n",
    "        else:\n",
    "            model_input = Input(shape=(max_length*num_classes,))\n",
    "    elif use_angles:\n",
    "        model_input = Input(shape=(max_length*3,))\n",
    "    else:\n",
    "        model_input = Input(shape=(max_length,))\n",
    "    #x=Conv1D(intermediate_dim, activation='sigmoid', kernel_size=3, padding='same', dilation_rate=1)(model_input)\n",
    "    #encoded=Conv1D(intermediate_dim, activation='sigmoid', kernel_size=3, padding='same', dilation_rate=1, name=\"encoded\")(x)\n",
    "    #x=Conv1D(num_classes, activation='sigmoid', kernel_size=3, padding='same', dilation_rate=1)(encoded)\n",
    "    encoded= Dense(intermediate_dim, activation='sigmoid')(model_input)\n",
    "    if categorical:\n",
    "        if not flatten:\n",
    "            x = Dense(num_classes, activation='sigmoid')(encoded)\n",
    "        else:\n",
    "            x = Dense(max_length*num_classes, activation='sigmoid')(encoded)\n",
    "    elif use_angles:\n",
    "        x = Dense(max_length*3, activation='sigmoid')(encoded)\n",
    "    else:\n",
    "        x = Dense(max_length, activation='sigmoid')(encoded)\n",
    "    ae=Model(inputs=model_input, outputs=[x])\n",
    "    opt=RMSprop(lr=learning_rate)\n",
    "    ae.compile(optimizer=opt, loss='binary_crossentropy', metrics=['mean_absolute_error'])\n",
    "    ae.summary()\n",
    "    return ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 0\n",
      "203 added to test from ../dataset_pfam/HCV(RdRP_3)_203.txt\n",
      "580 added to train from ../dataset_pfam/TET(_JBP)_645.txt\n",
      "65 added to validation from ../dataset_pfam/TET(_JBP)_645.txt\n",
      "(580, 2000, 23)\n",
      "(580, 46000)\n",
      "(65, 2000, 23)\n",
      "(65, 46000)\n",
      "Train set(580, 46000)\n",
      "Validation set(65, 46000)\n",
      "WARNING:tensorflow:From /Users/carminacodre/.virtualenvs/dizy/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 46000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                1150025   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46000)             1196000   \n",
      "=================================================================\n",
      "Total params: 2,346,025\n",
      "Trainable params: 2,346,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/carminacodre/.virtualenvs/dizy/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 580 samples, validate on 65 samples\n",
      "Epoch 1/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.3884 - mean_absolute_error: 0.3050 - val_loss: 0.2052 - val_mean_absolute_error: 0.1616\n",
      "Epoch 2/20\n",
      "580/580 [==============================] - 1s 3ms/step - loss: 0.1772 - mean_absolute_error: 0.1320 - val_loss: 0.1526 - val_mean_absolute_error: 0.1014\n",
      "Epoch 3/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1437 - mean_absolute_error: 0.0904 - val_loss: 0.1371 - val_mean_absolute_error: 0.0783\n",
      "Epoch 4/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1327 - mean_absolute_error: 0.0733 - val_loss: 0.1316 - val_mean_absolute_error: 0.0681\n",
      "Epoch 5/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1284 - mean_absolute_error: 0.0654 - val_loss: 0.1294 - val_mean_absolute_error: 0.0619\n",
      "Epoch 6/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1264 - mean_absolute_error: 0.0608 - val_loss: 0.1285 - val_mean_absolute_error: 0.0594\n",
      "Epoch 7/20\n",
      "580/580 [==============================] - 1s 3ms/step - loss: 0.1255 - mean_absolute_error: 0.0588 - val_loss: 0.1283 - val_mean_absolute_error: 0.0586\n",
      "Epoch 8/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1251 - mean_absolute_error: 0.0583 - val_loss: 0.1283 - val_mean_absolute_error: 0.0583\n",
      "Epoch 9/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1249 - mean_absolute_error: 0.0578 - val_loss: 0.1278 - val_mean_absolute_error: 0.0567\n",
      "Epoch 10/20\n",
      "580/580 [==============================] - 1s 3ms/step - loss: 0.1247 - mean_absolute_error: 0.0569 - val_loss: 0.1279 - val_mean_absolute_error: 0.0568\n",
      "Epoch 11/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1246 - mean_absolute_error: 0.0568 - val_loss: 0.1280 - val_mean_absolute_error: 0.0566\n",
      "Epoch 12/20\n",
      "580/580 [==============================] - 1s 3ms/step - loss: 0.1245 - mean_absolute_error: 0.0567 - val_loss: 0.1278 - val_mean_absolute_error: 0.0560\n",
      "Epoch 13/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1245 - mean_absolute_error: 0.0564 - val_loss: 0.1278 - val_mean_absolute_error: 0.0556\n",
      "Epoch 14/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1245 - mean_absolute_error: 0.0562 - val_loss: 0.1279 - val_mean_absolute_error: 0.0567\n",
      "Epoch 15/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1245 - mean_absolute_error: 0.0569 - val_loss: 0.1279 - val_mean_absolute_error: 0.0563\n",
      "Epoch 16/20\n",
      "580/580 [==============================] - 1s 3ms/step - loss: 0.1245 - mean_absolute_error: 0.0565 - val_loss: 0.1276 - val_mean_absolute_error: 0.0566\n",
      "Epoch 17/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1245 - mean_absolute_error: 0.0567 - val_loss: 0.1277 - val_mean_absolute_error: 0.0564\n",
      "Epoch 18/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1244 - mean_absolute_error: 0.0567 - val_loss: 0.1279 - val_mean_absolute_error: 0.0563\n",
      "Epoch 19/20\n",
      "580/580 [==============================] - 1s 3ms/step - loss: 0.1244 - mean_absolute_error: 0.0566 - val_loss: 0.1277 - val_mean_absolute_error: 0.0554\n",
      "Epoch 20/20\n",
      "580/580 [==============================] - 2s 3ms/step - loss: 0.1244 - mean_absolute_error: 0.0560 - val_loss: 0.1278 - val_mean_absolute_error: 0.0552\n",
      "Evaluation 0\n",
      "(203, 2000, 23)\n",
      "(203, 46000)\n",
      "Result for 0\n",
      "True negatives:     8\n",
      "Total:              203\n",
      "True negative rate: 0.039409\n",
      "Training 1\n",
      "182 added to train from ../dataset_pfam/HCV(RdRP_3)_203.txt\n",
      "21 added to validation from ../dataset_pfam/HCV(RdRP_3)_203.txt\n",
      "645 added to test from ../dataset_pfam/TET(_JBP)_645.txt\n",
      "(182, 2000, 23)\n",
      "(182, 46000)\n",
      "(21, 2000, 23)\n",
      "(21, 46000)\n",
      "Train set(182, 46000)\n",
      "Validation set(21, 46000)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 46000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                1150025   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46000)             1196000   \n",
      "=================================================================\n",
      "Total params: 2,346,025\n",
      "Trainable params: 2,346,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 182 samples, validate on 21 samples\n",
      "Epoch 1/20\n",
      "182/182 [==============================] - 1s 5ms/step - loss: 0.5982 - mean_absolute_error: 0.4472 - val_loss: 0.3630 - val_mean_absolute_error: 0.3013\n",
      "Epoch 2/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.3149 - mean_absolute_error: 0.2652 - val_loss: 0.2404 - val_mean_absolute_error: 0.2059\n",
      "Epoch 3/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.2195 - mean_absolute_error: 0.1885 - val_loss: 0.1855 - val_mean_absolute_error: 0.1577\n",
      "Epoch 4/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.1729 - mean_absolute_error: 0.1468 - val_loss: 0.1536 - val_mean_absolute_error: 0.1275\n",
      "Epoch 5/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.1446 - mean_absolute_error: 0.1198 - val_loss: 0.1327 - val_mean_absolute_error: 0.1067\n",
      "Epoch 6/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.1256 - mean_absolute_error: 0.1008 - val_loss: 0.1181 - val_mean_absolute_error: 0.0914\n",
      "Epoch 7/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.1121 - mean_absolute_error: 0.0867 - val_loss: 0.1074 - val_mean_absolute_error: 0.0797\n",
      "Epoch 8/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.1021 - mean_absolute_error: 0.0760 - val_loss: 0.0994 - val_mean_absolute_error: 0.0707\n",
      "Epoch 9/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.0945 - mean_absolute_error: 0.0675 - val_loss: 0.0932 - val_mean_absolute_error: 0.0635\n",
      "Epoch 10/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.0886 - mean_absolute_error: 0.0607 - val_loss: 0.0884 - val_mean_absolute_error: 0.0577\n",
      "Epoch 11/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.0553 - val_loss: 0.0846 - val_mean_absolute_error: 0.0530\n",
      "Epoch 12/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.0802 - mean_absolute_error: 0.0508 - val_loss: 0.0816 - val_mean_absolute_error: 0.0491\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 0s 3ms/step - loss: 0.0772 - mean_absolute_error: 0.0472 - val_loss: 0.0792 - val_mean_absolute_error: 0.0459\n",
      "Epoch 14/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.0748 - mean_absolute_error: 0.0442 - val_loss: 0.0772 - val_mean_absolute_error: 0.0433\n",
      "Epoch 15/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.0728 - mean_absolute_error: 0.0417 - val_loss: 0.0757 - val_mean_absolute_error: 0.0411\n",
      "Epoch 16/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.0711 - mean_absolute_error: 0.0397 - val_loss: 0.0744 - val_mean_absolute_error: 0.0392\n",
      "Epoch 17/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.0698 - mean_absolute_error: 0.0379 - val_loss: 0.0733 - val_mean_absolute_error: 0.0377\n",
      "Epoch 18/20\n",
      "182/182 [==============================] - 0s 3ms/step - loss: 0.0687 - mean_absolute_error: 0.0364 - val_loss: 0.0724 - val_mean_absolute_error: 0.0364\n",
      "Epoch 19/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.0677 - mean_absolute_error: 0.0351 - val_loss: 0.0717 - val_mean_absolute_error: 0.0353\n",
      "Epoch 20/20\n",
      "182/182 [==============================] - 1s 3ms/step - loss: 0.0669 - mean_absolute_error: 0.0342 - val_loss: 0.0711 - val_mean_absolute_error: 0.0344\n",
      "Evaluation 1\n",
      "(645, 2000, 23)\n",
      "(645, 46000)\n",
      "Result for 1\n",
      "True negatives:     187\n",
      "Total:              645\n",
      "True negative rate: 0.289922\n",
      "Training 2\n",
      "182 added to train from ../dataset_pfam/HCV(RdRP_3)_203.txt\n",
      "21 added to validation from ../dataset_pfam/HCV(RdRP_3)_203.txt\n",
      "580 added to train from ../dataset_pfam/TET(_JBP)_645.txt\n",
      "65 added to validation from ../dataset_pfam/TET(_JBP)_645.txt\n",
      "(762, 2000, 23)\n",
      "(762, 46000)\n",
      "(86, 2000, 23)\n",
      "(86, 46000)\n",
      "Train set(762, 46000)\n",
      "Validation set(86, 46000)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 46000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                1150025   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 46000)             1196000   \n",
      "=================================================================\n",
      "Total params: 2,346,025\n",
      "Trainable params: 2,346,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 762 samples, validate on 86 samples\n",
      "Epoch 1/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.3410 - mean_absolute_error: 0.2692 - val_loss: 0.1800 - val_mean_absolute_error: 0.1400\n",
      "Epoch 2/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1529 - mean_absolute_error: 0.1099 - val_loss: 0.1341 - val_mean_absolute_error: 0.0856\n",
      "Epoch 3/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1258 - mean_absolute_error: 0.0748 - val_loss: 0.1215 - val_mean_absolute_error: 0.0656\n",
      "Epoch 4/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1176 - mean_absolute_error: 0.0611 - val_loss: 0.1174 - val_mean_absolute_error: 0.0570\n",
      "Epoch 5/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1147 - mean_absolute_error: 0.0550 - val_loss: 0.1161 - val_mean_absolute_error: 0.0536\n",
      "Epoch 6/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1136 - mean_absolute_error: 0.0524 - val_loss: 0.1156 - val_mean_absolute_error: 0.0524\n",
      "Epoch 7/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1131 - mean_absolute_error: 0.0516 - val_loss: 0.1154 - val_mean_absolute_error: 0.0515\n",
      "Epoch 8/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1129 - mean_absolute_error: 0.0510 - val_loss: 0.1153 - val_mean_absolute_error: 0.0511\n",
      "Epoch 9/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1128 - mean_absolute_error: 0.0508 - val_loss: 0.1153 - val_mean_absolute_error: 0.0508\n",
      "Epoch 10/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1127 - mean_absolute_error: 0.0506 - val_loss: 0.1151 - val_mean_absolute_error: 0.0508\n",
      "Epoch 11/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1126 - mean_absolute_error: 0.0504 - val_loss: 0.1152 - val_mean_absolute_error: 0.0510\n",
      "Epoch 12/20\n",
      "762/762 [==============================] - 2s 2ms/step - loss: 0.1126 - mean_absolute_error: 0.0508 - val_loss: 0.1151 - val_mean_absolute_error: 0.0504\n",
      "Epoch 13/20\n",
      "762/762 [==============================] - 2s 2ms/step - loss: 0.1126 - mean_absolute_error: 0.0502 - val_loss: 0.1152 - val_mean_absolute_error: 0.0508\n",
      "Epoch 14/20\n",
      "762/762 [==============================] - 2s 2ms/step - loss: 0.1126 - mean_absolute_error: 0.0504 - val_loss: 0.1152 - val_mean_absolute_error: 0.0509\n",
      "Epoch 15/20\n",
      "762/762 [==============================] - 2s 2ms/step - loss: 0.1125 - mean_absolute_error: 0.0503 - val_loss: 0.1151 - val_mean_absolute_error: 0.0511\n",
      "Epoch 16/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1126 - mean_absolute_error: 0.0505 - val_loss: 0.1151 - val_mean_absolute_error: 0.0511\n",
      "Epoch 17/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1126 - mean_absolute_error: 0.0505 - val_loss: 0.1151 - val_mean_absolute_error: 0.0508\n",
      "Epoch 18/20\n",
      "762/762 [==============================] - 2s 3ms/step - loss: 0.1125 - mean_absolute_error: 0.0503 - val_loss: 0.1151 - val_mean_absolute_error: 0.0509\n",
      "Epoch 19/20\n",
      "762/762 [==============================] - 2s 2ms/step - loss: 0.1125 - mean_absolute_error: 0.0506 - val_loss: 0.1151 - val_mean_absolute_error: 0.0505\n",
      "Epoch 20/20\n",
      "762/762 [==============================] - 2s 2ms/step - loss: 0.1125 - mean_absolute_error: 0.0503 - val_loss: 0.1151 - val_mean_absolute_error: 0.0507\n",
      "Evaluation 2\n",
      "(0, 2000, 23)\n",
      "(0, 46000)\n",
      "Result for 2\n",
      "True negatives:     0\n",
      "Total:              0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-73f3096830e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True negatives:     %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total:              %d\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"True negative rate: %f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "for idx in range(0,5):\n",
    "    print(\"Training %d\" %idx)\n",
    "    train, validation, test = read_set(idx)\n",
    "    train = pre.process_conf(train, categorical=categorical, use_angles=use_angles, padding=padding, max_length=max_length, flatten=flatten, num_classes=num_classes)  \n",
    "    validation = pre.process_conf(validation, categorical=categorical, use_angles=use_angles, padding=padding, max_length=max_length, flatten=flatten, num_classes=num_classes)\n",
    "    print(\"Train set\" + repr(train.shape))\n",
    "    print(\"Validation set\" + repr(validation.shape))\n",
    "    ae = get_ae()\n",
    "    ae.fit(train, train,\n",
    "           shuffle=True,\n",
    "           epochs=epochs,\n",
    "           batch_size=batch_size,\n",
    "           validation_data=(validation, validation),\n",
    "           callbacks=create_checkpoints(idx),\n",
    "           verbose=1)\n",
    "    del validation\n",
    "    \n",
    "    print(\"Evaluation %d\" %idx)\n",
    "    \n",
    "    ae = load_model(os.path.join(\"models\", \"model\" + str(idx) + \".hdf5\"))\n",
    "    losses_train = []\n",
    "    for t in train:\n",
    "        losses_train.append(ae.evaluate(np.array([t]),np.array([t]), verbose=0)[0])\n",
    "    max_l = max(losses_train)\n",
    "    del train\n",
    "    del losses_train\n",
    "    tn = 0\n",
    "    total = len(test)\n",
    "    test = pre.process_conf(test, categorical=categorical, use_angles=use_angles, padding=padding, max_length=max_length, flatten=flatten, num_classes=num_classes)  \n",
    "    for t in test:\n",
    "        loss=ae.evaluate(np.array([t]),np.array([t]), verbose=0)[0]\n",
    "        if loss > max_l:\n",
    "            tn+=1\n",
    "    del test\n",
    "    print(\"Result for %d\" %idx)\n",
    "    print(\"True negatives:     %d\" %tn)\n",
    "    print(\"Total:              %d\" %total)\n",
    "    print(\"True negative rate: %f\" %(tn*1.0/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dizy",
   "language": "python",
   "name": "dizy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
