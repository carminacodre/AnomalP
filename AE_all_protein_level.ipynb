{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE on proteins in SA representation - protein level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import string\n",
    "from keras import Input\n",
    "from keras.layers import Dense, Lambda, Conv1D\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.objectives import binary_crossentropy, mse\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import NotebookLoader\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.models import load_model\n",
    "from tempfile import TemporaryFile\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Preprocessing.ipynb\n"
     ]
    }
   ],
   "source": [
    "import Preprocessing as pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins for family fam_1\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "Proteins for family fam_2\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "Proteins for family fam_3\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "Proteins for family fam_4\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "Proteins for family fam_5\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "Proteins for family fam_6\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "Proteins for family fam_7\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "Proteins for family fam_8\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "Proteins for family fam_9\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n"
     ]
    }
   ],
   "source": [
    "lengths = {}\n",
    "for f in pre.families:\n",
    "    proteins = glob.glob(os.path.join(pre.family_paths[f], \"*.out\"))\n",
    "    print(\"Proteins for family %s\" %f)\n",
    "    for p in proteins:\n",
    "        print(p)\n",
    "    lengths[f] = len(p)\n",
    "total = sum([lengths[f] for f in pre.families])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = True\n",
    "num_classes = 25\n",
    "categorical = False\n",
    "use_angles = True\n",
    "max_length = 668\n",
    "flatten = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "intermediate_dim = 25\n",
    "epochs = 20\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_checkpoints(f):\n",
    "    checkpoints_path = os.path.join(\"models_proteins\", f)\n",
    "    tensorboard_path = os.path.join(\"logs\", f)\n",
    "    cp_cb = ModelCheckpoint(filepath=os.path.join(checkpoints_path, \"model_protein_level_\" + f + \".hdf5\"), monitor='val_loss',\n",
    "                            save_best_only=True)\n",
    "    tb_cb = TensorBoard(log_dir=tensorboard_path)\n",
    "    return [cp_cb, tb_cb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder\n",
    "def get_ae():\n",
    "    if categorical:\n",
    "        if not flatten:\n",
    "            model_input = Input(shape=(None,num_classes))\n",
    "        else:\n",
    "            model_input = Input(shape=(max_length*num_classes,))\n",
    "    elif use_angles:\n",
    "        model_input = Input(shape=(max_length*3,))\n",
    "    else:\n",
    "        model_input = Input(shape=(max_length,))\n",
    "    #x=Conv1D(intermediate_dim, activation='sigmoid', kernel_size=3, padding='same', dilation_rate=1)(model_input)\n",
    "    #encoded=Conv1D(intermediate_dim, activation='sigmoid', kernel_size=3, padding='same', dilation_rate=1, name=\"encoded\")(x)\n",
    "    #x=Conv1D(num_classes, activation='sigmoid', kernel_size=3, padding='same', dilation_rate=1)(encoded)\n",
    "    encoded= Dense(intermediate_dim, activation='sigmoid')(model_input)\n",
    "    if categorical:\n",
    "        if not flatten:\n",
    "            x = Dense(num_classes, activation='sigmoid')(encoded)\n",
    "        else:\n",
    "            x = Dense(max_length*num_classes, activation='sigmoid')(encoded)\n",
    "    elif use_angles:\n",
    "        x = Dense(max_length*3, activation='sigmoid')(encoded)\n",
    "    else:\n",
    "        x = Dense(max_length, activation='sigmoid')(encoded)\n",
    "    ae=Model(inputs=model_input, outputs=[x])\n",
    "    opt=RMSprop(lr=learning_rate)\n",
    "    ae.compile(optimizer=opt, loss='binary_crossentropy', metrics=['mean_absolute_error'])\n",
    "    ae.summary()\n",
    "    return ae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the autoencoder for specific classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"fam_1\": \"models_proteins/fam_1/model_protein_level_fam_1.hdf5\",\n",
    "          \"fam_2\": \"models_proteins/fam_2/model_protein_level_fam_2.hdf5\",\n",
    "          \"fam_3\": \"models_proteins/fam_3/model_protein_level_fam_3.hdf5\",\n",
    "          \"fam_4\": \"models_proteins/fam_4/model_protein_level_fam_4.hdf5\",\n",
    "          \"fam_5\": \"models_proteins/fam_5/model_protein_level_fam_5.hdf5\",\n",
    "          \"fam_6\": \"models_proteins/fam_6/model_protein_level_fam_6.hdf5\",\n",
    "          \"fam_7\": \"models_proteins/fam_7/model_protein_level_fam_7.hdf5\",\n",
    "          \"fam_8\": \"models_proteins/fam_8/model_protein_level_fam_8.hdf5\",\n",
    "          \"fam_9\": \"models_proteins/fam_9/model_protein_level_fam_9.hdf5\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/tmp/data_serialized_proteins_prot'\n",
    "# for r in range(1, 10):\n",
    "#     os.makedirs(os.path.join(path, 'fam_%d' % r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_set_for_family(f, set_type):\n",
    "    ds_path = os.path.join(path, f, set_type)\n",
    "    files = glob.glob(os.path.join(ds_path, \"*.npy\"))\n",
    "    new = np.load(files[0])\n",
    "    for f in files[1:]:\n",
    "        conf_f = np.load(f)\n",
    "        new = np.concatenate([new,conf_f])\n",
    "        del conf_f\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_for_fam(f):\n",
    "    print(\"Test for autoencoder on fam %s\" %f)\n",
    "    train = read_set_for_family(f,\"train\")\n",
    "    ae = load_model(models[f])\n",
    "    ae.summary()\n",
    "    losses_train = []\n",
    "    for t in train:\n",
    "        losses_train.append(ae.evaluate(np.array([t]),np.array([t]), verbose=0)[1])\n",
    "    max_l = max(losses_train)\n",
    "    print(\"Max loss is %f\" %max_l)\n",
    "    losses_test = []\n",
    "    del train\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    tp_p, tn_p, fp_p, fn_p = 0, 0, 0, 0\n",
    "    for ft in pre.families:\n",
    "        print(\"Test for fam %s\" %ft)\n",
    "        ds_path = os.path.join(path, ft, \"test\")\n",
    "        files = glob.glob(os.path.join(ds_path, \"*.npy\"))\n",
    "        for file in files:\n",
    "            test = np.load(file)\n",
    "            total_nr = test.shape[0]\n",
    "            total_loss = 0.0\n",
    "            gt = 0\n",
    "            ls = 0\n",
    "            # check for each configuration the losses\n",
    "            for t in test:\n",
    "                loss=ae.evaluate(np.array([t]),np.array([t]), verbose=0)[1]\n",
    "                total_loss +=loss\n",
    "                if loss > max_l:\n",
    "                    gt+=1\n",
    "                else:\n",
    "                    ls+=1\n",
    "            if gt >= ls:\n",
    "                # predict other family\n",
    "                if ft == f:\n",
    "                    fn+=1\n",
    "                else:\n",
    "                    tn+=1\n",
    "            else:\n",
    "                # predict current family\n",
    "                if ft == f:\n",
    "                    tp+=1 \n",
    "                else:\n",
    "                    fp+=1\n",
    "            # compute the probability\n",
    "            total_loss /= total_nr\n",
    "            if total_loss > max_l:\n",
    "                pr = 1 - max_l / (2 * total_loss)\n",
    "            else:\n",
    "                pr = total_loss / (2 * max_l)\n",
    "            if pr >= 0.5:\n",
    "                # predict other family\n",
    "                if ft == f:\n",
    "                    fn_p+=1\n",
    "                else:\n",
    "                    tn_p+=1\n",
    "            else:\n",
    "                # predict current family\n",
    "                if ft == f:\n",
    "                    tp_p+=1 \n",
    "                else:\n",
    "                    fp_p+=1                 \n",
    "    return [tp, tn, fp, fn], [tp_p, tn_p, fp_p, fn_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "WARNING:tensorflow:From /Users/carminacodre/.virtualenvs/dizy/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/carminacodre/.virtualenvs/dizy/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.4194 - mean_absolute_error: 0.1526 - val_loss: 0.4079 - val_mean_absolute_error: 0.1414\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 5s 99us/step - loss: 0.4028 - mean_absolute_error: 0.1383 - val_loss: 0.3899 - val_mean_absolute_error: 0.1286\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 5s 101us/step - loss: 0.3725 - mean_absolute_error: 0.1183 - val_loss: 0.3536 - val_mean_absolute_error: 0.1059\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 5s 101us/step - loss: 0.3412 - mean_absolute_error: 0.0955 - val_loss: 0.3301 - val_mean_absolute_error: 0.0850\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 5s 102us/step - loss: 0.3186 - mean_absolute_error: 0.0730 - val_loss: 0.3101 - val_mean_absolute_error: 0.0635\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 5s 101us/step - loss: 0.3057 - mean_absolute_error: 0.0589 - val_loss: 0.3020 - val_mean_absolute_error: 0.0546\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.2997 - mean_absolute_error: 0.0520 - val_loss: 0.2976 - val_mean_absolute_error: 0.0493\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 108us/step - loss: 0.2964 - mean_absolute_error: 0.0476 - val_loss: 0.2956 - val_mean_absolute_error: 0.0464\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2944 - mean_absolute_error: 0.0448 - val_loss: 0.2935 - val_mean_absolute_error: 0.0438\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2931 - mean_absolute_error: 0.0429 - val_loss: 0.2925 - val_mean_absolute_error: 0.0420\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 6s 109us/step - loss: 0.2923 - mean_absolute_error: 0.0417 - val_loss: 0.2919 - val_mean_absolute_error: 0.0412\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 6s 102us/step - loss: 0.2916 - mean_absolute_error: 0.0408 - val_loss: 0.2910 - val_mean_absolute_error: 0.0401\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 6s 109us/step - loss: 0.2911 - mean_absolute_error: 0.0402 - val_loss: 0.2905 - val_mean_absolute_error: 0.0394\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 5s 101us/step - loss: 0.2907 - mean_absolute_error: 0.0398 - val_loss: 0.2901 - val_mean_absolute_error: 0.0390\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 5s 101us/step - loss: 0.2904 - mean_absolute_error: 0.0394 - val_loss: 0.2909 - val_mean_absolute_error: 0.0400\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 5s 100us/step - loss: 0.2900 - mean_absolute_error: 0.0392 - val_loss: 0.2893 - val_mean_absolute_error: 0.0385\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 5s 100us/step - loss: 0.2898 - mean_absolute_error: 0.0390 - val_loss: 0.2891 - val_mean_absolute_error: 0.0381\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 6s 104us/step - loss: 0.2896 - mean_absolute_error: 0.0388 - val_loss: 0.2893 - val_mean_absolute_error: 0.0386\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.2894 - mean_absolute_error: 0.0386 - val_loss: 0.2888 - val_mean_absolute_error: 0.0379\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 6s 104us/step - loss: 0.2892 - mean_absolute_error: 0.0384 - val_loss: 0.2887 - val_mean_absolute_error: 0.0377\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.2187 - mean_absolute_error: 0.0752 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0506\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0529\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0533\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0505\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0526\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0532\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s 107us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0529\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0507\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.2182 - mean_absolute_error: 0.0953 - val_loss: 0.1805 - val_mean_absolute_error: 0.0622\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0620\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0630\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 100us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0620\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 97us/step - loss: 0.1763 - mean_absolute_error: 0.0593 - val_loss: 0.1713 - val_mean_absolute_error: 0.0562\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 3s 97us/step - loss: 0.1672 - mean_absolute_error: 0.0527 - val_loss: 0.1633 - val_mean_absolute_error: 0.0497\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 3s 97us/step - loss: 0.1603 - mean_absolute_error: 0.0470 - val_loss: 0.1575 - val_mean_absolute_error: 0.0447\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 3s 97us/step - loss: 0.1553 - mean_absolute_error: 0.0426 - val_loss: 0.1533 - val_mean_absolute_error: 0.0406\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1518 - mean_absolute_error: 0.0389 - val_loss: 0.1503 - val_mean_absolute_error: 0.0375\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1493 - mean_absolute_error: 0.0364 - val_loss: 0.1483 - val_mean_absolute_error: 0.0354\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1476 - mean_absolute_error: 0.0348 - val_loss: 0.1471 - val_mean_absolute_error: 0.0349\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1464 - mean_absolute_error: 0.0338 - val_loss: 0.1460 - val_mean_absolute_error: 0.0336\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 3s 97us/step - loss: 0.1456 - mean_absolute_error: 0.0331 - val_loss: 0.1453 - val_mean_absolute_error: 0.0328\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1451 - mean_absolute_error: 0.0325 - val_loss: 0.1448 - val_mean_absolute_error: 0.0324\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1446 - mean_absolute_error: 0.0321 - val_loss: 0.1445 - val_mean_absolute_error: 0.0322\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 97us/step - loss: 0.1442 - mean_absolute_error: 0.0317 - val_loss: 0.1441 - val_mean_absolute_error: 0.0314\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1439 - mean_absolute_error: 0.0313 - val_loss: 0.1437 - val_mean_absolute_error: 0.0312\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1437 - mean_absolute_error: 0.0311 - val_loss: 0.1435 - val_mean_absolute_error: 0.0306\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1434 - mean_absolute_error: 0.0308 - val_loss: 0.1432 - val_mean_absolute_error: 0.0306\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1432 - mean_absolute_error: 0.0306 - val_loss: 0.1432 - val_mean_absolute_error: 0.0306\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1952 - mean_absolute_error: 0.0892 - val_loss: 0.1301 - val_mean_absolute_error: 0.0270\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1254 - mean_absolute_error: 0.0223 - val_loss: 0.1227 - val_mean_absolute_error: 0.0191\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 97us/step - loss: 0.1213 - mean_absolute_error: 0.0175 - val_loss: 0.1202 - val_mean_absolute_error: 0.0162\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1196 - mean_absolute_error: 0.0154 - val_loss: 0.1191 - val_mean_absolute_error: 0.0148\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 100us/step - loss: 0.1188 - mean_absolute_error: 0.0144 - val_loss: 0.1185 - val_mean_absolute_error: 0.0142\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1183 - mean_absolute_error: 0.0140 - val_loss: 0.1181 - val_mean_absolute_error: 0.0138\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1179 - mean_absolute_error: 0.0137 - val_loss: 0.1177 - val_mean_absolute_error: 0.0135\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1174 - mean_absolute_error: 0.0134 - val_loss: 0.1170 - val_mean_absolute_error: 0.0131\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1165 - mean_absolute_error: 0.0125 - val_loss: 0.1161 - val_mean_absolute_error: 0.0120\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1157 - mean_absolute_error: 0.0114 - val_loss: 0.1153 - val_mean_absolute_error: 0.0109\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1151 - mean_absolute_error: 0.0106 - val_loss: 0.1149 - val_mean_absolute_error: 0.0104\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1147 - mean_absolute_error: 0.0099 - val_loss: 0.1146 - val_mean_absolute_error: 0.0096\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1145 - mean_absolute_error: 0.0095 - val_loss: 0.1145 - val_mean_absolute_error: 0.0103\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1144 - mean_absolute_error: 0.0093 - val_loss: 0.1143 - val_mean_absolute_error: 0.0091\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1143 - mean_absolute_error: 0.0091 - val_loss: 0.1142 - val_mean_absolute_error: 0.0090\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1142 - mean_absolute_error: 0.0090 - val_loss: 0.1142 - val_mean_absolute_error: 0.0090\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1141 - mean_absolute_error: 0.0088 - val_loss: 0.1141 - val_mean_absolute_error: 0.0088\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1141 - mean_absolute_error: 0.0087 - val_loss: 0.1141 - val_mean_absolute_error: 0.0087\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 98us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.3266 - mean_absolute_error: 0.1270 - val_loss: 0.2503 - val_mean_absolute_error: 0.0470\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.2409 - mean_absolute_error: 0.0330 - val_loss: 0.2356 - val_mean_absolute_error: 0.0252\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2336 - mean_absolute_error: 0.0224 - val_loss: 0.2319 - val_mean_absolute_error: 0.0204\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2303 - mean_absolute_error: 0.0186 - val_loss: 0.2288 - val_mean_absolute_error: 0.0168\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2278 - mean_absolute_error: 0.0156 - val_loss: 0.2270 - val_mean_absolute_error: 0.0146\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2266 - mean_absolute_error: 0.0141 - val_loss: 0.2263 - val_mean_absolute_error: 0.0136\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2261 - mean_absolute_error: 0.0134 - val_loss: 0.2259 - val_mean_absolute_error: 0.0131\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2259 - mean_absolute_error: 0.0133 - val_loss: 0.2258 - val_mean_absolute_error: 0.0132\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 0.2257 - mean_absolute_error: 0.0130 - val_loss: 0.2255 - val_mean_absolute_error: 0.0128\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2255 - mean_absolute_error: 0.0127 - val_loss: 0.2254 - val_mean_absolute_error: 0.0127\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2254 - mean_absolute_error: 0.0127 - val_loss: 0.2253 - val_mean_absolute_error: 0.0126\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 0.2253 - mean_absolute_error: 0.0128 - val_loss: 0.2253 - val_mean_absolute_error: 0.0136\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2252 - mean_absolute_error: 0.0128 - val_loss: 0.2250 - val_mean_absolute_error: 0.0125\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2251 - mean_absolute_error: 0.0126 - val_loss: 0.2250 - val_mean_absolute_error: 0.0123\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2250 - mean_absolute_error: 0.0123 - val_loss: 0.2252 - val_mean_absolute_error: 0.0135\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2249 - mean_absolute_error: 0.0122 - val_loss: 0.2248 - val_mean_absolute_error: 0.0122\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2249 - mean_absolute_error: 0.0121 - val_loss: 0.2248 - val_mean_absolute_error: 0.0120\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2248 - mean_absolute_error: 0.0121 - val_loss: 0.2247 - val_mean_absolute_error: 0.0119\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2248 - mean_absolute_error: 0.0120 - val_loss: 0.2247 - val_mean_absolute_error: 0.0119\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.2247 - mean_absolute_error: 0.0120 - val_loss: 0.2246 - val_mean_absolute_error: 0.0119\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.1174 - mean_absolute_error: 0.0697 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 97us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 98us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.2953 - mean_absolute_error: 0.1296 - val_loss: 0.2361 - val_mean_absolute_error: 0.0791\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.2207 - mean_absolute_error: 0.0616 - val_loss: 0.2081 - val_mean_absolute_error: 0.0467\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 100us/step - loss: 0.1998 - mean_absolute_error: 0.0351 - val_loss: 0.1939 - val_mean_absolute_error: 0.0264\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1910 - mean_absolute_error: 0.0218 - val_loss: 0.1889 - val_mean_absolute_error: 0.0187\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 100us/step - loss: 0.1877 - mean_absolute_error: 0.0170 - val_loss: 0.1867 - val_mean_absolute_error: 0.0155\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1860 - mean_absolute_error: 0.0144 - val_loss: 0.1853 - val_mean_absolute_error: 0.0134\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1849 - mean_absolute_error: 0.0126 - val_loss: 0.1845 - val_mean_absolute_error: 0.0120\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1843 - mean_absolute_error: 0.0115 - val_loss: 0.1840 - val_mean_absolute_error: 0.0111\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1839 - mean_absolute_error: 0.0109 - val_loss: 0.1837 - val_mean_absolute_error: 0.0106\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1836 - mean_absolute_error: 0.0105 - val_loss: 0.1835 - val_mean_absolute_error: 0.0104\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1835 - mean_absolute_error: 0.0102 - val_loss: 0.1834 - val_mean_absolute_error: 0.0102\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 100us/step - loss: 0.1834 - mean_absolute_error: 0.0101 - val_loss: 0.1834 - val_mean_absolute_error: 0.0100\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0101\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 99us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0101\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2953 - mean_absolute_error: 0.1108 - val_loss: 0.2596 - val_mean_absolute_error: 0.0785\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0792\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0793\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0789\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 99us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0779\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 100us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0786\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0782\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 101us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.3737 - mean_absolute_error: 0.1433 - val_loss: 0.3261 - val_mean_absolute_error: 0.1027\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.3123 - mean_absolute_error: 0.0896 - val_loss: 0.3025 - val_mean_absolute_error: 0.0796\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2965 - mean_absolute_error: 0.0754 - val_loss: 0.2912 - val_mean_absolute_error: 0.0706\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2873 - mean_absolute_error: 0.0666 - val_loss: 0.2838 - val_mean_absolute_error: 0.0628\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 0.2812 - mean_absolute_error: 0.0602 - val_loss: 0.2790 - val_mean_absolute_error: 0.0580\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2774 - mean_absolute_error: 0.0565 - val_loss: 0.2760 - val_mean_absolute_error: 0.0551\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 0.2750 - mean_absolute_error: 0.0541 - val_loss: 0.2740 - val_mean_absolute_error: 0.0534\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2733 - mean_absolute_error: 0.0526 - val_loss: 0.2726 - val_mean_absolute_error: 0.0519\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2721 - mean_absolute_error: 0.0515 - val_loss: 0.2716 - val_mean_absolute_error: 0.0518\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 0.2711 - mean_absolute_error: 0.0509 - val_loss: 0.2704 - val_mean_absolute_error: 0.0503\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2701 - mean_absolute_error: 0.0504 - val_loss: 0.2693 - val_mean_absolute_error: 0.0496\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2687 - mean_absolute_error: 0.0500 - val_loss: 0.2674 - val_mean_absolute_error: 0.0498\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2664 - mean_absolute_error: 0.0488 - val_loss: 0.2650 - val_mean_absolute_error: 0.0492\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2629 - mean_absolute_error: 0.0455 - val_loss: 0.2610 - val_mean_absolute_error: 0.0433\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2594 - mean_absolute_error: 0.0403 - val_loss: 0.2578 - val_mean_absolute_error: 0.0377\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 0.2569 - mean_absolute_error: 0.0357 - val_loss: 0.2561 - val_mean_absolute_error: 0.0342\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2556 - mean_absolute_error: 0.0335 - val_loss: 0.2552 - val_mean_absolute_error: 0.0330\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2549 - mean_absolute_error: 0.0326 - val_loss: 0.2546 - val_mean_absolute_error: 0.0323\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 102us/step - loss: 0.2544 - mean_absolute_error: 0.0319 - val_loss: 0.2543 - val_mean_absolute_error: 0.0318\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 103us/step - loss: 0.2541 - mean_absolute_error: 0.0315 - val_loss: 0.2540 - val_mean_absolute_error: 0.0314\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.060418\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_1', 9, 45, 1, 45, 0.9, 1.0, 0.9782608695652174, 0.9891304347826086]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.141247\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.038838\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_3', 6, 45, 4, 45, 0.6, 1.0, 0.9183673469387755, 0.9591836734693877]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.017615\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_4', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028259\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022971\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.029019\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100536\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.044985\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[0, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[0, 0.7118547118547118, 1.0000000000000002, 0.8886638096496693, 0.9443319048248346]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 6s 115us/step - loss: 0.4194 - mean_absolute_error: 0.1526 - val_loss: 0.4081 - val_mean_absolute_error: 0.1406\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1406\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 7s 127us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1419\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 6s 111us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1413\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1425\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 109us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1419\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1424\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 6s 108us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1415\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1411\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 6s 104us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1411\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1421\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1418\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1414\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1425\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1405\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1418\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4083 - val_mean_absolute_error: 0.1422\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1430\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 6s 103us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1399\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s 118us/step - loss: 0.2185 - mean_absolute_error: 0.0750 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 107us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0505\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0507\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0527\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0529\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1929 - val_mean_absolute_error: 0.0518\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 4s 118us/step - loss: 0.2181 - mean_absolute_error: 0.0952 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0621\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0628\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 101us/step - loss: 0.1797 - mean_absolute_error: 0.0617 - val_loss: 0.1763 - val_mean_absolute_error: 0.0598\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1715 - mean_absolute_error: 0.0559 - val_loss: 0.1671 - val_mean_absolute_error: 0.0532\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1635 - mean_absolute_error: 0.0497 - val_loss: 0.1603 - val_mean_absolute_error: 0.0471\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1576 - mean_absolute_error: 0.0447 - val_loss: 0.1553 - val_mean_absolute_error: 0.0430\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1534 - mean_absolute_error: 0.0407 - val_loss: 0.1518 - val_mean_absolute_error: 0.0386\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1504 - mean_absolute_error: 0.0375 - val_loss: 0.1492 - val_mean_absolute_error: 0.0363\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1483 - mean_absolute_error: 0.0355 - val_loss: 0.1475 - val_mean_absolute_error: 0.0350\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1469 - mean_absolute_error: 0.0343 - val_loss: 0.1464 - val_mean_absolute_error: 0.0338\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1460 - mean_absolute_error: 0.0335 - val_loss: 0.1458 - val_mean_absolute_error: 0.0335\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1453 - mean_absolute_error: 0.0328 - val_loss: 0.1451 - val_mean_absolute_error: 0.0330\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1448 - mean_absolute_error: 0.0323 - val_loss: 0.1447 - val_mean_absolute_error: 0.0321\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1444 - mean_absolute_error: 0.0319 - val_loss: 0.1442 - val_mean_absolute_error: 0.0315\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1441 - mean_absolute_error: 0.0315 - val_loss: 0.1440 - val_mean_absolute_error: 0.0315\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1438 - mean_absolute_error: 0.0312 - val_loss: 0.1437 - val_mean_absolute_error: 0.0308\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1436 - mean_absolute_error: 0.0309 - val_loss: 0.1434 - val_mean_absolute_error: 0.0310\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1433 - mean_absolute_error: 0.0307 - val_loss: 0.1432 - val_mean_absolute_error: 0.0303\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1955 - mean_absolute_error: 0.0896 - val_loss: 0.1300 - val_mean_absolute_error: 0.0269\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 126us/step - loss: 0.1254 - mean_absolute_error: 0.0222 - val_loss: 0.1228 - val_mean_absolute_error: 0.0194\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1214 - mean_absolute_error: 0.0177 - val_loss: 0.1202 - val_mean_absolute_error: 0.0162\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1196 - mean_absolute_error: 0.0154 - val_loss: 0.1191 - val_mean_absolute_error: 0.0149\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1188 - mean_absolute_error: 0.0144 - val_loss: 0.1185 - val_mean_absolute_error: 0.0141\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1183 - mean_absolute_error: 0.0140 - val_loss: 0.1181 - val_mean_absolute_error: 0.0138\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1179 - mean_absolute_error: 0.0137 - val_loss: 0.1177 - val_mean_absolute_error: 0.0135\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1174 - mean_absolute_error: 0.0133 - val_loss: 0.1170 - val_mean_absolute_error: 0.0129\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1165 - mean_absolute_error: 0.0123 - val_loss: 0.1160 - val_mean_absolute_error: 0.0117\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1157 - mean_absolute_error: 0.0112 - val_loss: 0.1153 - val_mean_absolute_error: 0.0106\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1151 - mean_absolute_error: 0.0103 - val_loss: 0.1149 - val_mean_absolute_error: 0.0099\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1148 - mean_absolute_error: 0.0097 - val_loss: 0.1147 - val_mean_absolute_error: 0.0095\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1146 - mean_absolute_error: 0.0095 - val_loss: 0.1146 - val_mean_absolute_error: 0.0094\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1145 - mean_absolute_error: 0.0094 - val_loss: 0.1145 - val_mean_absolute_error: 0.0093\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1145 - mean_absolute_error: 0.0094 - val_loss: 0.1144 - val_mean_absolute_error: 0.0094\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1144 - mean_absolute_error: 0.0094 - val_loss: 0.1144 - val_mean_absolute_error: 0.0093\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1143 - mean_absolute_error: 0.0090 - val_loss: 0.1143 - val_mean_absolute_error: 0.0089\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1142 - mean_absolute_error: 0.0088 - val_loss: 0.1142 - val_mean_absolute_error: 0.0088\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1142 - mean_absolute_error: 0.0088 - val_loss: 0.1142 - val_mean_absolute_error: 0.0088\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1142 - mean_absolute_error: 0.0088 - val_loss: 0.1142 - val_mean_absolute_error: 0.0087\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.3242 - mean_absolute_error: 0.1219 - val_loss: 0.2480 - val_mean_absolute_error: 0.0440\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2388 - mean_absolute_error: 0.0305 - val_loss: 0.2339 - val_mean_absolute_error: 0.0229\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2326 - mean_absolute_error: 0.0212 - val_loss: 0.2317 - val_mean_absolute_error: 0.0201\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2309 - mean_absolute_error: 0.0192 - val_loss: 0.2304 - val_mean_absolute_error: 0.0185\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2287 - mean_absolute_error: 0.0164 - val_loss: 0.2277 - val_mean_absolute_error: 0.0152\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2272 - mean_absolute_error: 0.0146 - val_loss: 0.2267 - val_mean_absolute_error: 0.0140\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2265 - mean_absolute_error: 0.0138 - val_loss: 0.2262 - val_mean_absolute_error: 0.0134\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2261 - mean_absolute_error: 0.0133 - val_loss: 0.2260 - val_mean_absolute_error: 0.0132\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2258 - mean_absolute_error: 0.0130 - val_loss: 0.2257 - val_mean_absolute_error: 0.0128\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2257 - mean_absolute_error: 0.0128 - val_loss: 0.2256 - val_mean_absolute_error: 0.0128\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2256 - mean_absolute_error: 0.0127 - val_loss: 0.2256 - val_mean_absolute_error: 0.0125\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2255 - mean_absolute_error: 0.0127 - val_loss: 0.2255 - val_mean_absolute_error: 0.0127\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2255 - mean_absolute_error: 0.0128 - val_loss: 0.2254 - val_mean_absolute_error: 0.0128\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2254 - mean_absolute_error: 0.0128 - val_loss: 0.2253 - val_mean_absolute_error: 0.0126\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2252 - val_mean_absolute_error: 0.0123\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2252 - mean_absolute_error: 0.0123 - val_loss: 0.2251 - val_mean_absolute_error: 0.0121\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2251 - mean_absolute_error: 0.0121 - val_loss: 0.2251 - val_mean_absolute_error: 0.0120\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2251 - mean_absolute_error: 0.0120 - val_loss: 0.2250 - val_mean_absolute_error: 0.0122\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2250 - mean_absolute_error: 0.0120 - val_loss: 0.2250 - val_mean_absolute_error: 0.0119\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2250 - mean_absolute_error: 0.0119 - val_loss: 0.2250 - val_mean_absolute_error: 0.0119\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.1170 - mean_absolute_error: 0.0694 - val_loss: 0.0598 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 4s 118us/step - loss: 0.2929 - mean_absolute_error: 0.1261 - val_loss: 0.2287 - val_mean_absolute_error: 0.0685\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.2142 - mean_absolute_error: 0.0495 - val_loss: 0.2049 - val_mean_absolute_error: 0.0370\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1997 - mean_absolute_error: 0.0312 - val_loss: 0.1958 - val_mean_absolute_error: 0.0271\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1935 - mean_absolute_error: 0.0248 - val_loss: 0.1916 - val_mean_absolute_error: 0.0228\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1904 - mean_absolute_error: 0.0214 - val_loss: 0.1894 - val_mean_absolute_error: 0.0201\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1887 - mean_absolute_error: 0.0190 - val_loss: 0.1880 - val_mean_absolute_error: 0.0180\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1876 - mean_absolute_error: 0.0173 - val_loss: 0.1871 - val_mean_absolute_error: 0.0167\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 102us/step - loss: 0.1868 - mean_absolute_error: 0.0161 - val_loss: 0.1864 - val_mean_absolute_error: 0.0157\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1859 - mean_absolute_error: 0.0145 - val_loss: 0.1850 - val_mean_absolute_error: 0.0129\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1846 - mean_absolute_error: 0.0120 - val_loss: 0.1841 - val_mean_absolute_error: 0.0112\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1839 - mean_absolute_error: 0.0108 - val_loss: 0.1837 - val_mean_absolute_error: 0.0105\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1836 - mean_absolute_error: 0.0103 - val_loss: 0.1835 - val_mean_absolute_error: 0.0101\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1835 - mean_absolute_error: 0.0100 - val_loss: 0.1834 - val_mean_absolute_error: 0.0099\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1834 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1834 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1833 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2956 - mean_absolute_error: 0.1110 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0789\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0781\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2597 - val_mean_absolute_error: 0.0773\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0785\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2599 - val_mean_absolute_error: 0.0788\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0777\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0783\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.3752 - mean_absolute_error: 0.1444 - val_loss: 0.3318 - val_mean_absolute_error: 0.1079\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.3188 - mean_absolute_error: 0.0960 - val_loss: 0.3088 - val_mean_absolute_error: 0.0859\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.3030 - mean_absolute_error: 0.0806 - val_loss: 0.2981 - val_mean_absolute_error: 0.0761\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2948 - mean_absolute_error: 0.0744 - val_loss: 0.2911 - val_mean_absolute_error: 0.0718\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2876 - mean_absolute_error: 0.0683 - val_loss: 0.2843 - val_mean_absolute_error: 0.0650\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2818 - mean_absolute_error: 0.0618 - val_loss: 0.2794 - val_mean_absolute_error: 0.0592\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2778 - mean_absolute_error: 0.0573 - val_loss: 0.2762 - val_mean_absolute_error: 0.0555\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2753 - mean_absolute_error: 0.0546 - val_loss: 0.2743 - val_mean_absolute_error: 0.0535\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2736 - mean_absolute_error: 0.0529 - val_loss: 0.2729 - val_mean_absolute_error: 0.0522\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2724 - mean_absolute_error: 0.0517 - val_loss: 0.2719 - val_mean_absolute_error: 0.0511\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2716 - mean_absolute_error: 0.0508 - val_loss: 0.2712 - val_mean_absolute_error: 0.0504\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.2710 - mean_absolute_error: 0.0501 - val_loss: 0.2705 - val_mean_absolute_error: 0.0497\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2705 - mean_absolute_error: 0.0497 - val_loss: 0.2709 - val_mean_absolute_error: 0.0500\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2700 - mean_absolute_error: 0.0493 - val_loss: 0.2696 - val_mean_absolute_error: 0.0489\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2703 - val_mean_absolute_error: 0.0495\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2694 - mean_absolute_error: 0.0487 - val_loss: 0.2692 - val_mean_absolute_error: 0.0487\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2692 - mean_absolute_error: 0.0486 - val_loss: 0.2689 - val_mean_absolute_error: 0.0482\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2690 - mean_absolute_error: 0.0484 - val_loss: 0.2687 - val_mean_absolute_error: 0.0481\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2688 - mean_absolute_error: 0.0482 - val_loss: 0.2686 - val_mean_absolute_error: 0.0481\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2694 - val_mean_absolute_error: 0.0485\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.187484\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_1', 9, 36, 10, 36, 0.47368421052631576, 1.0, 0.782608695652174, 0.8913043478260869]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.141022\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.042489\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_3', 6, 42, 7, 42, 0.46153846153846156, 1.0, 0.8571428571428571, 0.9285714285714286]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.019232\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_4', 6, 46, 3, 46, 0.6666666666666666, 1.0, 0.9387755102040817, 0.9693877551020409]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.024708\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023003\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028309\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100333\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.068712\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[1, 'fam_9', 5, 42, 8, 42, 0.38461538461538464, 1.0, 0.84, 0.9199999999999999]\n",
      "[1, 0.5714663477821372, 1.0000000000000002, 0.8400766066525285, 0.9200383033262642]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.4194 - mean_absolute_error: 0.1527 - val_loss: 0.4079 - val_mean_absolute_error: 0.1419\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1423\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4084 - val_mean_absolute_error: 0.1415\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1411\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1415\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1407\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1408\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1411\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1417\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1421\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1421\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1419\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 6s 105us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1404\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 6s 106us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1417\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.3965 - mean_absolute_error: 0.1343 - val_loss: 0.3823 - val_mean_absolute_error: 0.1249\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 6s 108us/step - loss: 0.3713 - mean_absolute_error: 0.1169 - val_loss: 0.3619 - val_mean_absolute_error: 0.1099\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 6s 108us/step - loss: 0.3551 - mean_absolute_error: 0.1036 - val_loss: 0.3492 - val_mean_absolute_error: 0.0989\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 6s 109us/step - loss: 0.3450 - mean_absolute_error: 0.0935 - val_loss: 0.3413 - val_mean_absolute_error: 0.0896\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 6s 109us/step - loss: 0.3379 - mean_absolute_error: 0.0862 - val_loss: 0.3311 - val_mean_absolute_error: 0.0822\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.3243 - mean_absolute_error: 0.0759 - val_loss: 0.3176 - val_mean_absolute_error: 0.0708\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s 117us/step - loss: 0.2186 - mean_absolute_error: 0.0750 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0536\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0521\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0528\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0529\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0528\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.2184 - mean_absolute_error: 0.0954 - val_loss: 0.1806 - val_mean_absolute_error: 0.0629\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1798 - val_mean_absolute_error: 0.0619\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 103us/step - loss: 0.1745 - mean_absolute_error: 0.0581 - val_loss: 0.1697 - val_mean_absolute_error: 0.0547\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1657 - mean_absolute_error: 0.0515 - val_loss: 0.1621 - val_mean_absolute_error: 0.0483\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1592 - mean_absolute_error: 0.0461 - val_loss: 0.1566 - val_mean_absolute_error: 0.0436\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1546 - mean_absolute_error: 0.0419 - val_loss: 0.1528 - val_mean_absolute_error: 0.0403\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1512 - mean_absolute_error: 0.0384 - val_loss: 0.1499 - val_mean_absolute_error: 0.0369\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1489 - mean_absolute_error: 0.0360 - val_loss: 0.1480 - val_mean_absolute_error: 0.0352\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1473 - mean_absolute_error: 0.0346 - val_loss: 0.1467 - val_mean_absolute_error: 0.0344\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1462 - mean_absolute_error: 0.0337 - val_loss: 0.1458 - val_mean_absolute_error: 0.0330\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1455 - mean_absolute_error: 0.0330 - val_loss: 0.1452 - val_mean_absolute_error: 0.0326\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1450 - mean_absolute_error: 0.0324 - val_loss: 0.1447 - val_mean_absolute_error: 0.0322\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1445 - mean_absolute_error: 0.0320 - val_loss: 0.1443 - val_mean_absolute_error: 0.0315\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1442 - mean_absolute_error: 0.0316 - val_loss: 0.1440 - val_mean_absolute_error: 0.0314\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1439 - mean_absolute_error: 0.0313 - val_loss: 0.1437 - val_mean_absolute_error: 0.0311\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1436 - mean_absolute_error: 0.0310 - val_loss: 0.1439 - val_mean_absolute_error: 0.0316\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1434 - mean_absolute_error: 0.0307 - val_loss: 0.1435 - val_mean_absolute_error: 0.0306\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1432 - mean_absolute_error: 0.0305 - val_loss: 0.1431 - val_mean_absolute_error: 0.0307\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1430 - mean_absolute_error: 0.0303 - val_loss: 0.1430 - val_mean_absolute_error: 0.0300\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1429 - mean_absolute_error: 0.0301 - val_loss: 0.1429 - val_mean_absolute_error: 0.0299\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1958 - mean_absolute_error: 0.0899 - val_loss: 0.1295 - val_mean_absolute_error: 0.0270\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1251 - mean_absolute_error: 0.0218 - val_loss: 0.1225 - val_mean_absolute_error: 0.0188\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1212 - mean_absolute_error: 0.0174 - val_loss: 0.1201 - val_mean_absolute_error: 0.0161\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1195 - mean_absolute_error: 0.0154 - val_loss: 0.1191 - val_mean_absolute_error: 0.0148\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1188 - mean_absolute_error: 0.0144 - val_loss: 0.1185 - val_mean_absolute_error: 0.0141\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1183 - mean_absolute_error: 0.0140 - val_loss: 0.1181 - val_mean_absolute_error: 0.0138\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1179 - mean_absolute_error: 0.0137 - val_loss: 0.1177 - val_mean_absolute_error: 0.0136\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1174 - mean_absolute_error: 0.0133 - val_loss: 0.1170 - val_mean_absolute_error: 0.0130\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1165 - mean_absolute_error: 0.0124 - val_loss: 0.1161 - val_mean_absolute_error: 0.0118\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1157 - mean_absolute_error: 0.0113 - val_loss: 0.1154 - val_mean_absolute_error: 0.0108\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1151 - mean_absolute_error: 0.0104 - val_loss: 0.1149 - val_mean_absolute_error: 0.0101\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1148 - mean_absolute_error: 0.0099 - val_loss: 0.1147 - val_mean_absolute_error: 0.0096\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1146 - mean_absolute_error: 0.0097 - val_loss: 0.1145 - val_mean_absolute_error: 0.0095\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1144 - mean_absolute_error: 0.0093 - val_loss: 0.1144 - val_mean_absolute_error: 0.0091\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1143 - mean_absolute_error: 0.0090 - val_loss: 0.1143 - val_mean_absolute_error: 0.0089\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1143 - mean_absolute_error: 0.0089 - val_loss: 0.1143 - val_mean_absolute_error: 0.0092\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1142 - val_mean_absolute_error: 0.0089\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1142 - val_mean_absolute_error: 0.0090\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1142 - val_mean_absolute_error: 0.0090\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1142 - val_mean_absolute_error: 0.0092\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.3237 - mean_absolute_error: 0.1215 - val_loss: 0.2481 - val_mean_absolute_error: 0.0442\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2387 - mean_absolute_error: 0.0304 - val_loss: 0.2333 - val_mean_absolute_error: 0.0225\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2319 - mean_absolute_error: 0.0205 - val_loss: 0.2311 - val_mean_absolute_error: 0.0194\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2307 - mean_absolute_error: 0.0189 - val_loss: 0.2305 - val_mean_absolute_error: 0.0187\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2304 - mean_absolute_error: 0.0184 - val_loss: 0.2303 - val_mean_absolute_error: 0.0183\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2303 - mean_absolute_error: 0.0183 - val_loss: 0.2303 - val_mean_absolute_error: 0.0183\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2300 - mean_absolute_error: 0.0180 - val_loss: 0.2295 - val_mean_absolute_error: 0.0174\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2288 - mean_absolute_error: 0.0167 - val_loss: 0.2277 - val_mean_absolute_error: 0.0157\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2271 - mean_absolute_error: 0.0146 - val_loss: 0.2267 - val_mean_absolute_error: 0.0139\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2264 - mean_absolute_error: 0.0137 - val_loss: 0.2262 - val_mean_absolute_error: 0.0136\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2261 - mean_absolute_error: 0.0134 - val_loss: 0.2260 - val_mean_absolute_error: 0.0132\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2259 - mean_absolute_error: 0.0133 - val_loss: 0.2259 - val_mean_absolute_error: 0.0130\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2258 - mean_absolute_error: 0.0133 - val_loss: 0.2258 - val_mean_absolute_error: 0.0131\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2257 - mean_absolute_error: 0.0133 - val_loss: 0.2256 - val_mean_absolute_error: 0.0131\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2255 - mean_absolute_error: 0.0131 - val_loss: 0.2255 - val_mean_absolute_error: 0.0129\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2254 - mean_absolute_error: 0.0127 - val_loss: 0.2254 - val_mean_absolute_error: 0.0126\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2253 - val_mean_absolute_error: 0.0123\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0125\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2252 - mean_absolute_error: 0.0123 - val_loss: 0.2252 - val_mean_absolute_error: 0.0123\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2251 - mean_absolute_error: 0.0122 - val_loss: 0.2251 - val_mean_absolute_error: 0.0121\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.1171 - mean_absolute_error: 0.0695 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 104us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 105us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.2897 - mean_absolute_error: 0.1239 - val_loss: 0.2258 - val_mean_absolute_error: 0.0654\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 104us/step - loss: 0.2119 - mean_absolute_error: 0.0470 - val_loss: 0.2022 - val_mean_absolute_error: 0.0338\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1980 - mean_absolute_error: 0.0289 - val_loss: 0.1949 - val_mean_absolute_error: 0.0256\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1923 - mean_absolute_error: 0.0225 - val_loss: 0.1900 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1885 - mean_absolute_error: 0.0179 - val_loss: 0.1874 - val_mean_absolute_error: 0.0164\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1866 - mean_absolute_error: 0.0152 - val_loss: 0.1859 - val_mean_absolute_error: 0.0142\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1853 - mean_absolute_error: 0.0133 - val_loss: 0.1847 - val_mean_absolute_error: 0.0122\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1841 - mean_absolute_error: 0.0112 - val_loss: 0.1838 - val_mean_absolute_error: 0.0106\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1836 - mean_absolute_error: 0.0103 - val_loss: 0.1835 - val_mean_absolute_error: 0.0101\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1834 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1833 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1833 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1832 - mean_absolute_error: 0.0098 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1831 - mean_absolute_error: 0.0099 - val_loss: 0.1831 - val_mean_absolute_error: 0.0099\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1831 - mean_absolute_error: 0.0099 - val_loss: 0.1831 - val_mean_absolute_error: 0.0099\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1831 - mean_absolute_error: 0.0099 - val_loss: 0.1831 - val_mean_absolute_error: 0.0099\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2952 - mean_absolute_error: 0.1107 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0779\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0790\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0793\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0792\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0789\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0782\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.3728 - mean_absolute_error: 0.1425 - val_loss: 0.3254 - val_mean_absolute_error: 0.1033\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.3119 - mean_absolute_error: 0.0893 - val_loss: 0.3025 - val_mean_absolute_error: 0.0792\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2963 - mean_absolute_error: 0.0752 - val_loss: 0.2910 - val_mean_absolute_error: 0.0703\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2870 - mean_absolute_error: 0.0663 - val_loss: 0.2835 - val_mean_absolute_error: 0.0627\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2810 - mean_absolute_error: 0.0600 - val_loss: 0.2788 - val_mean_absolute_error: 0.0578\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2773 - mean_absolute_error: 0.0564 - val_loss: 0.2760 - val_mean_absolute_error: 0.0551\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2749 - mean_absolute_error: 0.0541 - val_loss: 0.2740 - val_mean_absolute_error: 0.0534\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2733 - mean_absolute_error: 0.0526 - val_loss: 0.2725 - val_mean_absolute_error: 0.0518\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2721 - mean_absolute_error: 0.0515 - val_loss: 0.2716 - val_mean_absolute_error: 0.0510\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2712 - mean_absolute_error: 0.0508 - val_loss: 0.2708 - val_mean_absolute_error: 0.0510\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2703 - mean_absolute_error: 0.0504 - val_loss: 0.2695 - val_mean_absolute_error: 0.0502\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2692 - mean_absolute_error: 0.0501 - val_loss: 0.2683 - val_mean_absolute_error: 0.0487\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2674 - mean_absolute_error: 0.0493 - val_loss: 0.2664 - val_mean_absolute_error: 0.0473\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2644 - mean_absolute_error: 0.0471 - val_loss: 0.2625 - val_mean_absolute_error: 0.0453\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2607 - mean_absolute_error: 0.0426 - val_loss: 0.2591 - val_mean_absolute_error: 0.0403\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2577 - mean_absolute_error: 0.0374 - val_loss: 0.2566 - val_mean_absolute_error: 0.0352\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2559 - mean_absolute_error: 0.0341 - val_loss: 0.2554 - val_mean_absolute_error: 0.0333\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2551 - mean_absolute_error: 0.0329 - val_loss: 0.2548 - val_mean_absolute_error: 0.0325\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2546 - mean_absolute_error: 0.0321 - val_loss: 0.2543 - val_mean_absolute_error: 0.0318\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2542 - mean_absolute_error: 0.0317 - val_loss: 0.2541 - val_mean_absolute_error: 0.0314\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.104896\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_1', 9, 35, 11, 35, 0.45, 1.0, 0.7608695652173914, 0.8804347826086957]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.140756\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.039051\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_3', 6, 44, 5, 44, 0.5454545454545454, 1.0, 0.8979591836734694, 0.9489795918367347]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.032272\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_4', 6, 42, 7, 42, 0.46153846153846156, 1.0, 0.8571428571428571, 0.9285714285714286]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.024698\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022974\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028378\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100797\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.046015\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[2, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[2, 0.6237428237428237, 1.0000000000000002, 0.850903778100818, 0.9254518890504089]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 7s 120us/step - loss: 0.4194 - mean_absolute_error: 0.1526 - val_loss: 0.4080 - val_mean_absolute_error: 0.1429\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1415\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1410\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1416\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1411\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1417\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 6s 108us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1413\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1417\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1421\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1414\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1414\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1413\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 6s 109us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4082 - val_mean_absolute_error: 0.1398\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 6s 109us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1408\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 6s 108us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1417\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 6s 107us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1416\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 6s 108us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1416\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 6s 111us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1409\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.2186 - mean_absolute_error: 0.0750 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s 107us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0529\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s 106us/step - loss: 0.1930 - mean_absolute_error: 0.0516 - val_loss: 0.1931 - val_mean_absolute_error: 0.0535\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1931 - val_mean_absolute_error: 0.0501\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0528\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.2183 - mean_absolute_error: 0.0953 - val_loss: 0.1806 - val_mean_absolute_error: 0.0624\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1772 - mean_absolute_error: 0.0600 - val_loss: 0.1723 - val_mean_absolute_error: 0.0567\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1680 - mean_absolute_error: 0.0533 - val_loss: 0.1641 - val_mean_absolute_error: 0.0503\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1609 - mean_absolute_error: 0.0475 - val_loss: 0.1580 - val_mean_absolute_error: 0.0449\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1557 - mean_absolute_error: 0.0430 - val_loss: 0.1537 - val_mean_absolute_error: 0.0411\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1521 - mean_absolute_error: 0.0393 - val_loss: 0.1506 - val_mean_absolute_error: 0.0375\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1495 - mean_absolute_error: 0.0365 - val_loss: 0.1484 - val_mean_absolute_error: 0.0354\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1477 - mean_absolute_error: 0.0350 - val_loss: 0.1472 - val_mean_absolute_error: 0.0346\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1465 - mean_absolute_error: 0.0339 - val_loss: 0.1460 - val_mean_absolute_error: 0.0335\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1457 - mean_absolute_error: 0.0331 - val_loss: 0.1453 - val_mean_absolute_error: 0.0330\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1451 - mean_absolute_error: 0.0326 - val_loss: 0.1448 - val_mean_absolute_error: 0.0324\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1446 - mean_absolute_error: 0.0321 - val_loss: 0.1445 - val_mean_absolute_error: 0.0318\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1443 - mean_absolute_error: 0.0317 - val_loss: 0.1441 - val_mean_absolute_error: 0.0314\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1440 - mean_absolute_error: 0.0314 - val_loss: 0.1438 - val_mean_absolute_error: 0.0314\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1437 - mean_absolute_error: 0.0311 - val_loss: 0.1435 - val_mean_absolute_error: 0.0309\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1435 - mean_absolute_error: 0.0308 - val_loss: 0.1433 - val_mean_absolute_error: 0.0310\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1432 - mean_absolute_error: 0.0306 - val_loss: 0.1431 - val_mean_absolute_error: 0.0305\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1431 - mean_absolute_error: 0.0303 - val_loss: 0.1429 - val_mean_absolute_error: 0.0303\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1429 - mean_absolute_error: 0.0302 - val_loss: 0.1427 - val_mean_absolute_error: 0.0299\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1427 - mean_absolute_error: 0.0300 - val_loss: 0.1426 - val_mean_absolute_error: 0.0298\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1974 - mean_absolute_error: 0.0918 - val_loss: 0.1318 - val_mean_absolute_error: 0.0310\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1261 - mean_absolute_error: 0.0232 - val_loss: 0.1230 - val_mean_absolute_error: 0.0195\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1216 - mean_absolute_error: 0.0180 - val_loss: 0.1206 - val_mean_absolute_error: 0.0166\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1199 - mean_absolute_error: 0.0159 - val_loss: 0.1193 - val_mean_absolute_error: 0.0152\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1190 - mean_absolute_error: 0.0148 - val_loss: 0.1187 - val_mean_absolute_error: 0.0146\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1184 - mean_absolute_error: 0.0143 - val_loss: 0.1182 - val_mean_absolute_error: 0.0144\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1180 - mean_absolute_error: 0.0142 - val_loss: 0.1178 - val_mean_absolute_error: 0.0138\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1175 - mean_absolute_error: 0.0137 - val_loss: 0.1172 - val_mean_absolute_error: 0.0132\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1168 - mean_absolute_error: 0.0129 - val_loss: 0.1163 - val_mean_absolute_error: 0.0122\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1158 - mean_absolute_error: 0.0117 - val_loss: 0.1154 - val_mean_absolute_error: 0.0110\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1151 - mean_absolute_error: 0.0106 - val_loss: 0.1149 - val_mean_absolute_error: 0.0101\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1147 - mean_absolute_error: 0.0098 - val_loss: 0.1146 - val_mean_absolute_error: 0.0095\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1144 - mean_absolute_error: 0.0094 - val_loss: 0.1144 - val_mean_absolute_error: 0.0092\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1143 - mean_absolute_error: 0.0091 - val_loss: 0.1143 - val_mean_absolute_error: 0.0092\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1142 - val_mean_absolute_error: 0.0087\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1141 - mean_absolute_error: 0.0087 - val_loss: 0.1141 - val_mean_absolute_error: 0.0087\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 105us/step - loss: 0.1141 - mean_absolute_error: 0.0086 - val_loss: 0.1141 - val_mean_absolute_error: 0.0086\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1141 - val_mean_absolute_error: 0.0086\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1140 - mean_absolute_error: 0.0085 - val_loss: 0.1141 - val_mean_absolute_error: 0.0086\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1140 - mean_absolute_error: 0.0085 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.3252 - mean_absolute_error: 0.1225 - val_loss: 0.2488 - val_mean_absolute_error: 0.0452\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2379 - mean_absolute_error: 0.0301 - val_loss: 0.2325 - val_mean_absolute_error: 0.0231\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2311 - mean_absolute_error: 0.0197 - val_loss: 0.2305 - val_mean_absolute_error: 0.0186\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2304 - mean_absolute_error: 0.0184 - val_loss: 0.2303 - val_mean_absolute_error: 0.0182\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2293 - mean_absolute_error: 0.0171 - val_loss: 0.2282 - val_mean_absolute_error: 0.0157\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2275 - mean_absolute_error: 0.0150 - val_loss: 0.2270 - val_mean_absolute_error: 0.0144\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2266 - mean_absolute_error: 0.0140 - val_loss: 0.2263 - val_mean_absolute_error: 0.0137\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2261 - mean_absolute_error: 0.0134 - val_loss: 0.2259 - val_mean_absolute_error: 0.0131\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2258 - mean_absolute_error: 0.0131 - val_loss: 0.2258 - val_mean_absolute_error: 0.0131\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2257 - mean_absolute_error: 0.0129 - val_loss: 0.2256 - val_mean_absolute_error: 0.0127\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2256 - mean_absolute_error: 0.0127 - val_loss: 0.2256 - val_mean_absolute_error: 0.0125\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2256 - mean_absolute_error: 0.0127 - val_loss: 0.2256 - val_mean_absolute_error: 0.0126\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2255 - mean_absolute_error: 0.0126 - val_loss: 0.2255 - val_mean_absolute_error: 0.0125\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2255 - mean_absolute_error: 0.0126 - val_loss: 0.2255 - val_mean_absolute_error: 0.0129\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2255 - mean_absolute_error: 0.0126 - val_loss: 0.2255 - val_mean_absolute_error: 0.0125\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2254 - mean_absolute_error: 0.0126 - val_loss: 0.2254 - val_mean_absolute_error: 0.0125\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2254 - mean_absolute_error: 0.0125 - val_loss: 0.2254 - val_mean_absolute_error: 0.0124\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2253 - val_mean_absolute_error: 0.0126\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2253 - val_mean_absolute_error: 0.0125\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2253 - val_mean_absolute_error: 0.0128\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.1170 - mean_absolute_error: 0.0695 - val_loss: 0.0598 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 106us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 107us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.2972 - mean_absolute_error: 0.1309 - val_loss: 0.2360 - val_mean_absolute_error: 0.0790\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.2141 - mean_absolute_error: 0.0560 - val_loss: 0.2012 - val_mean_absolute_error: 0.0398\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1963 - mean_absolute_error: 0.0309 - val_loss: 0.1928 - val_mean_absolute_error: 0.0245\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1905 - mean_absolute_error: 0.0203 - val_loss: 0.1887 - val_mean_absolute_error: 0.0174\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 106us/step - loss: 0.1876 - mean_absolute_error: 0.0160 - val_loss: 0.1866 - val_mean_absolute_error: 0.0148\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1857 - mean_absolute_error: 0.0138 - val_loss: 0.1849 - val_mean_absolute_error: 0.0125\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1843 - mean_absolute_error: 0.0115 - val_loss: 0.1839 - val_mean_absolute_error: 0.0109\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 107us/step - loss: 0.1837 - mean_absolute_error: 0.0105 - val_loss: 0.1836 - val_mean_absolute_error: 0.0103\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1835 - mean_absolute_error: 0.0101 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1834 - val_mean_absolute_error: 0.0100\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0101\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0101\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1832 - mean_absolute_error: 0.0101 - val_loss: 0.1833 - val_mean_absolute_error: 0.0102\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1832 - mean_absolute_error: 0.0101 - val_loss: 0.1832 - val_mean_absolute_error: 0.0105\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1832 - mean_absolute_error: 0.0101 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1831 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0102\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1831 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0101\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2956 - mean_absolute_error: 0.1110 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0779\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0792\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2597 - val_mean_absolute_error: 0.0786\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0790\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 109us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 108us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.3731 - mean_absolute_error: 0.1427 - val_loss: 0.3255 - val_mean_absolute_error: 0.1031\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.3119 - mean_absolute_error: 0.0893 - val_loss: 0.3022 - val_mean_absolute_error: 0.0802\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2963 - mean_absolute_error: 0.0752 - val_loss: 0.2910 - val_mean_absolute_error: 0.0705\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2871 - mean_absolute_error: 0.0664 - val_loss: 0.2836 - val_mean_absolute_error: 0.0625\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2810 - mean_absolute_error: 0.0600 - val_loss: 0.2788 - val_mean_absolute_error: 0.0578\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2772 - mean_absolute_error: 0.0563 - val_loss: 0.2759 - val_mean_absolute_error: 0.0551\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2748 - mean_absolute_error: 0.0540 - val_loss: 0.2739 - val_mean_absolute_error: 0.0532\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2732 - mean_absolute_error: 0.0525 - val_loss: 0.2724 - val_mean_absolute_error: 0.0517\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2720 - mean_absolute_error: 0.0515 - val_loss: 0.2714 - val_mean_absolute_error: 0.0508\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2710 - mean_absolute_error: 0.0509 - val_loss: 0.2711 - val_mean_absolute_error: 0.0506\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2699 - mean_absolute_error: 0.0504 - val_loss: 0.2692 - val_mean_absolute_error: 0.0492\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2684 - mean_absolute_error: 0.0499 - val_loss: 0.2674 - val_mean_absolute_error: 0.0481\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2657 - mean_absolute_error: 0.0483 - val_loss: 0.2642 - val_mean_absolute_error: 0.0457\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2621 - mean_absolute_error: 0.0445 - val_loss: 0.2602 - val_mean_absolute_error: 0.0417\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2587 - mean_absolute_error: 0.0392 - val_loss: 0.2573 - val_mean_absolute_error: 0.0367\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2565 - mean_absolute_error: 0.0350 - val_loss: 0.2558 - val_mean_absolute_error: 0.0338\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2554 - mean_absolute_error: 0.0333 - val_loss: 0.2550 - val_mean_absolute_error: 0.0328\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2547 - mean_absolute_error: 0.0324 - val_loss: 0.2545 - val_mean_absolute_error: 0.0321\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2544 - mean_absolute_error: 0.0318 - val_loss: 0.2542 - val_mean_absolute_error: 0.0317\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2541 - mean_absolute_error: 0.0315 - val_loss: 0.2540 - val_mean_absolute_error: 0.0315\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.188498\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_1', 9, 36, 10, 36, 0.47368421052631576, 1.0, 0.782608695652174, 0.8913043478260869]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.140598\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.039695\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_3', 6, 44, 5, 44, 0.5454545454545454, 1.0, 0.8979591836734694, 0.9489795918367347]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.017159\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_4', 6, 49, 0, 49, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_32 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.029128\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022935\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_34 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.029408\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100200\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.044600\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[3, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[3, 0.6862034625192519, 1.0000000000000002, 0.8691922529110319, 0.934596126455516]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 7s 128us/step - loss: 0.4155 - mean_absolute_error: 0.1502 - val_loss: 0.3924 - val_mean_absolute_error: 0.1322\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 6s 112us/step - loss: 0.3701 - mean_absolute_error: 0.1160 - val_loss: 0.3426 - val_mean_absolute_error: 0.0951\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 6s 114us/step - loss: 0.3271 - mean_absolute_error: 0.0800 - val_loss: 0.3163 - val_mean_absolute_error: 0.0695\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 6s 114us/step - loss: 0.3108 - mean_absolute_error: 0.0637 - val_loss: 0.3065 - val_mean_absolute_error: 0.0596\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.3038 - mean_absolute_error: 0.0559 - val_loss: 0.3014 - val_mean_absolute_error: 0.0532\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.3005 - mean_absolute_error: 0.0520 - val_loss: 0.2991 - val_mean_absolute_error: 0.0499\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2987 - mean_absolute_error: 0.0499 - val_loss: 0.2982 - val_mean_absolute_error: 0.0482\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2976 - mean_absolute_error: 0.0485 - val_loss: 0.2968 - val_mean_absolute_error: 0.0482\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2966 - mean_absolute_error: 0.0475 - val_loss: 0.2958 - val_mean_absolute_error: 0.0460\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2957 - mean_absolute_error: 0.0466 - val_loss: 0.2946 - val_mean_absolute_error: 0.0450\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2949 - mean_absolute_error: 0.0457 - val_loss: 0.2938 - val_mean_absolute_error: 0.0448\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2942 - mean_absolute_error: 0.0448 - val_loss: 0.2959 - val_mean_absolute_error: 0.0465\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2934 - mean_absolute_error: 0.0439 - val_loss: 0.2923 - val_mean_absolute_error: 0.0426\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 6s 114us/step - loss: 0.2922 - mean_absolute_error: 0.0424 - val_loss: 0.2923 - val_mean_absolute_error: 0.0440\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 6s 114us/step - loss: 0.2899 - mean_absolute_error: 0.0396 - val_loss: 0.2891 - val_mean_absolute_error: 0.0388\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2883 - mean_absolute_error: 0.0374 - val_loss: 0.2861 - val_mean_absolute_error: 0.0341\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 6s 114us/step - loss: 0.2853 - mean_absolute_error: 0.0335 - val_loss: 0.2836 - val_mean_absolute_error: 0.0316\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2830 - mean_absolute_error: 0.0306 - val_loss: 0.2800 - val_mean_absolute_error: 0.0251\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 6s 113us/step - loss: 0.2784 - mean_absolute_error: 0.0233 - val_loss: 0.2763 - val_mean_absolute_error: 0.0191\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 6s 115us/step - loss: 0.2759 - mean_absolute_error: 0.0194 - val_loss: 0.2750 - val_mean_absolute_error: 0.0168\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.2188 - mean_absolute_error: 0.0752 - val_loss: 0.1931 - val_mean_absolute_error: 0.0534\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0521\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1930 - mean_absolute_error: 0.0516 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0505\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1932 - val_mean_absolute_error: 0.0497\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1883 - mean_absolute_error: 0.0502 - val_loss: 0.1826 - val_mean_absolute_error: 0.0479\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s 109us/step - loss: 0.1774 - mean_absolute_error: 0.0459 - val_loss: 0.1727 - val_mean_absolute_error: 0.0439\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.1686 - mean_absolute_error: 0.0411 - val_loss: 0.1648 - val_mean_absolute_error: 0.0383\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s 110us/step - loss: 0.1616 - mean_absolute_error: 0.0361 - val_loss: 0.1588 - val_mean_absolute_error: 0.0337\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1565 - mean_absolute_error: 0.0314 - val_loss: 0.1545 - val_mean_absolute_error: 0.0293\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1530 - mean_absolute_error: 0.0276 - val_loss: 0.1517 - val_mean_absolute_error: 0.0262\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1508 - mean_absolute_error: 0.0247 - val_loss: 0.1500 - val_mean_absolute_error: 0.0230\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s 108us/step - loss: 0.1494 - mean_absolute_error: 0.0227 - val_loss: 0.1489 - val_mean_absolute_error: 0.0224\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.2180 - mean_absolute_error: 0.0951 - val_loss: 0.1805 - val_mean_absolute_error: 0.0619\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0620\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0620\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1804 - val_mean_absolute_error: 0.0624\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0622\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0614\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1804 - val_mean_absolute_error: 0.0625\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0629\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0619\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1805 - val_mean_absolute_error: 0.0631\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1807 - val_mean_absolute_error: 0.0614\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0621\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0621\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 108us/step - loss: 0.1769 - mean_absolute_error: 0.0597 - val_loss: 0.1720 - val_mean_absolute_error: 0.0563\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1677 - mean_absolute_error: 0.0531 - val_loss: 0.1638 - val_mean_absolute_error: 0.0501\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1607 - mean_absolute_error: 0.0473 - val_loss: 0.1579 - val_mean_absolute_error: 0.0445\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1556 - mean_absolute_error: 0.0429 - val_loss: 0.1536 - val_mean_absolute_error: 0.0410\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1946 - mean_absolute_error: 0.0885 - val_loss: 0.1282 - val_mean_absolute_error: 0.0253\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 109us/step - loss: 0.1240 - mean_absolute_error: 0.0205 - val_loss: 0.1215 - val_mean_absolute_error: 0.0177\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1202 - mean_absolute_error: 0.0164 - val_loss: 0.1193 - val_mean_absolute_error: 0.0154\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1186 - mean_absolute_error: 0.0147 - val_loss: 0.1180 - val_mean_absolute_error: 0.0142\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1176 - mean_absolute_error: 0.0137 - val_loss: 0.1172 - val_mean_absolute_error: 0.0133\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1168 - mean_absolute_error: 0.0128 - val_loss: 0.1164 - val_mean_absolute_error: 0.0123\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1162 - mean_absolute_error: 0.0119 - val_loss: 0.1159 - val_mean_absolute_error: 0.0115\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1157 - mean_absolute_error: 0.0113 - val_loss: 0.1155 - val_mean_absolute_error: 0.0110\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1153 - mean_absolute_error: 0.0109 - val_loss: 0.1152 - val_mean_absolute_error: 0.0105\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1150 - mean_absolute_error: 0.0105 - val_loss: 0.1149 - val_mean_absolute_error: 0.0106\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1148 - mean_absolute_error: 0.0100 - val_loss: 0.1148 - val_mean_absolute_error: 0.0109\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1146 - mean_absolute_error: 0.0098 - val_loss: 0.1145 - val_mean_absolute_error: 0.0095\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1144 - mean_absolute_error: 0.0095 - val_loss: 0.1143 - val_mean_absolute_error: 0.0095\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1142 - mean_absolute_error: 0.0094 - val_loss: 0.1142 - val_mean_absolute_error: 0.0093\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1141 - mean_absolute_error: 0.0092 - val_loss: 0.1140 - val_mean_absolute_error: 0.0091\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1140 - mean_absolute_error: 0.0091 - val_loss: 0.1139 - val_mean_absolute_error: 0.0090\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1139 - mean_absolute_error: 0.0089 - val_loss: 0.1138 - val_mean_absolute_error: 0.0089\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1138 - mean_absolute_error: 0.0088 - val_loss: 0.1138 - val_mean_absolute_error: 0.0089\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 110us/step - loss: 0.1137 - mean_absolute_error: 0.0087 - val_loss: 0.1136 - val_mean_absolute_error: 0.0086\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1135 - mean_absolute_error: 0.0085 - val_loss: 0.1134 - val_mean_absolute_error: 0.0083\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.3245 - mean_absolute_error: 0.1234 - val_loss: 0.2484 - val_mean_absolute_error: 0.0435\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.2399 - mean_absolute_error: 0.0307 - val_loss: 0.2359 - val_mean_absolute_error: 0.0248\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2347 - mean_absolute_error: 0.0233 - val_loss: 0.2338 - val_mean_absolute_error: 0.0223\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2331 - mean_absolute_error: 0.0217 - val_loss: 0.2320 - val_mean_absolute_error: 0.0210\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2309 - mean_absolute_error: 0.0193 - val_loss: 0.2299 - val_mean_absolute_error: 0.0184\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2292 - mean_absolute_error: 0.0171 - val_loss: 0.2285 - val_mean_absolute_error: 0.0163\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2281 - mean_absolute_error: 0.0160 - val_loss: 0.2276 - val_mean_absolute_error: 0.0158\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2272 - mean_absolute_error: 0.0152 - val_loss: 0.2267 - val_mean_absolute_error: 0.0145\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2264 - mean_absolute_error: 0.0143 - val_loss: 0.2261 - val_mean_absolute_error: 0.0140\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2260 - mean_absolute_error: 0.0139 - val_loss: 0.2259 - val_mean_absolute_error: 0.0137\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2257 - mean_absolute_error: 0.0136 - val_loss: 0.2256 - val_mean_absolute_error: 0.0131\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2255 - mean_absolute_error: 0.0131 - val_loss: 0.2254 - val_mean_absolute_error: 0.0128\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2254 - mean_absolute_error: 0.0129 - val_loss: 0.2253 - val_mean_absolute_error: 0.0127\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2253 - mean_absolute_error: 0.0128 - val_loss: 0.2253 - val_mean_absolute_error: 0.0127\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2253 - mean_absolute_error: 0.0127 - val_loss: 0.2252 - val_mean_absolute_error: 0.0126\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2252 - mean_absolute_error: 0.0127 - val_loss: 0.2252 - val_mean_absolute_error: 0.0127\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2252 - mean_absolute_error: 0.0127 - val_loss: 0.2252 - val_mean_absolute_error: 0.0129\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2252 - mean_absolute_error: 0.0127 - val_loss: 0.2252 - val_mean_absolute_error: 0.0129\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2251 - mean_absolute_error: 0.0127 - val_loss: 0.2253 - val_mean_absolute_error: 0.0129\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2251 - mean_absolute_error: 0.0127 - val_loss: 0.2250 - val_mean_absolute_error: 0.0126\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.1171 - mean_absolute_error: 0.0695 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 110us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.2961 - mean_absolute_error: 0.1283 - val_loss: 0.2359 - val_mean_absolute_error: 0.0755\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.2166 - mean_absolute_error: 0.0519 - val_loss: 0.2057 - val_mean_absolute_error: 0.0376\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.2001 - mean_absolute_error: 0.0312 - val_loss: 0.1962 - val_mean_absolute_error: 0.0270\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1941 - mean_absolute_error: 0.0246 - val_loss: 0.1919 - val_mean_absolute_error: 0.0221\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1899 - mean_absolute_error: 0.0196 - val_loss: 0.1883 - val_mean_absolute_error: 0.0175\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1873 - mean_absolute_error: 0.0161 - val_loss: 0.1865 - val_mean_absolute_error: 0.0151\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1859 - mean_absolute_error: 0.0140 - val_loss: 0.1853 - val_mean_absolute_error: 0.0132\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1849 - mean_absolute_error: 0.0125 - val_loss: 0.1845 - val_mean_absolute_error: 0.0119\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1843 - mean_absolute_error: 0.0115 - val_loss: 0.1840 - val_mean_absolute_error: 0.0112\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1839 - mean_absolute_error: 0.0108 - val_loss: 0.1837 - val_mean_absolute_error: 0.0106\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1836 - mean_absolute_error: 0.0104 - val_loss: 0.1835 - val_mean_absolute_error: 0.0103\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1835 - mean_absolute_error: 0.0102 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0101\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2953 - mean_absolute_error: 0.1108 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 111us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0783\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 112us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.3738 - mean_absolute_error: 0.1434 - val_loss: 0.3301 - val_mean_absolute_error: 0.1069\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.3176 - mean_absolute_error: 0.0949 - val_loss: 0.3079 - val_mean_absolute_error: 0.0859\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.3023 - mean_absolute_error: 0.0800 - val_loss: 0.2977 - val_mean_absolute_error: 0.0760\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2944 - mean_absolute_error: 0.0741 - val_loss: 0.2906 - val_mean_absolute_error: 0.0711\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2872 - mean_absolute_error: 0.0677 - val_loss: 0.2839 - val_mean_absolute_error: 0.0644\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2815 - mean_absolute_error: 0.0614 - val_loss: 0.2793 - val_mean_absolute_error: 0.0589\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2777 - mean_absolute_error: 0.0571 - val_loss: 0.2762 - val_mean_absolute_error: 0.0556\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2752 - mean_absolute_error: 0.0546 - val_loss: 0.2742 - val_mean_absolute_error: 0.0537\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2736 - mean_absolute_error: 0.0529 - val_loss: 0.2728 - val_mean_absolute_error: 0.0521\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2724 - mean_absolute_error: 0.0516 - val_loss: 0.2719 - val_mean_absolute_error: 0.0511\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2716 - mean_absolute_error: 0.0508 - val_loss: 0.2711 - val_mean_absolute_error: 0.0503\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2709 - mean_absolute_error: 0.0501 - val_loss: 0.2705 - val_mean_absolute_error: 0.0496\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2704 - mean_absolute_error: 0.0496 - val_loss: 0.2700 - val_mean_absolute_error: 0.0492\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2700 - mean_absolute_error: 0.0493 - val_loss: 0.2700 - val_mean_absolute_error: 0.0493\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2693 - val_mean_absolute_error: 0.0486\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2694 - mean_absolute_error: 0.0487 - val_loss: 0.2692 - val_mean_absolute_error: 0.0488\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2692 - mean_absolute_error: 0.0486 - val_loss: 0.2688 - val_mean_absolute_error: 0.0482\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2690 - mean_absolute_error: 0.0484 - val_loss: 0.2692 - val_mean_absolute_error: 0.0485\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2688 - mean_absolute_error: 0.0482 - val_loss: 0.2690 - val_mean_absolute_error: 0.0482\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2682 - val_mean_absolute_error: 0.0477\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_37 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.030480\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_1', 9, 46, 0, 46, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_38 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.039448\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_2', 8, 46, 1, 46, 0.8888888888888888, 1.0, 0.9787234042553191, 0.9893617021276595]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.050089\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_3', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_40 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.017555\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_4', 6, 49, 0, 49, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.032616\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_42 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023045\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_43 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028290\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.099508\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_45 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.069628\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[4, 'fam_9', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "[4, 0.7707231040564373, 1.0000000000000002, 0.9463434167993439, 0.973171708399672]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.4046 - mean_absolute_error: 0.1430 - val_loss: 0.3724 - val_mean_absolute_error: 0.1177\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.3492 - mean_absolute_error: 0.0991 - val_loss: 0.3245 - val_mean_absolute_error: 0.0770\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 6s 117us/step - loss: 0.3068 - mean_absolute_error: 0.0589 - val_loss: 0.2942 - val_mean_absolute_error: 0.0449\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 6s 117us/step - loss: 0.2891 - mean_absolute_error: 0.0384 - val_loss: 0.2853 - val_mean_absolute_error: 0.0330\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2828 - mean_absolute_error: 0.0291 - val_loss: 0.2803 - val_mean_absolute_error: 0.0246\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2785 - mean_absolute_error: 0.0220 - val_loss: 0.2769 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2759 - mean_absolute_error: 0.0182 - val_loss: 0.2750 - val_mean_absolute_error: 0.0168\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 117us/step - loss: 0.2744 - mean_absolute_error: 0.0154 - val_loss: 0.2737 - val_mean_absolute_error: 0.0137\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2735 - mean_absolute_error: 0.0135 - val_loss: 0.2731 - val_mean_absolute_error: 0.0126\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2730 - mean_absolute_error: 0.0122 - val_loss: 0.2730 - val_mean_absolute_error: 0.0124\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2727 - mean_absolute_error: 0.0114 - val_loss: 0.2727 - val_mean_absolute_error: 0.0114\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2726 - mean_absolute_error: 0.0108 - val_loss: 0.2725 - val_mean_absolute_error: 0.0108\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 6s 117us/step - loss: 0.2725 - mean_absolute_error: 0.0105 - val_loss: 0.2725 - val_mean_absolute_error: 0.0108\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2724 - mean_absolute_error: 0.0103 - val_loss: 0.2725 - val_mean_absolute_error: 0.0106\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2724 - mean_absolute_error: 0.0102 - val_loss: 0.2725 - val_mean_absolute_error: 0.0107\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2724 - mean_absolute_error: 0.0102 - val_loss: 0.2723 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2724 - mean_absolute_error: 0.0101 - val_loss: 0.2723 - val_mean_absolute_error: 0.0099\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 6s 116us/step - loss: 0.2724 - mean_absolute_error: 0.0101 - val_loss: 0.2724 - val_mean_absolute_error: 0.0102\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 6s 117us/step - loss: 0.2724 - mean_absolute_error: 0.0101 - val_loss: 0.2723 - val_mean_absolute_error: 0.0101\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 6s 117us/step - loss: 0.2724 - mean_absolute_error: 0.0101 - val_loss: 0.2723 - val_mean_absolute_error: 0.0103\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 7s 140us/step - loss: 0.2186 - mean_absolute_error: 0.0751 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0521\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0521\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0508\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 6s 117us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0504\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0505\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1931 - val_mean_absolute_error: 0.0507\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.2182 - mean_absolute_error: 0.0953 - val_loss: 0.1806 - val_mean_absolute_error: 0.0621\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0626\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0615\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0618\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1805 - val_mean_absolute_error: 0.0629\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0621\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0619\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0622\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1804 - val_mean_absolute_error: 0.0622\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1804 - val_mean_absolute_error: 0.0626\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0615\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 112us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0612\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1804 - val_mean_absolute_error: 0.0622\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0617\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 111us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1953 - mean_absolute_error: 0.0894 - val_loss: 0.1295 - val_mean_absolute_error: 0.0263\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1246 - mean_absolute_error: 0.0217 - val_loss: 0.1216 - val_mean_absolute_error: 0.0182\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1201 - mean_absolute_error: 0.0165 - val_loss: 0.1188 - val_mean_absolute_error: 0.0150\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1177 - mean_absolute_error: 0.0136 - val_loss: 0.1167 - val_mean_absolute_error: 0.0123\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1160 - mean_absolute_error: 0.0115 - val_loss: 0.1154 - val_mean_absolute_error: 0.0107\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1150 - mean_absolute_error: 0.0101 - val_loss: 0.1146 - val_mean_absolute_error: 0.0096\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1143 - mean_absolute_error: 0.0093 - val_loss: 0.1140 - val_mean_absolute_error: 0.0090\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1139 - mean_absolute_error: 0.0088 - val_loss: 0.1137 - val_mean_absolute_error: 0.0085\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1136 - mean_absolute_error: 0.0084 - val_loss: 0.1134 - val_mean_absolute_error: 0.0083\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1133 - mean_absolute_error: 0.0083 - val_loss: 0.1131 - val_mean_absolute_error: 0.0081\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1129 - mean_absolute_error: 0.0078 - val_loss: 0.1127 - val_mean_absolute_error: 0.0074\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1127 - mean_absolute_error: 0.0071 - val_loss: 0.1126 - val_mean_absolute_error: 0.0069\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1126 - mean_absolute_error: 0.0069 - val_loss: 0.1125 - val_mean_absolute_error: 0.0067\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 113us/step - loss: 0.1125 - mean_absolute_error: 0.0067 - val_loss: 0.1124 - val_mean_absolute_error: 0.0066\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1124 - mean_absolute_error: 0.0066 - val_loss: 0.1124 - val_mean_absolute_error: 0.0066\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1124 - mean_absolute_error: 0.0066 - val_loss: 0.1123 - val_mean_absolute_error: 0.0065\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1124 - mean_absolute_error: 0.0065 - val_loss: 0.1123 - val_mean_absolute_error: 0.0065\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1124 - mean_absolute_error: 0.0065 - val_loss: 0.1123 - val_mean_absolute_error: 0.0064\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1123 - mean_absolute_error: 0.0065 - val_loss: 0.1123 - val_mean_absolute_error: 0.0065\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1123 - mean_absolute_error: 0.0064 - val_loss: 0.1123 - val_mean_absolute_error: 0.0064\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_50 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.3241 - mean_absolute_error: 0.1232 - val_loss: 0.2481 - val_mean_absolute_error: 0.0433\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2398 - mean_absolute_error: 0.0306 - val_loss: 0.2358 - val_mean_absolute_error: 0.0246\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2344 - mean_absolute_error: 0.0232 - val_loss: 0.2329 - val_mean_absolute_error: 0.0216\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2322 - mean_absolute_error: 0.0206 - val_loss: 0.2316 - val_mean_absolute_error: 0.0200\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2312 - mean_absolute_error: 0.0196 - val_loss: 0.2309 - val_mean_absolute_error: 0.0194\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2307 - mean_absolute_error: 0.0191 - val_loss: 0.2305 - val_mean_absolute_error: 0.0189\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2305 - mean_absolute_error: 0.0189 - val_loss: 0.2303 - val_mean_absolute_error: 0.0188\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2303 - mean_absolute_error: 0.0188 - val_loss: 0.2300 - val_mean_absolute_error: 0.0185\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.2293 - mean_absolute_error: 0.0179 - val_loss: 0.2287 - val_mean_absolute_error: 0.0169\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2282 - mean_absolute_error: 0.0168 - val_loss: 0.2277 - val_mean_absolute_error: 0.0164\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2273 - mean_absolute_error: 0.0156 - val_loss: 0.2270 - val_mean_absolute_error: 0.0152\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2265 - mean_absolute_error: 0.0146 - val_loss: 0.2261 - val_mean_absolute_error: 0.0139\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2259 - mean_absolute_error: 0.0135 - val_loss: 0.2256 - val_mean_absolute_error: 0.0132\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2255 - mean_absolute_error: 0.0130 - val_loss: 0.2254 - val_mean_absolute_error: 0.0127\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2254 - mean_absolute_error: 0.0127 - val_loss: 0.2253 - val_mean_absolute_error: 0.0126\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2252 - val_mean_absolute_error: 0.0123\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2251 - val_mean_absolute_error: 0.0122\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0127\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2251 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0127\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2251 - mean_absolute_error: 0.0124 - val_loss: 0.2250 - val_mean_absolute_error: 0.0122\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.1174 - mean_absolute_error: 0.0697 - val_loss: 0.0598 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 113us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_52 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.2943 - mean_absolute_error: 0.1288 - val_loss: 0.2299 - val_mean_absolute_error: 0.0740\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.2119 - mean_absolute_error: 0.0537 - val_loss: 0.2008 - val_mean_absolute_error: 0.0391\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1959 - mean_absolute_error: 0.0303 - val_loss: 0.1920 - val_mean_absolute_error: 0.0233\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1896 - mean_absolute_error: 0.0195 - val_loss: 0.1876 - val_mean_absolute_error: 0.0165\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1863 - mean_absolute_error: 0.0145 - val_loss: 0.1851 - val_mean_absolute_error: 0.0129\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1845 - mean_absolute_error: 0.0119 - val_loss: 0.1840 - val_mean_absolute_error: 0.0111\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1838 - mean_absolute_error: 0.0107 - val_loss: 0.1836 - val_mean_absolute_error: 0.0104\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1835 - mean_absolute_error: 0.0102 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1834 - mean_absolute_error: 0.0101 - val_loss: 0.1833 - val_mean_absolute_error: 0.0101\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1833 - mean_absolute_error: 0.0101 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1833 - mean_absolute_error: 0.0101 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1832 - mean_absolute_error: 0.0102 - val_loss: 0.1832 - val_mean_absolute_error: 0.0101\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1832 - mean_absolute_error: 0.0102 - val_loss: 0.1831 - val_mean_absolute_error: 0.0103\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1832 - mean_absolute_error: 0.0103 - val_loss: 0.1831 - val_mean_absolute_error: 0.0105\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1831 - mean_absolute_error: 0.0103 - val_loss: 0.1830 - val_mean_absolute_error: 0.0105\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1830 - mean_absolute_error: 0.0103 - val_loss: 0.1830 - val_mean_absolute_error: 0.0104\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 114us/step - loss: 0.1829 - mean_absolute_error: 0.0102 - val_loss: 0.1829 - val_mean_absolute_error: 0.0103\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1829 - mean_absolute_error: 0.0100 - val_loss: 0.1828 - val_mean_absolute_error: 0.0097\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_53 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2953 - mean_absolute_error: 0.1108 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0778\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0776\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0777\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0793\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0795\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 114us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 115us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0781\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_54 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.3746 - mean_absolute_error: 0.1438 - val_loss: 0.3307 - val_mean_absolute_error: 0.1073\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.3181 - mean_absolute_error: 0.0954 - val_loss: 0.3084 - val_mean_absolute_error: 0.0859\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.3026 - mean_absolute_error: 0.0804 - val_loss: 0.2980 - val_mean_absolute_error: 0.0768\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2946 - mean_absolute_error: 0.0742 - val_loss: 0.2909 - val_mean_absolute_error: 0.0715\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2873 - mean_absolute_error: 0.0680 - val_loss: 0.2841 - val_mean_absolute_error: 0.0641\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2815 - mean_absolute_error: 0.0614 - val_loss: 0.2793 - val_mean_absolute_error: 0.0589\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2777 - mean_absolute_error: 0.0571 - val_loss: 0.2766 - val_mean_absolute_error: 0.0562\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2752 - mean_absolute_error: 0.0545 - val_loss: 0.2745 - val_mean_absolute_error: 0.0536\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2735 - mean_absolute_error: 0.0528 - val_loss: 0.2729 - val_mean_absolute_error: 0.0521\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2724 - mean_absolute_error: 0.0516 - val_loss: 0.2719 - val_mean_absolute_error: 0.0510\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.2716 - mean_absolute_error: 0.0507 - val_loss: 0.2712 - val_mean_absolute_error: 0.0503\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2709 - mean_absolute_error: 0.0501 - val_loss: 0.2706 - val_mean_absolute_error: 0.0498\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2704 - mean_absolute_error: 0.0496 - val_loss: 0.2704 - val_mean_absolute_error: 0.0496\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2700 - mean_absolute_error: 0.0493 - val_loss: 0.2697 - val_mean_absolute_error: 0.0488\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2697 - val_mean_absolute_error: 0.0491\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2694 - mean_absolute_error: 0.0488 - val_loss: 0.2690 - val_mean_absolute_error: 0.0484\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2692 - mean_absolute_error: 0.0485 - val_loss: 0.2688 - val_mean_absolute_error: 0.0481\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2690 - mean_absolute_error: 0.0484 - val_loss: 0.2708 - val_mean_absolute_error: 0.0495\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2688 - mean_absolute_error: 0.0482 - val_loss: 0.2692 - val_mean_absolute_error: 0.0484\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2683 - val_mean_absolute_error: 0.0478\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_46 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.018534\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_1', 9, 46, 0, 46, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.141316\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_48 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.087733\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_3', 6, 30, 19, 30, 0.24, 1.0, 0.6122448979591837, 0.8061224489795918]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_49 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.018793\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_4', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_50 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.029988\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_51 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023114\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_52 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.027887\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_53 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.099852\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_54 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.068308\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[5, 'fam_9', 5, 42, 8, 42, 0.38461538461538464, 1.0, 0.84, 0.9199999999999999]\n",
      "[5, 0.6145897545897545, 1.0000000000000002, 0.8392878853669128, 0.9196439426834564]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_55 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 8s 141us/step - loss: 0.4190 - mean_absolute_error: 0.1524 - val_loss: 0.4021 - val_mean_absolute_error: 0.1368\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 6s 118us/step - loss: 0.3831 - mean_absolute_error: 0.1250 - val_loss: 0.3633 - val_mean_absolute_error: 0.1095\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 6s 118us/step - loss: 0.3447 - mean_absolute_error: 0.0939 - val_loss: 0.3299 - val_mean_absolute_error: 0.0793\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.3213 - mean_absolute_error: 0.0719 - val_loss: 0.3147 - val_mean_absolute_error: 0.0663\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.3103 - mean_absolute_error: 0.0619 - val_loss: 0.3061 - val_mean_absolute_error: 0.0579\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.3037 - mean_absolute_error: 0.0551 - val_loss: 0.3008 - val_mean_absolute_error: 0.0520\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2992 - mean_absolute_error: 0.0499 - val_loss: 0.2977 - val_mean_absolute_error: 0.0482\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2960 - mean_absolute_error: 0.0460 - val_loss: 0.2945 - val_mean_absolute_error: 0.0445\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2936 - mean_absolute_error: 0.0430 - val_loss: 0.2930 - val_mean_absolute_error: 0.0419\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2921 - mean_absolute_error: 0.0407 - val_loss: 0.2914 - val_mean_absolute_error: 0.0399\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2913 - mean_absolute_error: 0.0394 - val_loss: 0.2908 - val_mean_absolute_error: 0.0389\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2907 - mean_absolute_error: 0.0386 - val_loss: 0.2903 - val_mean_absolute_error: 0.0384\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 6s 120us/step - loss: 0.2904 - mean_absolute_error: 0.0382 - val_loss: 0.2900 - val_mean_absolute_error: 0.0377\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2901 - mean_absolute_error: 0.0379 - val_loss: 0.2905 - val_mean_absolute_error: 0.0383\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2899 - mean_absolute_error: 0.0376 - val_loss: 0.2900 - val_mean_absolute_error: 0.0377\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2897 - mean_absolute_error: 0.0375 - val_loss: 0.2893 - val_mean_absolute_error: 0.0371\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2896 - mean_absolute_error: 0.0374 - val_loss: 0.2893 - val_mean_absolute_error: 0.0375\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2895 - mean_absolute_error: 0.0373 - val_loss: 0.2891 - val_mean_absolute_error: 0.0370\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2894 - mean_absolute_error: 0.0372 - val_loss: 0.2890 - val_mean_absolute_error: 0.0366\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.2893 - mean_absolute_error: 0.0371 - val_loss: 0.2890 - val_mean_absolute_error: 0.0369\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 7s 143us/step - loss: 0.2187 - mean_absolute_error: 0.0752 - val_loss: 0.1930 - val_mean_absolute_error: 0.0508\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 6s 116us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0535\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 6s 116us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0506\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0521\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0533\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0536\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0505\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 6s 116us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0531\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_57 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 151us/step - loss: 0.2182 - mean_absolute_error: 0.0952 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0626\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 118us/step - loss: 0.1775 - mean_absolute_error: 0.0602 - val_loss: 0.1727 - val_mean_absolute_error: 0.0566\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1684 - mean_absolute_error: 0.0536 - val_loss: 0.1643 - val_mean_absolute_error: 0.0500\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1611 - mean_absolute_error: 0.0477 - val_loss: 0.1582 - val_mean_absolute_error: 0.0450\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1559 - mean_absolute_error: 0.0432 - val_loss: 0.1538 - val_mean_absolute_error: 0.0413\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1522 - mean_absolute_error: 0.0394 - val_loss: 0.1507 - val_mean_absolute_error: 0.0377\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1496 - mean_absolute_error: 0.0366 - val_loss: 0.1486 - val_mean_absolute_error: 0.0357\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1478 - mean_absolute_error: 0.0350 - val_loss: 0.1470 - val_mean_absolute_error: 0.0344\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1465 - mean_absolute_error: 0.0340 - val_loss: 0.1461 - val_mean_absolute_error: 0.0333\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1457 - mean_absolute_error: 0.0332 - val_loss: 0.1453 - val_mean_absolute_error: 0.0329\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1451 - mean_absolute_error: 0.0326 - val_loss: 0.1449 - val_mean_absolute_error: 0.0326\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1447 - mean_absolute_error: 0.0321 - val_loss: 0.1445 - val_mean_absolute_error: 0.0315\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1443 - mean_absolute_error: 0.0318 - val_loss: 0.1442 - val_mean_absolute_error: 0.0316\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1440 - mean_absolute_error: 0.0314 - val_loss: 0.1438 - val_mean_absolute_error: 0.0310\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1437 - mean_absolute_error: 0.0311 - val_loss: 0.1436 - val_mean_absolute_error: 0.0311\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1435 - mean_absolute_error: 0.0308 - val_loss: 0.1434 - val_mean_absolute_error: 0.0310\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1433 - mean_absolute_error: 0.0306 - val_loss: 0.1436 - val_mean_absolute_error: 0.0312\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1431 - mean_absolute_error: 0.0304 - val_loss: 0.1429 - val_mean_absolute_error: 0.0301\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1429 - mean_absolute_error: 0.0302 - val_loss: 0.1428 - val_mean_absolute_error: 0.0304\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_58 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 5s 152us/step - loss: 0.1939 - mean_absolute_error: 0.0874 - val_loss: 0.1268 - val_mean_absolute_error: 0.0234\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1232 - mean_absolute_error: 0.0195 - val_loss: 0.1210 - val_mean_absolute_error: 0.0173\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1199 - mean_absolute_error: 0.0161 - val_loss: 0.1190 - val_mean_absolute_error: 0.0153\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1184 - mean_absolute_error: 0.0146 - val_loss: 0.1179 - val_mean_absolute_error: 0.0140\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1173 - mean_absolute_error: 0.0135 - val_loss: 0.1169 - val_mean_absolute_error: 0.0129\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1165 - mean_absolute_error: 0.0124 - val_loss: 0.1162 - val_mean_absolute_error: 0.0120\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1160 - mean_absolute_error: 0.0116 - val_loss: 0.1158 - val_mean_absolute_error: 0.0114\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1156 - mean_absolute_error: 0.0110 - val_loss: 0.1154 - val_mean_absolute_error: 0.0108\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1153 - mean_absolute_error: 0.0106 - val_loss: 0.1151 - val_mean_absolute_error: 0.0105\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1150 - mean_absolute_error: 0.0104 - val_loss: 0.1149 - val_mean_absolute_error: 0.0102\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1148 - mean_absolute_error: 0.0102 - val_loss: 0.1147 - val_mean_absolute_error: 0.0101\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1146 - mean_absolute_error: 0.0097 - val_loss: 0.1145 - val_mean_absolute_error: 0.0095\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1144 - mean_absolute_error: 0.0094 - val_loss: 0.1144 - val_mean_absolute_error: 0.0093\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1143 - mean_absolute_error: 0.0092 - val_loss: 0.1143 - val_mean_absolute_error: 0.0092\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 115us/step - loss: 0.1142 - mean_absolute_error: 0.0091 - val_loss: 0.1142 - val_mean_absolute_error: 0.0091\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1141 - mean_absolute_error: 0.0090 - val_loss: 0.1141 - val_mean_absolute_error: 0.0090\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1140 - mean_absolute_error: 0.0090 - val_loss: 0.1140 - val_mean_absolute_error: 0.0090\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1139 - mean_absolute_error: 0.0089 - val_loss: 0.1139 - val_mean_absolute_error: 0.0089\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1139 - mean_absolute_error: 0.0088 - val_loss: 0.1139 - val_mean_absolute_error: 0.0088\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 116us/step - loss: 0.1138 - mean_absolute_error: 0.0088 - val_loss: 0.1138 - val_mean_absolute_error: 0.0088\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_59 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.3245 - mean_absolute_error: 0.1234 - val_loss: 0.2480 - val_mean_absolute_error: 0.0433\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2397 - mean_absolute_error: 0.0304 - val_loss: 0.2358 - val_mean_absolute_error: 0.0248\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2347 - mean_absolute_error: 0.0232 - val_loss: 0.2338 - val_mean_absolute_error: 0.0223\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2332 - mean_absolute_error: 0.0217 - val_loss: 0.2327 - val_mean_absolute_error: 0.0212\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2323 - mean_absolute_error: 0.0209 - val_loss: 0.2320 - val_mean_absolute_error: 0.0205\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2317 - mean_absolute_error: 0.0203 - val_loss: 0.2315 - val_mean_absolute_error: 0.0200\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2308 - mean_absolute_error: 0.0193 - val_loss: 0.2300 - val_mean_absolute_error: 0.0185\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2293 - mean_absolute_error: 0.0178 - val_loss: 0.2287 - val_mean_absolute_error: 0.0170\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2283 - mean_absolute_error: 0.0169 - val_loss: 0.2281 - val_mean_absolute_error: 0.0177\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2274 - mean_absolute_error: 0.0162 - val_loss: 0.2271 - val_mean_absolute_error: 0.0159\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2267 - mean_absolute_error: 0.0149 - val_loss: 0.2264 - val_mean_absolute_error: 0.0142\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2262 - mean_absolute_error: 0.0138 - val_loss: 0.2260 - val_mean_absolute_error: 0.0133\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2259 - mean_absolute_error: 0.0132 - val_loss: 0.2257 - val_mean_absolute_error: 0.0130\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2256 - mean_absolute_error: 0.0129 - val_loss: 0.2256 - val_mean_absolute_error: 0.0127\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2255 - mean_absolute_error: 0.0127 - val_loss: 0.2255 - val_mean_absolute_error: 0.0130\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2254 - mean_absolute_error: 0.0126 - val_loss: 0.2254 - val_mean_absolute_error: 0.0124\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2253 - val_mean_absolute_error: 0.0125\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2253 - mean_absolute_error: 0.0124 - val_loss: 0.2253 - val_mean_absolute_error: 0.0124\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2253 - val_mean_absolute_error: 0.0125\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0125\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.1176 - mean_absolute_error: 0.0699 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0200\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 3s 116us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 3s 117us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_61 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 6s 154us/step - loss: 0.2921 - mean_absolute_error: 0.1256 - val_loss: 0.2302 - val_mean_absolute_error: 0.0700\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.2154 - mean_absolute_error: 0.0507 - val_loss: 0.2058 - val_mean_absolute_error: 0.0377\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.2007 - mean_absolute_error: 0.0322 - val_loss: 0.1966 - val_mean_absolute_error: 0.0278\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1941 - mean_absolute_error: 0.0253 - val_loss: 0.1920 - val_mean_absolute_error: 0.0232\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 118us/step - loss: 0.1907 - mean_absolute_error: 0.0217 - val_loss: 0.1896 - val_mean_absolute_error: 0.0203\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 118us/step - loss: 0.1889 - mean_absolute_error: 0.0192 - val_loss: 0.1882 - val_mean_absolute_error: 0.0183\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1877 - mean_absolute_error: 0.0175 - val_loss: 0.1872 - val_mean_absolute_error: 0.0168\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1869 - mean_absolute_error: 0.0162 - val_loss: 0.1865 - val_mean_absolute_error: 0.0158\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1863 - mean_absolute_error: 0.0152 - val_loss: 0.1860 - val_mean_absolute_error: 0.0149\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1858 - mean_absolute_error: 0.0144 - val_loss: 0.1856 - val_mean_absolute_error: 0.0141\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1854 - mean_absolute_error: 0.0138 - val_loss: 0.1852 - val_mean_absolute_error: 0.0134\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1851 - mean_absolute_error: 0.0132 - val_loss: 0.1850 - val_mean_absolute_error: 0.0131\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1849 - mean_absolute_error: 0.0127 - val_loss: 0.1847 - val_mean_absolute_error: 0.0125\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1846 - mean_absolute_error: 0.0123 - val_loss: 0.1844 - val_mean_absolute_error: 0.0120\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1844 - mean_absolute_error: 0.0118 - val_loss: 0.1842 - val_mean_absolute_error: 0.0116\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1842 - mean_absolute_error: 0.0115 - val_loss: 0.1841 - val_mean_absolute_error: 0.0113\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1840 - mean_absolute_error: 0.0111 - val_loss: 0.1839 - val_mean_absolute_error: 0.0110\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 117us/step - loss: 0.1839 - mean_absolute_error: 0.0109 - val_loss: 0.1838 - val_mean_absolute_error: 0.0108\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 118us/step - loss: 0.1838 - mean_absolute_error: 0.0107 - val_loss: 0.1837 - val_mean_absolute_error: 0.0107\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 118us/step - loss: 0.1837 - mean_absolute_error: 0.0106 - val_loss: 0.1837 - val_mean_absolute_error: 0.0107\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_62 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2954 - mean_absolute_error: 0.1109 - val_loss: 0.2596 - val_mean_absolute_error: 0.0794\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0794\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0789\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 117us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0779\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0792\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 118us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_63 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.3744 - mean_absolute_error: 0.1437 - val_loss: 0.3273 - val_mean_absolute_error: 0.1037\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.3130 - mean_absolute_error: 0.0903 - val_loss: 0.3029 - val_mean_absolute_error: 0.0812\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.2968 - mean_absolute_error: 0.0756 - val_loss: 0.2914 - val_mean_absolute_error: 0.0707\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2874 - mean_absolute_error: 0.0667 - val_loss: 0.2839 - val_mean_absolute_error: 0.0630\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2813 - mean_absolute_error: 0.0603 - val_loss: 0.2791 - val_mean_absolute_error: 0.0581\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.2775 - mean_absolute_error: 0.0565 - val_loss: 0.2761 - val_mean_absolute_error: 0.0553\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2750 - mean_absolute_error: 0.0542 - val_loss: 0.2740 - val_mean_absolute_error: 0.0533\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2733 - mean_absolute_error: 0.0526 - val_loss: 0.2726 - val_mean_absolute_error: 0.0517\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2721 - mean_absolute_error: 0.0516 - val_loss: 0.2716 - val_mean_absolute_error: 0.0511\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2711 - mean_absolute_error: 0.0509 - val_loss: 0.2709 - val_mean_absolute_error: 0.0503\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2702 - mean_absolute_error: 0.0504 - val_loss: 0.2702 - val_mean_absolute_error: 0.0499\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2689 - mean_absolute_error: 0.0500 - val_loss: 0.2685 - val_mean_absolute_error: 0.0524\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2669 - mean_absolute_error: 0.0491 - val_loss: 0.2653 - val_mean_absolute_error: 0.0472\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2636 - mean_absolute_error: 0.0463 - val_loss: 0.2620 - val_mean_absolute_error: 0.0450\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2599 - mean_absolute_error: 0.0414 - val_loss: 0.2583 - val_mean_absolute_error: 0.0385\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2572 - mean_absolute_error: 0.0364 - val_loss: 0.2563 - val_mean_absolute_error: 0.0347\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2557 - mean_absolute_error: 0.0337 - val_loss: 0.2553 - val_mean_absolute_error: 0.0331\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2549 - mean_absolute_error: 0.0327 - val_loss: 0.2547 - val_mean_absolute_error: 0.0323\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2545 - mean_absolute_error: 0.0320 - val_loss: 0.2543 - val_mean_absolute_error: 0.0318\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2542 - mean_absolute_error: 0.0316 - val_loss: 0.2541 - val_mean_absolute_error: 0.0314\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_55 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.064068\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_1', 9, 44, 2, 44, 0.8181818181818182, 1.0, 0.9565217391304348, 0.9782608695652174]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.140569\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_57 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.040186\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_3', 6, 43, 6, 43, 0.5, 1.0, 0.8775510204081632, 0.9387755102040816]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_58 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.018952\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_4', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_59 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.037310\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_5', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023148\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_61 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028966\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_62 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100633\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_63 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_125 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.045484\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[6, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[6, 0.6731341731341731, 1.0000000000000002, 0.8794909810979588, 0.9397454905489795]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_64 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 8s 147us/step - loss: 0.4194 - mean_absolute_error: 0.1526 - val_loss: 0.4079 - val_mean_absolute_error: 0.1418\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1425\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1414\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.4080 - mean_absolute_error: 0.1415 - val_loss: 0.4079 - val_mean_absolute_error: 0.1428\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 6s 120us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1419\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 6s 119us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1418\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 6s 120us/step - loss: 0.4079 - mean_absolute_error: 0.1415 - val_loss: 0.4061 - val_mean_absolute_error: 0.1402\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 7s 120us/step - loss: 0.3903 - mean_absolute_error: 0.1301 - val_loss: 0.3770 - val_mean_absolute_error: 0.1207\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 7s 120us/step - loss: 0.3671 - mean_absolute_error: 0.1137 - val_loss: 0.3586 - val_mean_absolute_error: 0.1062\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 7s 121us/step - loss: 0.3478 - mean_absolute_error: 0.0976 - val_loss: 0.3345 - val_mean_absolute_error: 0.0859\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.3262 - mean_absolute_error: 0.0783 - val_loss: 0.3193 - val_mean_absolute_error: 0.0723\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.3159 - mean_absolute_error: 0.0692 - val_loss: 0.3136 - val_mean_absolute_error: 0.0670\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.3113 - mean_absolute_error: 0.0646 - val_loss: 0.3117 - val_mean_absolute_error: 0.0639\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.3078 - mean_absolute_error: 0.0608 - val_loss: 0.3038 - val_mean_absolute_error: 0.0561\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.3012 - mean_absolute_error: 0.0536 - val_loss: 0.2993 - val_mean_absolute_error: 0.0520\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.2978 - mean_absolute_error: 0.0495 - val_loss: 0.2963 - val_mean_absolute_error: 0.0483\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.2960 - mean_absolute_error: 0.0472 - val_loss: 0.2948 - val_mean_absolute_error: 0.0462\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.2947 - mean_absolute_error: 0.0456 - val_loss: 0.2947 - val_mean_absolute_error: 0.0464\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.2936 - mean_absolute_error: 0.0442 - val_loss: 0.2928 - val_mean_absolute_error: 0.0434\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_65 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 7s 150us/step - loss: 0.2186 - mean_absolute_error: 0.0751 - val_loss: 0.1931 - val_mean_absolute_error: 0.0507\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0508\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 6s 124us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0504\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 6s 123us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0527\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 6s 118us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 6s 117us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1931 - val_mean_absolute_error: 0.0509\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1932 - val_mean_absolute_error: 0.0499\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1930 - mean_absolute_error: 0.0516 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 6s 119us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0504\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 6s 123us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0508\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1902 - mean_absolute_error: 0.0508 - val_loss: 0.1848 - val_mean_absolute_error: 0.0485\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1796 - mean_absolute_error: 0.0469 - val_loss: 0.1745 - val_mean_absolute_error: 0.0445\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 6s 119us/step - loss: 0.1703 - mean_absolute_error: 0.0421 - val_loss: 0.1662 - val_mean_absolute_error: 0.0397\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 6s 119us/step - loss: 0.1629 - mean_absolute_error: 0.0371 - val_loss: 0.1598 - val_mean_absolute_error: 0.0343\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1574 - mean_absolute_error: 0.0323 - val_loss: 0.1553 - val_mean_absolute_error: 0.0305\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1536 - mean_absolute_error: 0.0283 - val_loss: 0.1522 - val_mean_absolute_error: 0.0266\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1511 - mean_absolute_error: 0.0252 - val_loss: 0.1502 - val_mean_absolute_error: 0.0241\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_66 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.2180 - mean_absolute_error: 0.0951 - val_loss: 0.1805 - val_mean_absolute_error: 0.0622\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0629\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1779 - mean_absolute_error: 0.0605 - val_loss: 0.1733 - val_mean_absolute_error: 0.0577\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1688 - mean_absolute_error: 0.0539 - val_loss: 0.1648 - val_mean_absolute_error: 0.0503\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1615 - mean_absolute_error: 0.0480 - val_loss: 0.1585 - val_mean_absolute_error: 0.0457\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1562 - mean_absolute_error: 0.0434 - val_loss: 0.1541 - val_mean_absolute_error: 0.0412\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1524 - mean_absolute_error: 0.0396 - val_loss: 0.1508 - val_mean_absolute_error: 0.0379\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1497 - mean_absolute_error: 0.0368 - val_loss: 0.1487 - val_mean_absolute_error: 0.0355\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1478 - mean_absolute_error: 0.0351 - val_loss: 0.1472 - val_mean_absolute_error: 0.0343\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1466 - mean_absolute_error: 0.0340 - val_loss: 0.1462 - val_mean_absolute_error: 0.0333\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1458 - mean_absolute_error: 0.0332 - val_loss: 0.1454 - val_mean_absolute_error: 0.0327\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1452 - mean_absolute_error: 0.0326 - val_loss: 0.1450 - val_mean_absolute_error: 0.0322\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1447 - mean_absolute_error: 0.0322 - val_loss: 0.1445 - val_mean_absolute_error: 0.0321\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1443 - mean_absolute_error: 0.0318 - val_loss: 0.1446 - val_mean_absolute_error: 0.0316\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1440 - mean_absolute_error: 0.0314 - val_loss: 0.1438 - val_mean_absolute_error: 0.0311\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1437 - mean_absolute_error: 0.0311 - val_loss: 0.1436 - val_mean_absolute_error: 0.0311\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1435 - mean_absolute_error: 0.0308 - val_loss: 0.1433 - val_mean_absolute_error: 0.0306\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1433 - mean_absolute_error: 0.0306 - val_loss: 0.1435 - val_mean_absolute_error: 0.0305\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1431 - mean_absolute_error: 0.0304 - val_loss: 0.1430 - val_mean_absolute_error: 0.0301\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1429 - mean_absolute_error: 0.0302 - val_loss: 0.1428 - val_mean_absolute_error: 0.0302\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_67 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1941 - mean_absolute_error: 0.0880 - val_loss: 0.1285 - val_mean_absolute_error: 0.0255\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1247 - mean_absolute_error: 0.0214 - val_loss: 0.1224 - val_mean_absolute_error: 0.0187\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1212 - mean_absolute_error: 0.0175 - val_loss: 0.1203 - val_mean_absolute_error: 0.0165\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1197 - mean_absolute_error: 0.0156 - val_loss: 0.1192 - val_mean_absolute_error: 0.0151\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1188 - mean_absolute_error: 0.0147 - val_loss: 0.1183 - val_mean_absolute_error: 0.0143\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1176 - mean_absolute_error: 0.0135 - val_loss: 0.1169 - val_mean_absolute_error: 0.0126\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1164 - mean_absolute_error: 0.0121 - val_loss: 0.1160 - val_mean_absolute_error: 0.0118\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1156 - mean_absolute_error: 0.0111 - val_loss: 0.1154 - val_mean_absolute_error: 0.0113\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1151 - mean_absolute_error: 0.0105 - val_loss: 0.1149 - val_mean_absolute_error: 0.0102\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1148 - mean_absolute_error: 0.0099 - val_loss: 0.1147 - val_mean_absolute_error: 0.0099\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1145 - mean_absolute_error: 0.0095 - val_loss: 0.1144 - val_mean_absolute_error: 0.0093\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1144 - mean_absolute_error: 0.0093 - val_loss: 0.1143 - val_mean_absolute_error: 0.0091\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1143 - mean_absolute_error: 0.0091 - val_loss: 0.1142 - val_mean_absolute_error: 0.0089\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1141 - val_mean_absolute_error: 0.0088\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1141 - mean_absolute_error: 0.0087 - val_loss: 0.1141 - val_mean_absolute_error: 0.0086\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1141 - mean_absolute_error: 0.0086 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1140 - mean_absolute_error: 0.0085 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1140 - mean_absolute_error: 0.0085 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1140 - mean_absolute_error: 0.0085 - val_loss: 0.1139 - val_mean_absolute_error: 0.0084\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 119us/step - loss: 0.1139 - mean_absolute_error: 0.0084 - val_loss: 0.1139 - val_mean_absolute_error: 0.0084\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.3268 - mean_absolute_error: 0.1271 - val_loss: 0.2504 - val_mean_absolute_error: 0.0473\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2413 - mean_absolute_error: 0.0333 - val_loss: 0.2366 - val_mean_absolute_error: 0.0261\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2352 - mean_absolute_error: 0.0245 - val_loss: 0.2341 - val_mean_absolute_error: 0.0230\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2334 - mean_absolute_error: 0.0222 - val_loss: 0.2323 - val_mean_absolute_error: 0.0211\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2313 - mean_absolute_error: 0.0199 - val_loss: 0.2303 - val_mean_absolute_error: 0.0187\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2297 - mean_absolute_error: 0.0181 - val_loss: 0.2289 - val_mean_absolute_error: 0.0171\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2281 - mean_absolute_error: 0.0163 - val_loss: 0.2273 - val_mean_absolute_error: 0.0153\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2268 - mean_absolute_error: 0.0145 - val_loss: 0.2264 - val_mean_absolute_error: 0.0140\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2262 - mean_absolute_error: 0.0136 - val_loss: 0.2260 - val_mean_absolute_error: 0.0135\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2259 - mean_absolute_error: 0.0133 - val_loss: 0.2258 - val_mean_absolute_error: 0.0132\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2258 - mean_absolute_error: 0.0132 - val_loss: 0.2258 - val_mean_absolute_error: 0.0130\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2257 - mean_absolute_error: 0.0132 - val_loss: 0.2255 - val_mean_absolute_error: 0.0130\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2255 - mean_absolute_error: 0.0130 - val_loss: 0.2255 - val_mean_absolute_error: 0.0130\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2254 - mean_absolute_error: 0.0126 - val_loss: 0.2253 - val_mean_absolute_error: 0.0125\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2253 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0123\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2251 - val_mean_absolute_error: 0.0126\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2251 - mean_absolute_error: 0.0124 - val_loss: 0.2251 - val_mean_absolute_error: 0.0125\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2251 - mean_absolute_error: 0.0125 - val_loss: 0.2250 - val_mean_absolute_error: 0.0125\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2250 - mean_absolute_error: 0.0125 - val_loss: 0.2249 - val_mean_absolute_error: 0.0124\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2249 - mean_absolute_error: 0.0125 - val_loss: 0.2249 - val_mean_absolute_error: 0.0126\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.1173 - mean_absolute_error: 0.0697 - val_loss: 0.0598 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 119us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 120us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 121us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_70 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.2847 - mean_absolute_error: 0.1186 - val_loss: 0.2163 - val_mean_absolute_error: 0.0536\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.2063 - mean_absolute_error: 0.0396 - val_loss: 0.1998 - val_mean_absolute_error: 0.0317\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1967 - mean_absolute_error: 0.0282 - val_loss: 0.1946 - val_mean_absolute_error: 0.0257\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1933 - mean_absolute_error: 0.0241 - val_loss: 0.1923 - val_mean_absolute_error: 0.0229\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1913 - mean_absolute_error: 0.0215 - val_loss: 0.1899 - val_mean_absolute_error: 0.0197\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1887 - mean_absolute_error: 0.0184 - val_loss: 0.1878 - val_mean_absolute_error: 0.0171\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1871 - mean_absolute_error: 0.0163 - val_loss: 0.1865 - val_mean_absolute_error: 0.0155\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1860 - mean_absolute_error: 0.0148 - val_loss: 0.1855 - val_mean_absolute_error: 0.0139\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1850 - mean_absolute_error: 0.0131 - val_loss: 0.1847 - val_mean_absolute_error: 0.0124\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1844 - mean_absolute_error: 0.0121 - val_loss: 0.1842 - val_mean_absolute_error: 0.0116\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1840 - mean_absolute_error: 0.0115 - val_loss: 0.1839 - val_mean_absolute_error: 0.0114\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1838 - mean_absolute_error: 0.0112 - val_loss: 0.1837 - val_mean_absolute_error: 0.0109\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1836 - mean_absolute_error: 0.0108 - val_loss: 0.1835 - val_mean_absolute_error: 0.0106\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1834 - mean_absolute_error: 0.0102 - val_loss: 0.1833 - val_mean_absolute_error: 0.0102\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0098\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1831 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0102\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 120us/step - loss: 0.1831 - mean_absolute_error: 0.0098 - val_loss: 0.1831 - val_mean_absolute_error: 0.0098\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1831 - mean_absolute_error: 0.0098 - val_loss: 0.1831 - val_mean_absolute_error: 0.0097\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1830 - mean_absolute_error: 0.0098 - val_loss: 0.1831 - val_mean_absolute_error: 0.0097\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_71 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.2952 - mean_absolute_error: 0.1107 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0789\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0789\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0779\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0781\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0792\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0787\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_72 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.3764 - mean_absolute_error: 0.1453 - val_loss: 0.3331 - val_mean_absolute_error: 0.1079\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.3197 - mean_absolute_error: 0.0969 - val_loss: 0.3094 - val_mean_absolute_error: 0.0869\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.3033 - mean_absolute_error: 0.0809 - val_loss: 0.2986 - val_mean_absolute_error: 0.0757\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.2948 - mean_absolute_error: 0.0744 - val_loss: 0.2908 - val_mean_absolute_error: 0.0713\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2872 - mean_absolute_error: 0.0676 - val_loss: 0.2840 - val_mean_absolute_error: 0.0640\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2815 - mean_absolute_error: 0.0612 - val_loss: 0.2793 - val_mean_absolute_error: 0.0587\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2777 - mean_absolute_error: 0.0570 - val_loss: 0.2763 - val_mean_absolute_error: 0.0557\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2752 - mean_absolute_error: 0.0545 - val_loss: 0.2742 - val_mean_absolute_error: 0.0535\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2735 - mean_absolute_error: 0.0528 - val_loss: 0.2731 - val_mean_absolute_error: 0.0520\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2724 - mean_absolute_error: 0.0516 - val_loss: 0.2723 - val_mean_absolute_error: 0.0513\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2716 - mean_absolute_error: 0.0507 - val_loss: 0.2713 - val_mean_absolute_error: 0.0502\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2710 - mean_absolute_error: 0.0501 - val_loss: 0.2706 - val_mean_absolute_error: 0.0499\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2704 - mean_absolute_error: 0.0497 - val_loss: 0.2700 - val_mean_absolute_error: 0.0494\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2700 - mean_absolute_error: 0.0493 - val_loss: 0.2696 - val_mean_absolute_error: 0.0490\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2693 - val_mean_absolute_error: 0.0487\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2694 - mean_absolute_error: 0.0488 - val_loss: 0.2690 - val_mean_absolute_error: 0.0486\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2692 - mean_absolute_error: 0.0486 - val_loss: 0.2688 - val_mean_absolute_error: 0.0486\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2690 - mean_absolute_error: 0.0484 - val_loss: 0.2686 - val_mean_absolute_error: 0.0481\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2688 - mean_absolute_error: 0.0483 - val_loss: 0.2712 - val_mean_absolute_error: 0.0499\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2682 - val_mean_absolute_error: 0.0478\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_64 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.060405\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_1', 9, 45, 1, 45, 0.9, 1.0, 0.9782608695652174, 0.9891304347826086]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_65 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.040841\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_2', 8, 46, 1, 46, 0.8888888888888888, 1.0, 0.9787234042553191, 0.9893617021276595]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_66 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.036868\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_3', 6, 45, 4, 45, 0.6, 1.0, 0.9183673469387755, 0.9591836734693877]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_67 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.016884\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_4', 6, 49, 0, 49, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_135 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.033758\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_69 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023239\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_70 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_140 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.025970\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_7', 6, 48, 1, 48, 0.8571428571428571, 1.0, 0.9795918367346939, 0.9897959183673469]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_71 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100013\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_72 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.070272\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[7, 'fam_9', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "[7, 0.7548500881834214, 1.0000000000000002, 0.9416603841660007, 0.9708301920830003]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_73 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 8s 153us/step - loss: 0.4192 - mean_absolute_error: 0.1525 - val_loss: 0.4080 - val_mean_absolute_error: 0.1411\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1404\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1411\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1421\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1417\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1423\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1408\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1408\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1418\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1421\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1405\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1403\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.4080 - mean_absolute_error: 0.1415 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1428\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 7s 124us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1414\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 7s 122us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1409\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 7s 123us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1407\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_74 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 7s 155us/step - loss: 0.2185 - mean_absolute_error: 0.0750 - val_loss: 0.1931 - val_mean_absolute_error: 0.0527\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0503\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0506\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0501\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0507\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 6s 119us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 6s 122us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0530\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 6s 121us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_75 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 6s 174us/step - loss: 0.2183 - mean_absolute_error: 0.0954 - val_loss: 0.1805 - val_mean_absolute_error: 0.0620\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0620\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 125us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0616\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 126us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0630\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 125us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0613\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 126us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1806 - val_mean_absolute_error: 0.0619\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 125us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0621\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 125us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1762 - mean_absolute_error: 0.0593 - val_loss: 0.1714 - val_mean_absolute_error: 0.0549\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 125us/step - loss: 0.1671 - mean_absolute_error: 0.0526 - val_loss: 0.1633 - val_mean_absolute_error: 0.0498\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 127us/step - loss: 0.1602 - mean_absolute_error: 0.0469 - val_loss: 0.1575 - val_mean_absolute_error: 0.0445\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 127us/step - loss: 0.1553 - mean_absolute_error: 0.0425 - val_loss: 0.1533 - val_mean_absolute_error: 0.0405\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 126us/step - loss: 0.1517 - mean_absolute_error: 0.0389 - val_loss: 0.1503 - val_mean_absolute_error: 0.0375\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1492 - mean_absolute_error: 0.0363 - val_loss: 0.1483 - val_mean_absolute_error: 0.0355\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1475 - mean_absolute_error: 0.0348 - val_loss: 0.1469 - val_mean_absolute_error: 0.0346\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1464 - mean_absolute_error: 0.0338 - val_loss: 0.1459 - val_mean_absolute_error: 0.0335\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1456 - mean_absolute_error: 0.0331 - val_loss: 0.1453 - val_mean_absolute_error: 0.0327\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1451 - mean_absolute_error: 0.0325 - val_loss: 0.1448 - val_mean_absolute_error: 0.0323\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_76 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 6s 171us/step - loss: 0.1958 - mean_absolute_error: 0.0897 - val_loss: 0.1295 - val_mean_absolute_error: 0.0266\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1243 - mean_absolute_error: 0.0208 - val_loss: 0.1216 - val_mean_absolute_error: 0.0178\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1203 - mean_absolute_error: 0.0165 - val_loss: 0.1194 - val_mean_absolute_error: 0.0154\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1188 - mean_absolute_error: 0.0148 - val_loss: 0.1183 - val_mean_absolute_error: 0.0144\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1178 - mean_absolute_error: 0.0140 - val_loss: 0.1174 - val_mean_absolute_error: 0.0137\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1170 - mean_absolute_error: 0.0132 - val_loss: 0.1166 - val_mean_absolute_error: 0.0127\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1163 - mean_absolute_error: 0.0124 - val_loss: 0.1160 - val_mean_absolute_error: 0.0119\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1157 - mean_absolute_error: 0.0117 - val_loss: 0.1155 - val_mean_absolute_error: 0.0113\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1152 - mean_absolute_error: 0.0107 - val_loss: 0.1151 - val_mean_absolute_error: 0.0103\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1149 - mean_absolute_error: 0.0101 - val_loss: 0.1149 - val_mean_absolute_error: 0.0103\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1147 - mean_absolute_error: 0.0098 - val_loss: 0.1146 - val_mean_absolute_error: 0.0096\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1145 - mean_absolute_error: 0.0096 - val_loss: 0.1145 - val_mean_absolute_error: 0.0096\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1144 - mean_absolute_error: 0.0094 - val_loss: 0.1144 - val_mean_absolute_error: 0.0094\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1143 - mean_absolute_error: 0.0093 - val_loss: 0.1142 - val_mean_absolute_error: 0.0092\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1141 - mean_absolute_error: 0.0092 - val_loss: 0.1141 - val_mean_absolute_error: 0.0092\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1140 - mean_absolute_error: 0.0090 - val_loss: 0.1140 - val_mean_absolute_error: 0.0090\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1140 - mean_absolute_error: 0.0089 - val_loss: 0.1139 - val_mean_absolute_error: 0.0089\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 126us/step - loss: 0.1139 - mean_absolute_error: 0.0088 - val_loss: 0.1139 - val_mean_absolute_error: 0.0088\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 121us/step - loss: 0.1138 - mean_absolute_error: 0.0088 - val_loss: 0.1138 - val_mean_absolute_error: 0.0088\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 122us/step - loss: 0.1137 - mean_absolute_error: 0.0087 - val_loss: 0.1137 - val_mean_absolute_error: 0.0086\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_77 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 0.3272 - mean_absolute_error: 0.1238 - val_loss: 0.2499 - val_mean_absolute_error: 0.0466\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2395 - mean_absolute_error: 0.0317 - val_loss: 0.2336 - val_mean_absolute_error: 0.0228\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2316 - mean_absolute_error: 0.0202 - val_loss: 0.2296 - val_mean_absolute_error: 0.0178\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2281 - mean_absolute_error: 0.0159 - val_loss: 0.2270 - val_mean_absolute_error: 0.0146\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2265 - mean_absolute_error: 0.0137 - val_loss: 0.2261 - val_mean_absolute_error: 0.0131\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2259 - mean_absolute_error: 0.0128 - val_loss: 0.2257 - val_mean_absolute_error: 0.0126\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2257 - mean_absolute_error: 0.0126 - val_loss: 0.2256 - val_mean_absolute_error: 0.0125\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2256 - mean_absolute_error: 0.0125 - val_loss: 0.2255 - val_mean_absolute_error: 0.0125\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2255 - mean_absolute_error: 0.0125 - val_loss: 0.2254 - val_mean_absolute_error: 0.0125\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2254 - mean_absolute_error: 0.0125 - val_loss: 0.2254 - val_mean_absolute_error: 0.0124\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2253 - mean_absolute_error: 0.0124 - val_loss: 0.2253 - val_mean_absolute_error: 0.0124\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2253 - mean_absolute_error: 0.0124 - val_loss: 0.2253 - val_mean_absolute_error: 0.0122\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0124\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0122\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2252 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0124\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2251 - mean_absolute_error: 0.0124 - val_loss: 0.2252 - val_mean_absolute_error: 0.0129\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2251 - mean_absolute_error: 0.0124 - val_loss: 0.2251 - val_mean_absolute_error: 0.0123\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2250 - mean_absolute_error: 0.0124 - val_loss: 0.2250 - val_mean_absolute_error: 0.0125\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2250 - mean_absolute_error: 0.0125 - val_loss: 0.2249 - val_mean_absolute_error: 0.0124\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2249 - mean_absolute_error: 0.0125 - val_loss: 0.2249 - val_mean_absolute_error: 0.0124\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_78 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.1171 - mean_absolute_error: 0.0695 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 122us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 0.2910 - mean_absolute_error: 0.1248 - val_loss: 0.2273 - val_mean_absolute_error: 0.0672\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 126us/step - loss: 0.2134 - mean_absolute_error: 0.0485 - val_loss: 0.2045 - val_mean_absolute_error: 0.0362\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 4s 125us/step - loss: 0.1994 - mean_absolute_error: 0.0309 - val_loss: 0.1956 - val_mean_absolute_error: 0.0269\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1933 - mean_absolute_error: 0.0246 - val_loss: 0.1915 - val_mean_absolute_error: 0.0227\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1904 - mean_absolute_error: 0.0213 - val_loss: 0.1894 - val_mean_absolute_error: 0.0200\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1887 - mean_absolute_error: 0.0190 - val_loss: 0.1881 - val_mean_absolute_error: 0.0182\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1876 - mean_absolute_error: 0.0173 - val_loss: 0.1871 - val_mean_absolute_error: 0.0166\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1868 - mean_absolute_error: 0.0161 - val_loss: 0.1865 - val_mean_absolute_error: 0.0155\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 4s 125us/step - loss: 0.1862 - mean_absolute_error: 0.0151 - val_loss: 0.1860 - val_mean_absolute_error: 0.0148\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1858 - mean_absolute_error: 0.0144 - val_loss: 0.1856 - val_mean_absolute_error: 0.0143\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1854 - mean_absolute_error: 0.0138 - val_loss: 0.1853 - val_mean_absolute_error: 0.0138\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1851 - mean_absolute_error: 0.0133 - val_loss: 0.1849 - val_mean_absolute_error: 0.0130\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1848 - mean_absolute_error: 0.0129 - val_loss: 0.1847 - val_mean_absolute_error: 0.0126\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1845 - mean_absolute_error: 0.0125 - val_loss: 0.1844 - val_mean_absolute_error: 0.0124\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1842 - mean_absolute_error: 0.0121 - val_loss: 0.1841 - val_mean_absolute_error: 0.0118\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 4s 124us/step - loss: 0.1839 - mean_absolute_error: 0.0114 - val_loss: 0.1838 - val_mean_absolute_error: 0.0110\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 4s 123us/step - loss: 0.1837 - mean_absolute_error: 0.0109 - val_loss: 0.1837 - val_mean_absolute_error: 0.0107\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 125us/step - loss: 0.1836 - mean_absolute_error: 0.0106 - val_loss: 0.1836 - val_mean_absolute_error: 0.0106\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 4s 125us/step - loss: 0.1835 - mean_absolute_error: 0.0104 - val_loss: 0.1834 - val_mean_absolute_error: 0.0104\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 4s 125us/step - loss: 0.1834 - mean_absolute_error: 0.0103 - val_loss: 0.1834 - val_mean_absolute_error: 0.0103\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_80 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 5s 180us/step - loss: 0.2953 - mean_absolute_error: 0.1108 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 123us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0793\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0781\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0790\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 124us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 125us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_81 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.3772 - mean_absolute_error: 0.1458 - val_loss: 0.3352 - val_mean_absolute_error: 0.1115\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.3212 - mean_absolute_error: 0.0982 - val_loss: 0.3104 - val_mean_absolute_error: 0.0880\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.3040 - mean_absolute_error: 0.0816 - val_loss: 0.2989 - val_mean_absolute_error: 0.0770\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2953 - mean_absolute_error: 0.0748 - val_loss: 0.2916 - val_mean_absolute_error: 0.0724\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2879 - mean_absolute_error: 0.0686 - val_loss: 0.2846 - val_mean_absolute_error: 0.0648\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2820 - mean_absolute_error: 0.0619 - val_loss: 0.2796 - val_mean_absolute_error: 0.0591\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2779 - mean_absolute_error: 0.0573 - val_loss: 0.2764 - val_mean_absolute_error: 0.0557\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2753 - mean_absolute_error: 0.0547 - val_loss: 0.2743 - val_mean_absolute_error: 0.0538\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2736 - mean_absolute_error: 0.0529 - val_loss: 0.2729 - val_mean_absolute_error: 0.0523\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2725 - mean_absolute_error: 0.0517 - val_loss: 0.2724 - val_mean_absolute_error: 0.0512\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2717 - mean_absolute_error: 0.0508 - val_loss: 0.2712 - val_mean_absolute_error: 0.0505\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2710 - mean_absolute_error: 0.0502 - val_loss: 0.2708 - val_mean_absolute_error: 0.0499\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2705 - mean_absolute_error: 0.0497 - val_loss: 0.2703 - val_mean_absolute_error: 0.0494\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2701 - mean_absolute_error: 0.0493 - val_loss: 0.2701 - val_mean_absolute_error: 0.0493\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2696 - val_mean_absolute_error: 0.0488\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2694 - mean_absolute_error: 0.0488 - val_loss: 0.2691 - val_mean_absolute_error: 0.0484\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2692 - mean_absolute_error: 0.0486 - val_loss: 0.2688 - val_mean_absolute_error: 0.0483\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2690 - mean_absolute_error: 0.0484 - val_loss: 0.2685 - val_mean_absolute_error: 0.0480\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.2688 - mean_absolute_error: 0.0482 - val_loss: 0.2689 - val_mean_absolute_error: 0.0484\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2682 - val_mean_absolute_error: 0.0477\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_73 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.188127\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_1', 9, 36, 10, 36, 0.47368421052631576, 1.0, 0.782608695652174, 0.8913043478260869]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_74 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.141271\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_75 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.045382\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_3', 6, 41, 8, 41, 0.42857142857142855, 1.0, 0.8367346938775511, 0.9183673469387755]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_76 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.018632\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_4', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_77 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.029338\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_78 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022940\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.026074\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_7', 6, 48, 1, 48, 0.8571428571428571, 1.0, 0.9795918367346939, 0.9897959183673469]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_80 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100884\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_81 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.070137\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[8, 'fam_9', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "[8, 0.5859148622306516, 1.0000000000000002, 0.8401219581264514, 0.9200609790632257]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_82 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 9s 162us/step - loss: 0.4194 - mean_absolute_error: 0.1527 - val_loss: 0.4080 - val_mean_absolute_error: 0.1412\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 7s 132us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1420\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1424\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 7s 129us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1425\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 7s 129us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1418\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1414\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 7s 129us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1414\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 7s 130us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1414\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1408\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.4080 - mean_absolute_error: 0.1415 - val_loss: 0.4079 - val_mean_absolute_error: 0.1417\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 7s 133us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1422\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 7s 133us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1413\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1426\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1421\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 7s 129us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1417\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 7s 129us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1424\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 7s 128us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1425\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 7s 129us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 7s 128us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1415\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.2187 - mean_absolute_error: 0.0752 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 6s 124us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0524\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 124us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0528\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 6s 124us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0528\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0529\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 6s 126us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1931 - val_mean_absolute_error: 0.0501\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 6s 124us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 6s 125us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 6s 133us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0507\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 6s 128us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0507\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 6s 129us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0531\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 6s 124us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_84 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 182us/step - loss: 0.2183 - mean_absolute_error: 0.0953 - val_loss: 0.1806 - val_mean_absolute_error: 0.0630\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1795 - mean_absolute_error: 0.0616 - val_loss: 0.1759 - val_mean_absolute_error: 0.0584\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1711 - mean_absolute_error: 0.0557 - val_loss: 0.1668 - val_mean_absolute_error: 0.0516\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1632 - mean_absolute_error: 0.0494 - val_loss: 0.1599 - val_mean_absolute_error: 0.0465\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1574 - mean_absolute_error: 0.0445 - val_loss: 0.1550 - val_mean_absolute_error: 0.0423\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1533 - mean_absolute_error: 0.0405 - val_loss: 0.1516 - val_mean_absolute_error: 0.0388\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1503 - mean_absolute_error: 0.0374 - val_loss: 0.1492 - val_mean_absolute_error: 0.0360\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1483 - mean_absolute_error: 0.0355 - val_loss: 0.1476 - val_mean_absolute_error: 0.0343\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1469 - mean_absolute_error: 0.0343 - val_loss: 0.1463 - val_mean_absolute_error: 0.0337\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1460 - mean_absolute_error: 0.0334 - val_loss: 0.1456 - val_mean_absolute_error: 0.0328\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 126us/step - loss: 0.1453 - mean_absolute_error: 0.0328 - val_loss: 0.1450 - val_mean_absolute_error: 0.0324\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 126us/step - loss: 0.1448 - mean_absolute_error: 0.0323 - val_loss: 0.1446 - val_mean_absolute_error: 0.0322\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1444 - mean_absolute_error: 0.0319 - val_loss: 0.1442 - val_mean_absolute_error: 0.0317\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1441 - mean_absolute_error: 0.0315 - val_loss: 0.1439 - val_mean_absolute_error: 0.0312\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1438 - mean_absolute_error: 0.0312 - val_loss: 0.1438 - val_mean_absolute_error: 0.0315\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1435 - mean_absolute_error: 0.0309 - val_loss: 0.1434 - val_mean_absolute_error: 0.0308\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1433 - mean_absolute_error: 0.0307 - val_loss: 0.1432 - val_mean_absolute_error: 0.0304\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1431 - mean_absolute_error: 0.0304 - val_loss: 0.1430 - val_mean_absolute_error: 0.0305\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1430 - mean_absolute_error: 0.0302 - val_loss: 0.1428 - val_mean_absolute_error: 0.0301\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_85 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 6s 179us/step - loss: 0.1956 - mean_absolute_error: 0.0897 - val_loss: 0.1301 - val_mean_absolute_error: 0.0269\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1254 - mean_absolute_error: 0.0221 - val_loss: 0.1228 - val_mean_absolute_error: 0.0197\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1214 - mean_absolute_error: 0.0179 - val_loss: 0.1203 - val_mean_absolute_error: 0.0163\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1196 - mean_absolute_error: 0.0154 - val_loss: 0.1191 - val_mean_absolute_error: 0.0148\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1188 - mean_absolute_error: 0.0144 - val_loss: 0.1185 - val_mean_absolute_error: 0.0142\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1183 - mean_absolute_error: 0.0139 - val_loss: 0.1181 - val_mean_absolute_error: 0.0138\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1179 - mean_absolute_error: 0.0137 - val_loss: 0.1177 - val_mean_absolute_error: 0.0135\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1174 - mean_absolute_error: 0.0133 - val_loss: 0.1171 - val_mean_absolute_error: 0.0130\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1165 - mean_absolute_error: 0.0124 - val_loss: 0.1161 - val_mean_absolute_error: 0.0118\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1157 - mean_absolute_error: 0.0112 - val_loss: 0.1154 - val_mean_absolute_error: 0.0107\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1151 - mean_absolute_error: 0.0102 - val_loss: 0.1150 - val_mean_absolute_error: 0.0100\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1148 - mean_absolute_error: 0.0096 - val_loss: 0.1147 - val_mean_absolute_error: 0.0095\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1146 - mean_absolute_error: 0.0093 - val_loss: 0.1146 - val_mean_absolute_error: 0.0093\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1145 - mean_absolute_error: 0.0092 - val_loss: 0.1145 - val_mean_absolute_error: 0.0092\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1145 - mean_absolute_error: 0.0091 - val_loss: 0.1145 - val_mean_absolute_error: 0.0091\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1144 - mean_absolute_error: 0.0091 - val_loss: 0.1144 - val_mean_absolute_error: 0.0092\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1144 - mean_absolute_error: 0.0091 - val_loss: 0.1144 - val_mean_absolute_error: 0.0091\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 127us/step - loss: 0.1144 - mean_absolute_error: 0.0091 - val_loss: 0.1144 - val_mean_absolute_error: 0.0091\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1144 - mean_absolute_error: 0.0092 - val_loss: 0.1144 - val_mean_absolute_error: 0.0095\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1143 - mean_absolute_error: 0.0092 - val_loss: 0.1143 - val_mean_absolute_error: 0.0090\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_86 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 193us/step - loss: 0.3243 - mean_absolute_error: 0.1223 - val_loss: 0.2482 - val_mean_absolute_error: 0.0427\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2396 - mean_absolute_error: 0.0304 - val_loss: 0.2357 - val_mean_absolute_error: 0.0245\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2346 - mean_absolute_error: 0.0231 - val_loss: 0.2338 - val_mean_absolute_error: 0.0222\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2332 - mean_absolute_error: 0.0216 - val_loss: 0.2327 - val_mean_absolute_error: 0.0212\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2323 - mean_absolute_error: 0.0207 - val_loss: 0.2320 - val_mean_absolute_error: 0.0204\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2317 - mean_absolute_error: 0.0201 - val_loss: 0.2315 - val_mean_absolute_error: 0.0199\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2313 - mean_absolute_error: 0.0196 - val_loss: 0.2311 - val_mean_absolute_error: 0.0195\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2308 - mean_absolute_error: 0.0191 - val_loss: 0.2300 - val_mean_absolute_error: 0.0183\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2291 - mean_absolute_error: 0.0170 - val_loss: 0.2283 - val_mean_absolute_error: 0.0159\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2276 - mean_absolute_error: 0.0151 - val_loss: 0.2271 - val_mean_absolute_error: 0.0145\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2267 - mean_absolute_error: 0.0142 - val_loss: 0.2264 - val_mean_absolute_error: 0.0137\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2262 - mean_absolute_error: 0.0136 - val_loss: 0.2261 - val_mean_absolute_error: 0.0133\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2260 - mean_absolute_error: 0.0134 - val_loss: 0.2260 - val_mean_absolute_error: 0.0139\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2259 - mean_absolute_error: 0.0134 - val_loss: 0.2259 - val_mean_absolute_error: 0.0139\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2257 - mean_absolute_error: 0.0133 - val_loss: 0.2262 - val_mean_absolute_error: 0.0151\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2256 - mean_absolute_error: 0.0132 - val_loss: 0.2255 - val_mean_absolute_error: 0.0129\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2255 - mean_absolute_error: 0.0130 - val_loss: 0.2256 - val_mean_absolute_error: 0.0132\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2254 - mean_absolute_error: 0.0127 - val_loss: 0.2253 - val_mean_absolute_error: 0.0127\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2253 - mean_absolute_error: 0.0126 - val_loss: 0.2253 - val_mean_absolute_error: 0.0126\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2252 - val_mean_absolute_error: 0.0123\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_87 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.1170 - mean_absolute_error: 0.0695 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 126us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_88 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 181us/step - loss: 0.2939 - mean_absolute_error: 0.1268 - val_loss: 0.2293 - val_mean_absolute_error: 0.0695\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.2132 - mean_absolute_error: 0.0484 - val_loss: 0.2029 - val_mean_absolute_error: 0.0345\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1979 - mean_absolute_error: 0.0288 - val_loss: 0.1937 - val_mean_absolute_error: 0.0243\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1912 - mean_absolute_error: 0.0214 - val_loss: 0.1893 - val_mean_absolute_error: 0.0192\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1876 - mean_absolute_error: 0.0166 - val_loss: 0.1860 - val_mean_absolute_error: 0.0143\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1850 - mean_absolute_error: 0.0127 - val_loss: 0.1844 - val_mean_absolute_error: 0.0116\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1840 - mean_absolute_error: 0.0109 - val_loss: 0.1837 - val_mean_absolute_error: 0.0105\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1835 - mean_absolute_error: 0.0102 - val_loss: 0.1835 - val_mean_absolute_error: 0.0101\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1834 - mean_absolute_error: 0.0099 - val_loss: 0.1834 - val_mean_absolute_error: 0.0100\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1833 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1833 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0098\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1832 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1832 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1832 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1832 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1832 - mean_absolute_error: 0.0098 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0101\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_89 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.2956 - mean_absolute_error: 0.1110 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0779\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0779\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0776\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 127us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 128us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0779\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0783\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_90 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 195us/step - loss: 0.3713 - mean_absolute_error: 0.1414 - val_loss: 0.3235 - val_mean_absolute_error: 0.1013\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.3106 - mean_absolute_error: 0.0880 - val_loss: 0.3014 - val_mean_absolute_error: 0.0795\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2955 - mean_absolute_error: 0.0745 - val_loss: 0.2904 - val_mean_absolute_error: 0.0696\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2866 - mean_absolute_error: 0.0658 - val_loss: 0.2832 - val_mean_absolute_error: 0.0622\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2808 - mean_absolute_error: 0.0597 - val_loss: 0.2787 - val_mean_absolute_error: 0.0577\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2771 - mean_absolute_error: 0.0562 - val_loss: 0.2759 - val_mean_absolute_error: 0.0550\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2748 - mean_absolute_error: 0.0540 - val_loss: 0.2739 - val_mean_absolute_error: 0.0536\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2732 - mean_absolute_error: 0.0525 - val_loss: 0.2725 - val_mean_absolute_error: 0.0521\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2720 - mean_absolute_error: 0.0515 - val_loss: 0.2714 - val_mean_absolute_error: 0.0512\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2710 - mean_absolute_error: 0.0508 - val_loss: 0.2705 - val_mean_absolute_error: 0.0518\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2699 - mean_absolute_error: 0.0504 - val_loss: 0.2694 - val_mean_absolute_error: 0.0493\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2684 - mean_absolute_error: 0.0499 - val_loss: 0.2671 - val_mean_absolute_error: 0.0497\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2657 - mean_absolute_error: 0.0483 - val_loss: 0.2639 - val_mean_absolute_error: 0.0465\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2621 - mean_absolute_error: 0.0445 - val_loss: 0.2602 - val_mean_absolute_error: 0.0420\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2587 - mean_absolute_error: 0.0391 - val_loss: 0.2573 - val_mean_absolute_error: 0.0365\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2565 - mean_absolute_error: 0.0349 - val_loss: 0.2558 - val_mean_absolute_error: 0.0338\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.2554 - mean_absolute_error: 0.0332 - val_loss: 0.2550 - val_mean_absolute_error: 0.0328\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2547 - mean_absolute_error: 0.0324 - val_loss: 0.2545 - val_mean_absolute_error: 0.0320\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2543 - mean_absolute_error: 0.0318 - val_loss: 0.2542 - val_mean_absolute_error: 0.0316\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2541 - mean_absolute_error: 0.0314 - val_loss: 0.2541 - val_mean_absolute_error: 0.0314\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_82 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.187999\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_1', 9, 36, 10, 36, 0.47368421052631576, 1.0, 0.782608695652174, 0.8913043478260869]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_83 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.141059\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_84 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.038835\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_3', 6, 45, 4, 45, 0.6, 1.0, 0.9183673469387755, 0.9591836734693877]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_85 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.021016\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_4', 6, 46, 3, 46, 0.6666666666666666, 1.0, 0.9387755102040817, 0.9693877551020409]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_86 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.030049\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_87 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023072\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_88 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028686\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_89 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100965\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_90 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.045591\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[9, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[9, 0.655227031542821, 1.0000000000000002, 0.8646571055187415, 0.9323285527593708]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_91 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 9s 168us/step - loss: 0.4193 - mean_absolute_error: 0.1525 - val_loss: 0.4079 - val_mean_absolute_error: 0.1421\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 7s 130us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1417\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 7s 130us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1417\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 7s 130us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1415\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 7s 130us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4083 - val_mean_absolute_error: 0.1414\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 7s 130us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1408\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1415\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1406\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 7s 130us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1410\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1402\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1406\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 7s 131us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1414\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 7s 132us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1414\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1417\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 7s 132us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1422\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 7s 133us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1423\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 7s 133us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1413\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 7s 133us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1414\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_92 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 8s 171us/step - loss: 0.2187 - mean_absolute_error: 0.0751 - val_loss: 0.1930 - val_mean_absolute_error: 0.0528\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 6s 128us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0528\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0508\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1929 - val_mean_absolute_error: 0.0515\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 6s 128us/step - loss: 0.1886 - mean_absolute_error: 0.0503 - val_loss: 0.1830 - val_mean_absolute_error: 0.0483\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1779 - mean_absolute_error: 0.0461 - val_loss: 0.1730 - val_mean_absolute_error: 0.0441\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1689 - mean_absolute_error: 0.0413 - val_loss: 0.1650 - val_mean_absolute_error: 0.0386\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1619 - mean_absolute_error: 0.0362 - val_loss: 0.1590 - val_mean_absolute_error: 0.0338\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1567 - mean_absolute_error: 0.0316 - val_loss: 0.1547 - val_mean_absolute_error: 0.0291\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1531 - mean_absolute_error: 0.0277 - val_loss: 0.1518 - val_mean_absolute_error: 0.0263\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 6s 128us/step - loss: 0.1508 - mean_absolute_error: 0.0248 - val_loss: 0.1500 - val_mean_absolute_error: 0.0236\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1494 - mean_absolute_error: 0.0228 - val_loss: 0.1489 - val_mean_absolute_error: 0.0217\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 6s 127us/step - loss: 0.1486 - mean_absolute_error: 0.0215 - val_loss: 0.1483 - val_mean_absolute_error: 0.0210\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 6s 128us/step - loss: 0.1482 - mean_absolute_error: 0.0208 - val_loss: 0.1480 - val_mean_absolute_error: 0.0204\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_93 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 186us/step - loss: 0.2184 - mean_absolute_error: 0.0953 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0624\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0618\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1763 - mean_absolute_error: 0.0594 - val_loss: 0.1713 - val_mean_absolute_error: 0.0560\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1672 - mean_absolute_error: 0.0527 - val_loss: 0.1633 - val_mean_absolute_error: 0.0497\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1602 - mean_absolute_error: 0.0470 - val_loss: 0.1574 - val_mean_absolute_error: 0.0447\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1553 - mean_absolute_error: 0.0426 - val_loss: 0.1534 - val_mean_absolute_error: 0.0403\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1517 - mean_absolute_error: 0.0389 - val_loss: 0.1504 - val_mean_absolute_error: 0.0374\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1493 - mean_absolute_error: 0.0363 - val_loss: 0.1483 - val_mean_absolute_error: 0.0355\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1475 - mean_absolute_error: 0.0348 - val_loss: 0.1468 - val_mean_absolute_error: 0.0345\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1464 - mean_absolute_error: 0.0338 - val_loss: 0.1460 - val_mean_absolute_error: 0.0336\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1456 - mean_absolute_error: 0.0331 - val_loss: 0.1453 - val_mean_absolute_error: 0.0328\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1451 - mean_absolute_error: 0.0325 - val_loss: 0.1448 - val_mean_absolute_error: 0.0324\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1446 - mean_absolute_error: 0.0321 - val_loss: 0.1444 - val_mean_absolute_error: 0.0320\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1442 - mean_absolute_error: 0.0317 - val_loss: 0.1440 - val_mean_absolute_error: 0.0315\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1439 - mean_absolute_error: 0.0313 - val_loss: 0.1438 - val_mean_absolute_error: 0.0312\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1437 - mean_absolute_error: 0.0310 - val_loss: 0.1435 - val_mean_absolute_error: 0.0311\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1434 - mean_absolute_error: 0.0308 - val_loss: 0.1432 - val_mean_absolute_error: 0.0305\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1432 - mean_absolute_error: 0.0305 - val_loss: 0.1432 - val_mean_absolute_error: 0.0303\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1430 - mean_absolute_error: 0.0303 - val_loss: 0.1429 - val_mean_absolute_error: 0.0302\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_94 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 188us/step - loss: 0.1943 - mean_absolute_error: 0.0883 - val_loss: 0.1286 - val_mean_absolute_error: 0.0255\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1249 - mean_absolute_error: 0.0216 - val_loss: 0.1225 - val_mean_absolute_error: 0.0187\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1213 - mean_absolute_error: 0.0175 - val_loss: 0.1204 - val_mean_absolute_error: 0.0164\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1197 - mean_absolute_error: 0.0156 - val_loss: 0.1192 - val_mean_absolute_error: 0.0151\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1188 - mean_absolute_error: 0.0147 - val_loss: 0.1183 - val_mean_absolute_error: 0.0143\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1175 - mean_absolute_error: 0.0135 - val_loss: 0.1169 - val_mean_absolute_error: 0.0126\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1164 - mean_absolute_error: 0.0120 - val_loss: 0.1160 - val_mean_absolute_error: 0.0114\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1156 - mean_absolute_error: 0.0111 - val_loss: 0.1154 - val_mean_absolute_error: 0.0107\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1151 - mean_absolute_error: 0.0106 - val_loss: 0.1150 - val_mean_absolute_error: 0.0109\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1148 - mean_absolute_error: 0.0101 - val_loss: 0.1146 - val_mean_absolute_error: 0.0096\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1145 - mean_absolute_error: 0.0095 - val_loss: 0.1144 - val_mean_absolute_error: 0.0092\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1144 - mean_absolute_error: 0.0092 - val_loss: 0.1143 - val_mean_absolute_error: 0.0090\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1143 - mean_absolute_error: 0.0090 - val_loss: 0.1142 - val_mean_absolute_error: 0.0089\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1142 - val_mean_absolute_error: 0.0088\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1141 - mean_absolute_error: 0.0088 - val_loss: 0.1141 - val_mean_absolute_error: 0.0088\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1141 - mean_absolute_error: 0.0087 - val_loss: 0.1141 - val_mean_absolute_error: 0.0087\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1141 - val_mean_absolute_error: 0.0087\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 128us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1140 - mean_absolute_error: 0.0085 - val_loss: 0.1139 - val_mean_absolute_error: 0.0086\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_95 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 201us/step - loss: 0.3236 - mean_absolute_error: 0.1227 - val_loss: 0.2482 - val_mean_absolute_error: 0.0436\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2399 - mean_absolute_error: 0.0307 - val_loss: 0.2358 - val_mean_absolute_error: 0.0246\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2347 - mean_absolute_error: 0.0233 - val_loss: 0.2338 - val_mean_absolute_error: 0.0223\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2332 - mean_absolute_error: 0.0217 - val_loss: 0.2327 - val_mean_absolute_error: 0.0212\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2324 - mean_absolute_error: 0.0209 - val_loss: 0.2320 - val_mean_absolute_error: 0.0205\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2317 - mean_absolute_error: 0.0203 - val_loss: 0.2314 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2313 - mean_absolute_error: 0.0198 - val_loss: 0.2310 - val_mean_absolute_error: 0.0196\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2310 - mean_absolute_error: 0.0196 - val_loss: 0.2308 - val_mean_absolute_error: 0.0193\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2307 - mean_absolute_error: 0.0196 - val_loss: 0.2306 - val_mean_absolute_error: 0.0200\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2305 - mean_absolute_error: 0.0197 - val_loss: 0.2302 - val_mean_absolute_error: 0.0195\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2302 - mean_absolute_error: 0.0193 - val_loss: 0.2300 - val_mean_absolute_error: 0.0193\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2299 - mean_absolute_error: 0.0185 - val_loss: 0.2298 - val_mean_absolute_error: 0.0182\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2298 - mean_absolute_error: 0.0181 - val_loss: 0.2296 - val_mean_absolute_error: 0.0178\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2297 - mean_absolute_error: 0.0180 - val_loss: 0.2296 - val_mean_absolute_error: 0.0178\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2291 - mean_absolute_error: 0.0173 - val_loss: 0.2285 - val_mean_absolute_error: 0.0164\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2280 - mean_absolute_error: 0.0159 - val_loss: 0.2274 - val_mean_absolute_error: 0.0153\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2272 - mean_absolute_error: 0.0150 - val_loss: 0.2267 - val_mean_absolute_error: 0.0145\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2266 - mean_absolute_error: 0.0144 - val_loss: 0.2262 - val_mean_absolute_error: 0.0139\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2261 - mean_absolute_error: 0.0139 - val_loss: 0.2258 - val_mean_absolute_error: 0.0135\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2258 - mean_absolute_error: 0.0135 - val_loss: 0.2256 - val_mean_absolute_error: 0.0132\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_96 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 6s 201us/step - loss: 0.1174 - mean_absolute_error: 0.0697 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 131us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 129us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 130us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_97 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 188us/step - loss: 0.2871 - mean_absolute_error: 0.1221 - val_loss: 0.2207 - val_mean_absolute_error: 0.0617\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.2060 - mean_absolute_error: 0.0412 - val_loss: 0.1980 - val_mean_absolute_error: 0.0292\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1947 - mean_absolute_error: 0.0252 - val_loss: 0.1919 - val_mean_absolute_error: 0.0220\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1901 - mean_absolute_error: 0.0198 - val_loss: 0.1886 - val_mean_absolute_error: 0.0179\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1875 - mean_absolute_error: 0.0164 - val_loss: 0.1865 - val_mean_absolute_error: 0.0151\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1859 - mean_absolute_error: 0.0141 - val_loss: 0.1853 - val_mean_absolute_error: 0.0132\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1849 - mean_absolute_error: 0.0126 - val_loss: 0.1845 - val_mean_absolute_error: 0.0120\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1843 - mean_absolute_error: 0.0116 - val_loss: 0.1840 - val_mean_absolute_error: 0.0112\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1840 - mean_absolute_error: 0.0110 - val_loss: 0.1838 - val_mean_absolute_error: 0.0108\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1837 - mean_absolute_error: 0.0107 - val_loss: 0.1836 - val_mean_absolute_error: 0.0105\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 129us/step - loss: 0.1836 - mean_absolute_error: 0.0104 - val_loss: 0.1835 - val_mean_absolute_error: 0.0104\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1835 - mean_absolute_error: 0.0103 - val_loss: 0.1834 - val_mean_absolute_error: 0.0102\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1835 - mean_absolute_error: 0.0103 - val_loss: 0.1834 - val_mean_absolute_error: 0.0102\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1834 - mean_absolute_error: 0.0102 - val_loss: 0.1833 - val_mean_absolute_error: 0.0101\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1834 - mean_absolute_error: 0.0102 - val_loss: 0.1833 - val_mean_absolute_error: 0.0104\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1834 - mean_absolute_error: 0.0103 - val_loss: 0.1833 - val_mean_absolute_error: 0.0102\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1833 - mean_absolute_error: 0.0104 - val_loss: 0.1832 - val_mean_absolute_error: 0.0103\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1833 - mean_absolute_error: 0.0105 - val_loss: 0.1833 - val_mean_absolute_error: 0.0109\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1832 - mean_absolute_error: 0.0105 - val_loss: 0.1831 - val_mean_absolute_error: 0.0103\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1831 - mean_absolute_error: 0.0102 - val_loss: 0.1829 - val_mean_absolute_error: 0.0098\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_98 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 206us/step - loss: 0.2955 - mean_absolute_error: 0.1110 - val_loss: 0.2596 - val_mean_absolute_error: 0.0781\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0789\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0782\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0789\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0792\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0781\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0781\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0789\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_99 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 202us/step - loss: 0.3721 - mean_absolute_error: 0.1420 - val_loss: 0.3249 - val_mean_absolute_error: 0.1031\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.3115 - mean_absolute_error: 0.0889 - val_loss: 0.3021 - val_mean_absolute_error: 0.0801\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2960 - mean_absolute_error: 0.0750 - val_loss: 0.2907 - val_mean_absolute_error: 0.0702\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2868 - mean_absolute_error: 0.0661 - val_loss: 0.2833 - val_mean_absolute_error: 0.0623\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2808 - mean_absolute_error: 0.0598 - val_loss: 0.2786 - val_mean_absolute_error: 0.0577\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2772 - mean_absolute_error: 0.0562 - val_loss: 0.2758 - val_mean_absolute_error: 0.0549\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2748 - mean_absolute_error: 0.0540 - val_loss: 0.2738 - val_mean_absolute_error: 0.0530\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2731 - mean_absolute_error: 0.0525 - val_loss: 0.2724 - val_mean_absolute_error: 0.0521\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2720 - mean_absolute_error: 0.0515 - val_loss: 0.2713 - val_mean_absolute_error: 0.0512\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2709 - mean_absolute_error: 0.0508 - val_loss: 0.2702 - val_mean_absolute_error: 0.0502\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2698 - mean_absolute_error: 0.0504 - val_loss: 0.2689 - val_mean_absolute_error: 0.0507\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2682 - mean_absolute_error: 0.0498 - val_loss: 0.2671 - val_mean_absolute_error: 0.0505\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2656 - mean_absolute_error: 0.0482 - val_loss: 0.2642 - val_mean_absolute_error: 0.0456\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2621 - mean_absolute_error: 0.0444 - val_loss: 0.2601 - val_mean_absolute_error: 0.0419\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2587 - mean_absolute_error: 0.0391 - val_loss: 0.2574 - val_mean_absolute_error: 0.0366\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2565 - mean_absolute_error: 0.0350 - val_loss: 0.2558 - val_mean_absolute_error: 0.0339\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2554 - mean_absolute_error: 0.0333 - val_loss: 0.2550 - val_mean_absolute_error: 0.0327\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2548 - mean_absolute_error: 0.0324 - val_loss: 0.2545 - val_mean_absolute_error: 0.0321\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2544 - mean_absolute_error: 0.0318 - val_loss: 0.2542 - val_mean_absolute_error: 0.0316\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2541 - mean_absolute_error: 0.0315 - val_loss: 0.2539 - val_mean_absolute_error: 0.0313\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_91 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.188624\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_1', 9, 36, 10, 36, 0.47368421052631576, 1.0, 0.782608695652174, 0.8913043478260869]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_92 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.039864\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_2', 8, 46, 1, 46, 0.8888888888888888, 1.0, 0.9787234042553191, 0.9893617021276595]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_93 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.040111\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_3', 6, 43, 6, 43, 0.5, 1.0, 0.8775510204081632, 0.9387755102040816]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_94 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.018692\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_4', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_95 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.026111\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_96 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023214\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_97 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.026843\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_98 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.101239\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_99 (InputLayer)        (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.043955\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[10, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[10, 0.7281165877657105, 1.0000000000000002, 0.9285833852504923, 0.9642916926252463]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_100 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 9s 175us/step - loss: 0.4194 - mean_absolute_error: 0.1526 - val_loss: 0.4079 - val_mean_absolute_error: 0.1413\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 7s 133us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1415\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 7s 132us/step - loss: 0.4070 - mean_absolute_error: 0.1410 - val_loss: 0.3997 - val_mean_absolute_error: 0.1370\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.3853 - mean_absolute_error: 0.1268 - val_loss: 0.3730 - val_mean_absolute_error: 0.1185\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.3558 - mean_absolute_error: 0.1048 - val_loss: 0.3383 - val_mean_absolute_error: 0.0900\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.3262 - mean_absolute_error: 0.0783 - val_loss: 0.3177 - val_mean_absolute_error: 0.0700\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.3126 - mean_absolute_error: 0.0649 - val_loss: 0.3089 - val_mean_absolute_error: 0.0612\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 7s 137us/step - loss: 0.3061 - mean_absolute_error: 0.0580 - val_loss: 0.3037 - val_mean_absolute_error: 0.0554\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 7s 137us/step - loss: 0.3020 - mean_absolute_error: 0.0533 - val_loss: 0.3008 - val_mean_absolute_error: 0.0513\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.2990 - mean_absolute_error: 0.0499 - val_loss: 0.2977 - val_mean_absolute_error: 0.0482\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.2967 - mean_absolute_error: 0.0472 - val_loss: 0.2955 - val_mean_absolute_error: 0.0460\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.2948 - mean_absolute_error: 0.0449 - val_loss: 0.2938 - val_mean_absolute_error: 0.0438\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.2932 - mean_absolute_error: 0.0427 - val_loss: 0.2936 - val_mean_absolute_error: 0.0425\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.2921 - mean_absolute_error: 0.0408 - val_loss: 0.2917 - val_mean_absolute_error: 0.0402\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.2913 - mean_absolute_error: 0.0395 - val_loss: 0.2908 - val_mean_absolute_error: 0.0390\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 7s 134us/step - loss: 0.2908 - mean_absolute_error: 0.0388 - val_loss: 0.2905 - val_mean_absolute_error: 0.0388\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 7s 136us/step - loss: 0.2904 - mean_absolute_error: 0.0384 - val_loss: 0.2906 - val_mean_absolute_error: 0.0384\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 7s 136us/step - loss: 0.2902 - mean_absolute_error: 0.0380 - val_loss: 0.2898 - val_mean_absolute_error: 0.0378\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 7s 136us/step - loss: 0.2900 - mean_absolute_error: 0.0378 - val_loss: 0.2904 - val_mean_absolute_error: 0.0381\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.2898 - mean_absolute_error: 0.0376 - val_loss: 0.2899 - val_mean_absolute_error: 0.0382\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_101 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 9s 178us/step - loss: 0.2186 - mean_absolute_error: 0.0751 - val_loss: 0.1930 - val_mean_absolute_error: 0.0526\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 6s 132us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0527\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0503\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 129us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 6s 129us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 6s 131us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 6s 129us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 6s 129us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0528\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 6s 129us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0507\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0504\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 6s 131us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 6s 131us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0506\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 6s 131us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_102 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 0.2183 - mean_absolute_error: 0.0953 - val_loss: 0.1806 - val_mean_absolute_error: 0.0622\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0628\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0624\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1804 - mean_absolute_error: 0.0622 - val_loss: 0.1787 - val_mean_absolute_error: 0.0612\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1736 - mean_absolute_error: 0.0575 - val_loss: 0.1690 - val_mean_absolute_error: 0.0537\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1651 - mean_absolute_error: 0.0510 - val_loss: 0.1615 - val_mean_absolute_error: 0.0479\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1587 - mean_absolute_error: 0.0457 - val_loss: 0.1562 - val_mean_absolute_error: 0.0436\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1542 - mean_absolute_error: 0.0415 - val_loss: 0.1524 - val_mean_absolute_error: 0.0397\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1510 - mean_absolute_error: 0.0381 - val_loss: 0.1497 - val_mean_absolute_error: 0.0366\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1487 - mean_absolute_error: 0.0358 - val_loss: 0.1478 - val_mean_absolute_error: 0.0349\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1472 - mean_absolute_error: 0.0345 - val_loss: 0.1466 - val_mean_absolute_error: 0.0339\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1462 - mean_absolute_error: 0.0336 - val_loss: 0.1457 - val_mean_absolute_error: 0.0332\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1455 - mean_absolute_error: 0.0329 - val_loss: 0.1452 - val_mean_absolute_error: 0.0326\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1449 - mean_absolute_error: 0.0324 - val_loss: 0.1447 - val_mean_absolute_error: 0.0324\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1445 - mean_absolute_error: 0.0320 - val_loss: 0.1443 - val_mean_absolute_error: 0.0318\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1442 - mean_absolute_error: 0.0316 - val_loss: 0.1441 - val_mean_absolute_error: 0.0313\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1439 - mean_absolute_error: 0.0313 - val_loss: 0.1437 - val_mean_absolute_error: 0.0311\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1436 - mean_absolute_error: 0.0310 - val_loss: 0.1436 - val_mean_absolute_error: 0.0309\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1434 - mean_absolute_error: 0.0307 - val_loss: 0.1432 - val_mean_absolute_error: 0.0308\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1432 - mean_absolute_error: 0.0305 - val_loss: 0.1431 - val_mean_absolute_error: 0.0306\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_103 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 195us/step - loss: 0.1941 - mean_absolute_error: 0.0878 - val_loss: 0.1274 - val_mean_absolute_error: 0.0241\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1234 - mean_absolute_error: 0.0199 - val_loss: 0.1211 - val_mean_absolute_error: 0.0173\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1200 - mean_absolute_error: 0.0161 - val_loss: 0.1191 - val_mean_absolute_error: 0.0152\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1185 - mean_absolute_error: 0.0146 - val_loss: 0.1179 - val_mean_absolute_error: 0.0140\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1176 - mean_absolute_error: 0.0137 - val_loss: 0.1172 - val_mean_absolute_error: 0.0135\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1168 - mean_absolute_error: 0.0130 - val_loss: 0.1165 - val_mean_absolute_error: 0.0127\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1162 - mean_absolute_error: 0.0122 - val_loss: 0.1159 - val_mean_absolute_error: 0.0117\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1157 - mean_absolute_error: 0.0116 - val_loss: 0.1155 - val_mean_absolute_error: 0.0114\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1153 - mean_absolute_error: 0.0110 - val_loss: 0.1151 - val_mean_absolute_error: 0.0104\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1149 - mean_absolute_error: 0.0103 - val_loss: 0.1148 - val_mean_absolute_error: 0.0103\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1147 - mean_absolute_error: 0.0099 - val_loss: 0.1146 - val_mean_absolute_error: 0.0096\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1145 - mean_absolute_error: 0.0096 - val_loss: 0.1144 - val_mean_absolute_error: 0.0095\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1143 - mean_absolute_error: 0.0095 - val_loss: 0.1142 - val_mean_absolute_error: 0.0094\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1142 - mean_absolute_error: 0.0094 - val_loss: 0.1142 - val_mean_absolute_error: 0.0098\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1141 - mean_absolute_error: 0.0092 - val_loss: 0.1140 - val_mean_absolute_error: 0.0091\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 130us/step - loss: 0.1139 - mean_absolute_error: 0.0090 - val_loss: 0.1139 - val_mean_absolute_error: 0.0089\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1139 - mean_absolute_error: 0.0089 - val_loss: 0.1138 - val_mean_absolute_error: 0.0089\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1138 - mean_absolute_error: 0.0088 - val_loss: 0.1137 - val_mean_absolute_error: 0.0088\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1137 - mean_absolute_error: 0.0087 - val_loss: 0.1137 - val_mean_absolute_error: 0.0087\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 131us/step - loss: 0.1136 - mean_absolute_error: 0.0086 - val_loss: 0.1136 - val_mean_absolute_error: 0.0085\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_104 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 207us/step - loss: 0.3239 - mean_absolute_error: 0.1223 - val_loss: 0.2475 - val_mean_absolute_error: 0.0426\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2383 - mean_absolute_error: 0.0297 - val_loss: 0.2333 - val_mean_absolute_error: 0.0226\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2320 - mean_absolute_error: 0.0206 - val_loss: 0.2311 - val_mean_absolute_error: 0.0194\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2308 - mean_absolute_error: 0.0190 - val_loss: 0.2305 - val_mean_absolute_error: 0.0187\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2304 - mean_absolute_error: 0.0185 - val_loss: 0.2303 - val_mean_absolute_error: 0.0184\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2303 - mean_absolute_error: 0.0184 - val_loss: 0.2302 - val_mean_absolute_error: 0.0184\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2301 - mean_absolute_error: 0.0184 - val_loss: 0.2298 - val_mean_absolute_error: 0.0186\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2293 - mean_absolute_error: 0.0177 - val_loss: 0.2288 - val_mean_absolute_error: 0.0170\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2284 - mean_absolute_error: 0.0166 - val_loss: 0.2280 - val_mean_absolute_error: 0.0160\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2277 - mean_absolute_error: 0.0158 - val_loss: 0.2274 - val_mean_absolute_error: 0.0153\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2271 - mean_absolute_error: 0.0153 - val_loss: 0.2268 - val_mean_absolute_error: 0.0147\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2267 - mean_absolute_error: 0.0146 - val_loss: 0.2265 - val_mean_absolute_error: 0.0142\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2264 - mean_absolute_error: 0.0142 - val_loss: 0.2264 - val_mean_absolute_error: 0.0151\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2261 - mean_absolute_error: 0.0139 - val_loss: 0.2260 - val_mean_absolute_error: 0.0136\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2260 - mean_absolute_error: 0.0136 - val_loss: 0.2258 - val_mean_absolute_error: 0.0135\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2258 - mean_absolute_error: 0.0133 - val_loss: 0.2258 - val_mean_absolute_error: 0.0134\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2257 - mean_absolute_error: 0.0130 - val_loss: 0.2257 - val_mean_absolute_error: 0.0129\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2257 - mean_absolute_error: 0.0128 - val_loss: 0.2256 - val_mean_absolute_error: 0.0126\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2256 - mean_absolute_error: 0.0127 - val_loss: 0.2256 - val_mean_absolute_error: 0.0125\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2256 - mean_absolute_error: 0.0127 - val_loss: 0.2256 - val_mean_absolute_error: 0.0126\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_105 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 208us/step - loss: 0.1172 - mean_absolute_error: 0.0696 - val_loss: 0.0597 - val_mean_absolute_error: 0.0200\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 132us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_106 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 198us/step - loss: 0.2985 - mean_absolute_error: 0.1316 - val_loss: 0.2377 - val_mean_absolute_error: 0.0804\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.2147 - mean_absolute_error: 0.0566 - val_loss: 0.2018 - val_mean_absolute_error: 0.0405\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 132us/step - loss: 0.1959 - mean_absolute_error: 0.0305 - val_loss: 0.1917 - val_mean_absolute_error: 0.0230\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1896 - mean_absolute_error: 0.0192 - val_loss: 0.1880 - val_mean_absolute_error: 0.0167\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1867 - mean_absolute_error: 0.0153 - val_loss: 0.1855 - val_mean_absolute_error: 0.0136\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1847 - mean_absolute_error: 0.0123 - val_loss: 0.1842 - val_mean_absolute_error: 0.0114\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1839 - mean_absolute_error: 0.0108 - val_loss: 0.1837 - val_mean_absolute_error: 0.0105\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1835 - mean_absolute_error: 0.0102 - val_loss: 0.1834 - val_mean_absolute_error: 0.0102\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1834 - val_mean_absolute_error: 0.0100\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0101\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1832 - mean_absolute_error: 0.0101 - val_loss: 0.1832 - val_mean_absolute_error: 0.0101\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1832 - mean_absolute_error: 0.0102 - val_loss: 0.1832 - val_mean_absolute_error: 0.0103\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 133us/step - loss: 0.1832 - mean_absolute_error: 0.0102 - val_loss: 0.1831 - val_mean_absolute_error: 0.0104\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1831 - mean_absolute_error: 0.0102 - val_loss: 0.1831 - val_mean_absolute_error: 0.0101\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1831 - mean_absolute_error: 0.0102 - val_loss: 0.1831 - val_mean_absolute_error: 0.0103\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_107 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 209us/step - loss: 0.2953 - mean_absolute_error: 0.1108 - val_loss: 0.2597 - val_mean_absolute_error: 0.0783\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 133us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0793\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 134us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_108 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 6s 214us/step - loss: 0.3746 - mean_absolute_error: 0.1438 - val_loss: 0.3306 - val_mean_absolute_error: 0.1067\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.3180 - mean_absolute_error: 0.0952 - val_loss: 0.3083 - val_mean_absolute_error: 0.0856\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.3025 - mean_absolute_error: 0.0802 - val_loss: 0.2978 - val_mean_absolute_error: 0.0770\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2944 - mean_absolute_error: 0.0741 - val_loss: 0.2906 - val_mean_absolute_error: 0.0715\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2871 - mean_absolute_error: 0.0677 - val_loss: 0.2843 - val_mean_absolute_error: 0.0649\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2814 - mean_absolute_error: 0.0613 - val_loss: 0.2792 - val_mean_absolute_error: 0.0587\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2776 - mean_absolute_error: 0.0570 - val_loss: 0.2762 - val_mean_absolute_error: 0.0557\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2752 - mean_absolute_error: 0.0545 - val_loss: 0.2742 - val_mean_absolute_error: 0.0534\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2735 - mean_absolute_error: 0.0528 - val_loss: 0.2728 - val_mean_absolute_error: 0.0522\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2724 - mean_absolute_error: 0.0516 - val_loss: 0.2720 - val_mean_absolute_error: 0.0514\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2716 - mean_absolute_error: 0.0507 - val_loss: 0.2715 - val_mean_absolute_error: 0.0503\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2709 - mean_absolute_error: 0.0501 - val_loss: 0.2705 - val_mean_absolute_error: 0.0498\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2704 - mean_absolute_error: 0.0496 - val_loss: 0.2700 - val_mean_absolute_error: 0.0493\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2700 - mean_absolute_error: 0.0493 - val_loss: 0.2696 - val_mean_absolute_error: 0.0489\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2693 - val_mean_absolute_error: 0.0488\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2694 - mean_absolute_error: 0.0487 - val_loss: 0.2690 - val_mean_absolute_error: 0.0484\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2692 - mean_absolute_error: 0.0485 - val_loss: 0.2713 - val_mean_absolute_error: 0.0501\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2690 - mean_absolute_error: 0.0483 - val_loss: 0.2686 - val_mean_absolute_error: 0.0480\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2688 - mean_absolute_error: 0.0482 - val_loss: 0.2686 - val_mean_absolute_error: 0.0482\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2686 - val_mean_absolute_error: 0.0482\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_100 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.062033\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_1', 9, 43, 3, 43, 0.75, 1.0, 0.9347826086956522, 0.9673913043478262]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_101 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.140879\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_102 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.041414\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_3', 6, 43, 6, 43, 0.5, 1.0, 0.8775510204081632, 0.9387755102040816]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_103 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.018704\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_4', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_104 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028055\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_105 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023237\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_106 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.037985\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_7', 6, 44, 5, 44, 0.5454545454545454, 1.0, 0.8979591836734694, 0.9489795918367347]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_107 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.099782\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_108 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.070367\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[11, 'fam_9', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "[11, 0.5899210899210898, 1.0000000000000002, 0.8524950232945475, 0.9262475116472737]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_109 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 10s 180us/step - loss: 0.4194 - mean_absolute_error: 0.1527 - val_loss: 0.4080 - val_mean_absolute_error: 0.1432\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1405\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4084 - val_mean_absolute_error: 0.1415\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 7s 135us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1400\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 7s 136us/step - loss: 0.4005 - mean_absolute_error: 0.1368 - val_loss: 0.3865 - val_mean_absolute_error: 0.1278\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 7s 136us/step - loss: 0.3748 - mean_absolute_error: 0.1194 - val_loss: 0.3647 - val_mean_absolute_error: 0.1111\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 7s 137us/step - loss: 0.3567 - mean_absolute_error: 0.1051 - val_loss: 0.3480 - val_mean_absolute_error: 0.0977\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 7s 137us/step - loss: 0.3410 - mean_absolute_error: 0.0902 - val_loss: 0.3351 - val_mean_absolute_error: 0.0840\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 7s 138us/step - loss: 0.3310 - mean_absolute_error: 0.0799 - val_loss: 0.3267 - val_mean_absolute_error: 0.0765\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 7s 139us/step - loss: 0.3245 - mean_absolute_error: 0.0745 - val_loss: 0.3215 - val_mean_absolute_error: 0.0717\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 8s 139us/step - loss: 0.3209 - mean_absolute_error: 0.0709 - val_loss: 0.3189 - val_mean_absolute_error: 0.0697\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 8s 139us/step - loss: 0.3187 - mean_absolute_error: 0.0688 - val_loss: 0.3175 - val_mean_absolute_error: 0.0690\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 7s 137us/step - loss: 0.3172 - mean_absolute_error: 0.0676 - val_loss: 0.3177 - val_mean_absolute_error: 0.0666\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 7s 138us/step - loss: 0.3162 - mean_absolute_error: 0.0668 - val_loss: 0.3142 - val_mean_absolute_error: 0.0659\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 7s 138us/step - loss: 0.3154 - mean_absolute_error: 0.0661 - val_loss: 0.3153 - val_mean_absolute_error: 0.0676\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 7s 137us/step - loss: 0.3147 - mean_absolute_error: 0.0656 - val_loss: 0.3132 - val_mean_absolute_error: 0.0654\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 7s 138us/step - loss: 0.3141 - mean_absolute_error: 0.0651 - val_loss: 0.3136 - val_mean_absolute_error: 0.0638\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 7s 138us/step - loss: 0.3136 - mean_absolute_error: 0.0647 - val_loss: 0.3118 - val_mean_absolute_error: 0.0643\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 7s 138us/step - loss: 0.3132 - mean_absolute_error: 0.0643 - val_loss: 0.3132 - val_mean_absolute_error: 0.0635\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_110 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 9s 187us/step - loss: 0.2185 - mean_absolute_error: 0.0750 - val_loss: 0.1931 - val_mean_absolute_error: 0.0535\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0527\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0508\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 6s 133us/step - loss: 0.1929 - mean_absolute_error: 0.0517 - val_loss: 0.1908 - val_mean_absolute_error: 0.0517\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1851 - mean_absolute_error: 0.0491 - val_loss: 0.1796 - val_mean_absolute_error: 0.0474\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 6s 135us/step - loss: 0.1747 - mean_absolute_error: 0.0446 - val_loss: 0.1703 - val_mean_absolute_error: 0.0423\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1664 - mean_absolute_error: 0.0396 - val_loss: 0.1629 - val_mean_absolute_error: 0.0369\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 6s 133us/step - loss: 0.1600 - mean_absolute_error: 0.0347 - val_loss: 0.1574 - val_mean_absolute_error: 0.0321\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 6s 133us/step - loss: 0.1554 - mean_absolute_error: 0.0303 - val_loss: 0.1536 - val_mean_absolute_error: 0.0280\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 6s 135us/step - loss: 0.1523 - mean_absolute_error: 0.0267 - val_loss: 0.1511 - val_mean_absolute_error: 0.0254\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1503 - mean_absolute_error: 0.0241 - val_loss: 0.1496 - val_mean_absolute_error: 0.0235\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 6s 133us/step - loss: 0.1491 - mean_absolute_error: 0.0223 - val_loss: 0.1487 - val_mean_absolute_error: 0.0216\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1485 - mean_absolute_error: 0.0212 - val_loss: 0.1482 - val_mean_absolute_error: 0.0209\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 6s 133us/step - loss: 0.1480 - mean_absolute_error: 0.0206 - val_loss: 0.1473 - val_mean_absolute_error: 0.0206\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1470 - mean_absolute_error: 0.0205 - val_loss: 0.1468 - val_mean_absolute_error: 0.0200\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1465 - mean_absolute_error: 0.0203 - val_loss: 0.1464 - val_mean_absolute_error: 0.0204\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 6s 134us/step - loss: 0.1461 - mean_absolute_error: 0.0202 - val_loss: 0.1458 - val_mean_absolute_error: 0.0202\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_111 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 205us/step - loss: 0.2181 - mean_absolute_error: 0.0952 - val_loss: 0.1805 - val_mean_absolute_error: 0.0621\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1804 - val_mean_absolute_error: 0.0612\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1750 - mean_absolute_error: 0.0584 - val_loss: 0.1701 - val_mean_absolute_error: 0.0550\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1661 - mean_absolute_error: 0.0518 - val_loss: 0.1624 - val_mean_absolute_error: 0.0493\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1595 - mean_absolute_error: 0.0463 - val_loss: 0.1568 - val_mean_absolute_error: 0.0440\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1548 - mean_absolute_error: 0.0420 - val_loss: 0.1529 - val_mean_absolute_error: 0.0400\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1514 - mean_absolute_error: 0.0385 - val_loss: 0.1500 - val_mean_absolute_error: 0.0372\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1490 - mean_absolute_error: 0.0361 - val_loss: 0.1480 - val_mean_absolute_error: 0.0354\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1474 - mean_absolute_error: 0.0347 - val_loss: 0.1471 - val_mean_absolute_error: 0.0341\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1463 - mean_absolute_error: 0.0337 - val_loss: 0.1459 - val_mean_absolute_error: 0.0336\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1456 - mean_absolute_error: 0.0330 - val_loss: 0.1452 - val_mean_absolute_error: 0.0329\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1450 - mean_absolute_error: 0.0325 - val_loss: 0.1447 - val_mean_absolute_error: 0.0321\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1446 - mean_absolute_error: 0.0320 - val_loss: 0.1446 - val_mean_absolute_error: 0.0319\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1442 - mean_absolute_error: 0.0317 - val_loss: 0.1441 - val_mean_absolute_error: 0.0311\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1439 - mean_absolute_error: 0.0313 - val_loss: 0.1437 - val_mean_absolute_error: 0.0311\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1437 - mean_absolute_error: 0.0310 - val_loss: 0.1437 - val_mean_absolute_error: 0.0310\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1434 - mean_absolute_error: 0.0308 - val_loss: 0.1432 - val_mean_absolute_error: 0.0305\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1432 - mean_absolute_error: 0.0305 - val_loss: 0.1431 - val_mean_absolute_error: 0.0302\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 134us/step - loss: 0.1430 - mean_absolute_error: 0.0303 - val_loss: 0.1431 - val_mean_absolute_error: 0.0303\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_112 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 0.1941 - mean_absolute_error: 0.0880 - val_loss: 0.1285 - val_mean_absolute_error: 0.0257\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1248 - mean_absolute_error: 0.0215 - val_loss: 0.1225 - val_mean_absolute_error: 0.0188\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1213 - mean_absolute_error: 0.0175 - val_loss: 0.1203 - val_mean_absolute_error: 0.0166\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1197 - mean_absolute_error: 0.0157 - val_loss: 0.1192 - val_mean_absolute_error: 0.0151\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1187 - mean_absolute_error: 0.0147 - val_loss: 0.1180 - val_mean_absolute_error: 0.0140\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1173 - mean_absolute_error: 0.0132 - val_loss: 0.1166 - val_mean_absolute_error: 0.0123\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1162 - mean_absolute_error: 0.0119 - val_loss: 0.1158 - val_mean_absolute_error: 0.0113\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1155 - mean_absolute_error: 0.0111 - val_loss: 0.1153 - val_mean_absolute_error: 0.0111\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1150 - mean_absolute_error: 0.0102 - val_loss: 0.1148 - val_mean_absolute_error: 0.0097\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1147 - mean_absolute_error: 0.0097 - val_loss: 0.1145 - val_mean_absolute_error: 0.0093\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1145 - mean_absolute_error: 0.0093 - val_loss: 0.1144 - val_mean_absolute_error: 0.0094\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1143 - mean_absolute_error: 0.0091 - val_loss: 0.1143 - val_mean_absolute_error: 0.0090\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1142 - mean_absolute_error: 0.0090 - val_loss: 0.1142 - val_mean_absolute_error: 0.0090\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1141 - val_mean_absolute_error: 0.0089\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1141 - mean_absolute_error: 0.0088 - val_loss: 0.1141 - val_mean_absolute_error: 0.0088\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1141 - mean_absolute_error: 0.0086 - val_loss: 0.1141 - val_mean_absolute_error: 0.0086\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1140 - mean_absolute_error: 0.0085 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1140 - mean_absolute_error: 0.0085 - val_loss: 0.1140 - val_mean_absolute_error: 0.0085\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1140 - mean_absolute_error: 0.0084 - val_loss: 0.1139 - val_mean_absolute_error: 0.0084\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1140 - mean_absolute_error: 0.0084 - val_loss: 0.1139 - val_mean_absolute_error: 0.0084\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_113 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.3243 - mean_absolute_error: 0.1232 - val_loss: 0.2483 - val_mean_absolute_error: 0.0434\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.2399 - mean_absolute_error: 0.0307 - val_loss: 0.2359 - val_mean_absolute_error: 0.0249\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.2345 - mean_absolute_error: 0.0233 - val_loss: 0.2331 - val_mean_absolute_error: 0.0221\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2322 - mean_absolute_error: 0.0208 - val_loss: 0.2316 - val_mean_absolute_error: 0.0200\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2313 - mean_absolute_error: 0.0197 - val_loss: 0.2310 - val_mean_absolute_error: 0.0193\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2306 - mean_absolute_error: 0.0190 - val_loss: 0.2300 - val_mean_absolute_error: 0.0183\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2293 - mean_absolute_error: 0.0174 - val_loss: 0.2287 - val_mean_absolute_error: 0.0169\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2283 - mean_absolute_error: 0.0164 - val_loss: 0.2278 - val_mean_absolute_error: 0.0160\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2275 - mean_absolute_error: 0.0158 - val_loss: 0.2272 - val_mean_absolute_error: 0.0154\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2269 - mean_absolute_error: 0.0154 - val_loss: 0.2269 - val_mean_absolute_error: 0.0164\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2262 - mean_absolute_error: 0.0147 - val_loss: 0.2259 - val_mean_absolute_error: 0.0137\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2257 - mean_absolute_error: 0.0137 - val_loss: 0.2256 - val_mean_absolute_error: 0.0132\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2255 - mean_absolute_error: 0.0130 - val_loss: 0.2254 - val_mean_absolute_error: 0.0128\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2253 - mean_absolute_error: 0.0127 - val_loss: 0.2253 - val_mean_absolute_error: 0.0127\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2252 - mean_absolute_error: 0.0125 - val_loss: 0.2251 - val_mean_absolute_error: 0.0124\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2251 - mean_absolute_error: 0.0125 - val_loss: 0.2252 - val_mean_absolute_error: 0.0127\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2251 - mean_absolute_error: 0.0124 - val_loss: 0.2250 - val_mean_absolute_error: 0.0126\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2250 - mean_absolute_error: 0.0124 - val_loss: 0.2250 - val_mean_absolute_error: 0.0123\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2249 - mean_absolute_error: 0.0125 - val_loss: 0.2248 - val_mean_absolute_error: 0.0124\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2249 - mean_absolute_error: 0.0125 - val_loss: 0.2249 - val_mean_absolute_error: 0.0125\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_114 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 219us/step - loss: 0.1170 - mean_absolute_error: 0.0695 - val_loss: 0.0598 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 135us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_115 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 7s 205us/step - loss: 0.2948 - mean_absolute_error: 0.1274 - val_loss: 0.2316 - val_mean_absolute_error: 0.0720\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.2164 - mean_absolute_error: 0.0517 - val_loss: 0.2073 - val_mean_absolute_error: 0.0391\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.2028 - mean_absolute_error: 0.0341 - val_loss: 0.1995 - val_mean_absolute_error: 0.0307\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1964 - mean_absolute_error: 0.0275 - val_loss: 0.1936 - val_mean_absolute_error: 0.0246\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1918 - mean_absolute_error: 0.0227 - val_loss: 0.1903 - val_mean_absolute_error: 0.0210\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1894 - mean_absolute_error: 0.0198 - val_loss: 0.1885 - val_mean_absolute_error: 0.0187\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1879 - mean_absolute_error: 0.0178 - val_loss: 0.1874 - val_mean_absolute_error: 0.0170\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1870 - mean_absolute_error: 0.0164 - val_loss: 0.1866 - val_mean_absolute_error: 0.0157\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1863 - mean_absolute_error: 0.0153 - val_loss: 0.1860 - val_mean_absolute_error: 0.0149\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1858 - mean_absolute_error: 0.0145 - val_loss: 0.1856 - val_mean_absolute_error: 0.0142\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1854 - mean_absolute_error: 0.0138 - val_loss: 0.1853 - val_mean_absolute_error: 0.0134\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1851 - mean_absolute_error: 0.0132 - val_loss: 0.1850 - val_mean_absolute_error: 0.0129\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1848 - mean_absolute_error: 0.0127 - val_loss: 0.1847 - val_mean_absolute_error: 0.0125\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1845 - mean_absolute_error: 0.0122 - val_loss: 0.1844 - val_mean_absolute_error: 0.0119\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1843 - mean_absolute_error: 0.0118 - val_loss: 0.1842 - val_mean_absolute_error: 0.0116\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 135us/step - loss: 0.1841 - mean_absolute_error: 0.0114 - val_loss: 0.1841 - val_mean_absolute_error: 0.0113\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1840 - mean_absolute_error: 0.0111 - val_loss: 0.1839 - val_mean_absolute_error: 0.0110\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1839 - mean_absolute_error: 0.0109 - val_loss: 0.1838 - val_mean_absolute_error: 0.0108\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1838 - mean_absolute_error: 0.0107 - val_loss: 0.1837 - val_mean_absolute_error: 0.0107\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1837 - mean_absolute_error: 0.0106 - val_loss: 0.1837 - val_mean_absolute_error: 0.0106\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_116 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 218us/step - loss: 0.2956 - mean_absolute_error: 0.1110 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0792\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2597 - val_mean_absolute_error: 0.0782\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0782\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 137us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0792\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 136us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_117 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 221us/step - loss: 0.3728 - mean_absolute_error: 0.1426 - val_loss: 0.3252 - val_mean_absolute_error: 0.1015\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.3117 - mean_absolute_error: 0.0891 - val_loss: 0.3021 - val_mean_absolute_error: 0.0793\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2962 - mean_absolute_error: 0.0751 - val_loss: 0.2909 - val_mean_absolute_error: 0.0706\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.2870 - mean_absolute_error: 0.0663 - val_loss: 0.2835 - val_mean_absolute_error: 0.0624\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2810 - mean_absolute_error: 0.0600 - val_loss: 0.2788 - val_mean_absolute_error: 0.0578\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2773 - mean_absolute_error: 0.0563 - val_loss: 0.2760 - val_mean_absolute_error: 0.0550\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.2749 - mean_absolute_error: 0.0541 - val_loss: 0.2740 - val_mean_absolute_error: 0.0540\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2732 - mean_absolute_error: 0.0526 - val_loss: 0.2726 - val_mean_absolute_error: 0.0518\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.2720 - mean_absolute_error: 0.0515 - val_loss: 0.2713 - val_mean_absolute_error: 0.0514\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2709 - mean_absolute_error: 0.0509 - val_loss: 0.2701 - val_mean_absolute_error: 0.0507\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2696 - mean_absolute_error: 0.0505 - val_loss: 0.2690 - val_mean_absolute_error: 0.0520\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2676 - mean_absolute_error: 0.0496 - val_loss: 0.2664 - val_mean_absolute_error: 0.0476\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2644 - mean_absolute_error: 0.0472 - val_loss: 0.2625 - val_mean_absolute_error: 0.0446\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2607 - mean_absolute_error: 0.0424 - val_loss: 0.2591 - val_mean_absolute_error: 0.0395\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2577 - mean_absolute_error: 0.0372 - val_loss: 0.2567 - val_mean_absolute_error: 0.0352\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2560 - mean_absolute_error: 0.0342 - val_loss: 0.2555 - val_mean_absolute_error: 0.0334\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2552 - mean_absolute_error: 0.0330 - val_loss: 0.2549 - val_mean_absolute_error: 0.0325\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2546 - mean_absolute_error: 0.0322 - val_loss: 0.2544 - val_mean_absolute_error: 0.0320\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2543 - mean_absolute_error: 0.0317 - val_loss: 0.2542 - val_mean_absolute_error: 0.0316\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2540 - mean_absolute_error: 0.0314 - val_loss: 0.2539 - val_mean_absolute_error: 0.0312\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_109 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.097988\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_1', 9, 29, 17, 29, 0.34615384615384615, 1.0, 0.6304347826086957, 0.8152173913043479]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_110 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.035192\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_2', 8, 46, 1, 46, 0.8888888888888888, 1.0, 0.9787234042553191, 0.9893617021276595]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_111 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.041501\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_3', 6, 43, 6, 43, 0.5, 1.0, 0.8775510204081632, 0.9387755102040816]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_112 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.017276\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_4', 6, 49, 0, 49, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_113 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.039797\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_114 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023171\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_115 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028604\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_116 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_231 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_232 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.099381\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_117 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_233 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.043417\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[12, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[12, 0.7417243250576584, 1.0000000000000002, 0.9162103200823961, 0.9581051600411981]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_118 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 10s 190us/step - loss: 0.4195 - mean_absolute_error: 0.1527 - val_loss: 0.4080 - val_mean_absolute_error: 0.1420\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 8s 141us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1418\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 8s 140us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1413\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 8s 140us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1425\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 8s 140us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1413\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 8s 141us/step - loss: 0.4049 - mean_absolute_error: 0.1396 - val_loss: 0.3936 - val_mean_absolute_error: 0.1331\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 8s 140us/step - loss: 0.3805 - mean_absolute_error: 0.1235 - val_loss: 0.3692 - val_mean_absolute_error: 0.1156\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 8s 140us/step - loss: 0.3609 - mean_absolute_error: 0.1087 - val_loss: 0.3540 - val_mean_absolute_error: 0.1018\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 8s 142us/step - loss: 0.3425 - mean_absolute_error: 0.0931 - val_loss: 0.3260 - val_mean_absolute_error: 0.0792\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 8s 143us/step - loss: 0.3144 - mean_absolute_error: 0.0668 - val_loss: 0.3055 - val_mean_absolute_error: 0.0577\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 8s 143us/step - loss: 0.2996 - mean_absolute_error: 0.0501 - val_loss: 0.2960 - val_mean_absolute_error: 0.0460\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 8s 143us/step - loss: 0.2920 - mean_absolute_error: 0.0410 - val_loss: 0.2895 - val_mean_absolute_error: 0.0379\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 8s 142us/step - loss: 0.2884 - mean_absolute_error: 0.0363 - val_loss: 0.2878 - val_mean_absolute_error: 0.0355\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 8s 142us/step - loss: 0.2867 - mean_absolute_error: 0.0341 - val_loss: 0.2869 - val_mean_absolute_error: 0.0350\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 8s 143us/step - loss: 0.2858 - mean_absolute_error: 0.0328 - val_loss: 0.2842 - val_mean_absolute_error: 0.0302\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 8s 143us/step - loss: 0.2819 - mean_absolute_error: 0.0276 - val_loss: 0.2788 - val_mean_absolute_error: 0.0229\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 8s 142us/step - loss: 0.2782 - mean_absolute_error: 0.0228 - val_loss: 0.2768 - val_mean_absolute_error: 0.0205\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 8s 142us/step - loss: 0.2769 - mean_absolute_error: 0.0209 - val_loss: 0.2761 - val_mean_absolute_error: 0.0190\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 8s 142us/step - loss: 0.2765 - mean_absolute_error: 0.0201 - val_loss: 0.2759 - val_mean_absolute_error: 0.0190\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 8s 144us/step - loss: 0.2763 - mean_absolute_error: 0.0198 - val_loss: 0.2759 - val_mean_absolute_error: 0.0190\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_119 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 9s 196us/step - loss: 0.2186 - mean_absolute_error: 0.0751 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 140us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 137us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 137us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 138us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1931 - val_mean_absolute_error: 0.0503\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 137us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 137us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 137us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 138us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 138us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0503\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0527\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 137us/step - loss: 0.1916 - mean_absolute_error: 0.0513 - val_loss: 0.1872 - val_mean_absolute_error: 0.0494\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 138us/step - loss: 0.1818 - mean_absolute_error: 0.0478 - val_loss: 0.1766 - val_mean_absolute_error: 0.0458\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_120 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 212us/step - loss: 0.2182 - mean_absolute_error: 0.0953 - val_loss: 0.1805 - val_mean_absolute_error: 0.0626\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0622\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0622\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1755 - mean_absolute_error: 0.0588 - val_loss: 0.1706 - val_mean_absolute_error: 0.0553\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1665 - mean_absolute_error: 0.0522 - val_loss: 0.1628 - val_mean_absolute_error: 0.0497\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1598 - mean_absolute_error: 0.0466 - val_loss: 0.1571 - val_mean_absolute_error: 0.0440\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1549 - mean_absolute_error: 0.0422 - val_loss: 0.1531 - val_mean_absolute_error: 0.0404\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1515 - mean_absolute_error: 0.0386 - val_loss: 0.1502 - val_mean_absolute_error: 0.0375\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1491 - mean_absolute_error: 0.0362 - val_loss: 0.1482 - val_mean_absolute_error: 0.0350\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1474 - mean_absolute_error: 0.0347 - val_loss: 0.1469 - val_mean_absolute_error: 0.0342\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1463 - mean_absolute_error: 0.0338 - val_loss: 0.1459 - val_mean_absolute_error: 0.0335\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1456 - mean_absolute_error: 0.0331 - val_loss: 0.1452 - val_mean_absolute_error: 0.0325\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1450 - mean_absolute_error: 0.0325 - val_loss: 0.1448 - val_mean_absolute_error: 0.0323\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1446 - mean_absolute_error: 0.0320 - val_loss: 0.1444 - val_mean_absolute_error: 0.0318\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1442 - mean_absolute_error: 0.0317 - val_loss: 0.1441 - val_mean_absolute_error: 0.0311\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1439 - mean_absolute_error: 0.0313 - val_loss: 0.1438 - val_mean_absolute_error: 0.0311\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1437 - mean_absolute_error: 0.0310 - val_loss: 0.1435 - val_mean_absolute_error: 0.0307\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1434 - mean_absolute_error: 0.0308 - val_loss: 0.1433 - val_mean_absolute_error: 0.0305\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 136us/step - loss: 0.1432 - mean_absolute_error: 0.0306 - val_loss: 0.1431 - val_mean_absolute_error: 0.0302\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 137us/step - loss: 0.1430 - mean_absolute_error: 0.0303 - val_loss: 0.1429 - val_mean_absolute_error: 0.0301\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_121 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 213us/step - loss: 0.1959 - mean_absolute_error: 0.0898 - val_loss: 0.1292 - val_mean_absolute_error: 0.0258\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1241 - mean_absolute_error: 0.0206 - val_loss: 0.1215 - val_mean_absolute_error: 0.0177\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1203 - mean_absolute_error: 0.0164 - val_loss: 0.1194 - val_mean_absolute_error: 0.0154\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1187 - mean_absolute_error: 0.0148 - val_loss: 0.1182 - val_mean_absolute_error: 0.0144\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1178 - mean_absolute_error: 0.0140 - val_loss: 0.1174 - val_mean_absolute_error: 0.0136\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1170 - mean_absolute_error: 0.0133 - val_loss: 0.1166 - val_mean_absolute_error: 0.0128\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1163 - mean_absolute_error: 0.0125 - val_loss: 0.1160 - val_mean_absolute_error: 0.0119\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1157 - mean_absolute_error: 0.0116 - val_loss: 0.1154 - val_mean_absolute_error: 0.0110\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1153 - mean_absolute_error: 0.0107 - val_loss: 0.1151 - val_mean_absolute_error: 0.0108\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1149 - mean_absolute_error: 0.0102 - val_loss: 0.1148 - val_mean_absolute_error: 0.0099\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1147 - mean_absolute_error: 0.0098 - val_loss: 0.1146 - val_mean_absolute_error: 0.0097\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1145 - mean_absolute_error: 0.0096 - val_loss: 0.1144 - val_mean_absolute_error: 0.0095\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1144 - mean_absolute_error: 0.0094 - val_loss: 0.1143 - val_mean_absolute_error: 0.0094\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1142 - mean_absolute_error: 0.0093 - val_loss: 0.1142 - val_mean_absolute_error: 0.0092\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1141 - mean_absolute_error: 0.0091 - val_loss: 0.1141 - val_mean_absolute_error: 0.0091\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1140 - mean_absolute_error: 0.0090 - val_loss: 0.1140 - val_mean_absolute_error: 0.0089\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1139 - mean_absolute_error: 0.0089 - val_loss: 0.1139 - val_mean_absolute_error: 0.0089\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1139 - mean_absolute_error: 0.0088 - val_loss: 0.1138 - val_mean_absolute_error: 0.0088\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 138us/step - loss: 0.1138 - mean_absolute_error: 0.0087 - val_loss: 0.1138 - val_mean_absolute_error: 0.0087\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1136 - mean_absolute_error: 0.0085 - val_loss: 0.1134 - val_mean_absolute_error: 0.0081\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_122 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.3245 - mean_absolute_error: 0.1236 - val_loss: 0.2484 - val_mean_absolute_error: 0.0435\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.2399 - mean_absolute_error: 0.0309 - val_loss: 0.2359 - val_mean_absolute_error: 0.0248\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2347 - mean_absolute_error: 0.0233 - val_loss: 0.2339 - val_mean_absolute_error: 0.0225\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2326 - mean_absolute_error: 0.0214 - val_loss: 0.2318 - val_mean_absolute_error: 0.0203\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2313 - mean_absolute_error: 0.0198 - val_loss: 0.2310 - val_mean_absolute_error: 0.0195\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.2307 - mean_absolute_error: 0.0193 - val_loss: 0.2306 - val_mean_absolute_error: 0.0193\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.2299 - mean_absolute_error: 0.0183 - val_loss: 0.2292 - val_mean_absolute_error: 0.0171\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2285 - mean_absolute_error: 0.0164 - val_loss: 0.2281 - val_mean_absolute_error: 0.0158\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2276 - mean_absolute_error: 0.0154 - val_loss: 0.2273 - val_mean_absolute_error: 0.0151\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2270 - mean_absolute_error: 0.0148 - val_loss: 0.2267 - val_mean_absolute_error: 0.0144\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2265 - mean_absolute_error: 0.0143 - val_loss: 0.2263 - val_mean_absolute_error: 0.0139\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2260 - mean_absolute_error: 0.0138 - val_loss: 0.2259 - val_mean_absolute_error: 0.0134\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2257 - mean_absolute_error: 0.0134 - val_loss: 0.2257 - val_mean_absolute_error: 0.0139\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2255 - mean_absolute_error: 0.0131 - val_loss: 0.2255 - val_mean_absolute_error: 0.0131\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2254 - mean_absolute_error: 0.0127 - val_loss: 0.2253 - val_mean_absolute_error: 0.0126\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2253 - mean_absolute_error: 0.0124 - val_loss: 0.2253 - val_mean_absolute_error: 0.0124\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2252 - mean_absolute_error: 0.0123 - val_loss: 0.2252 - val_mean_absolute_error: 0.0122\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2252 - mean_absolute_error: 0.0122 - val_loss: 0.2252 - val_mean_absolute_error: 0.0121\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2251 - mean_absolute_error: 0.0122 - val_loss: 0.2251 - val_mean_absolute_error: 0.0121\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2251 - mean_absolute_error: 0.0122 - val_loss: 0.2251 - val_mean_absolute_error: 0.0120\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_123 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 7s 225us/step - loss: 0.1174 - mean_absolute_error: 0.0697 - val_loss: 0.0598 - val_mean_absolute_error: 0.0200\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0196\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 138us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_124 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 215us/step - loss: 0.2899 - mean_absolute_error: 0.1242 - val_loss: 0.2257 - val_mean_absolute_error: 0.0661\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.2120 - mean_absolute_error: 0.0470 - val_loss: 0.2024 - val_mean_absolute_error: 0.0341\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1980 - mean_absolute_error: 0.0290 - val_loss: 0.1945 - val_mean_absolute_error: 0.0251\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1917 - mean_absolute_error: 0.0219 - val_loss: 0.1896 - val_mean_absolute_error: 0.0193\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1882 - mean_absolute_error: 0.0176 - val_loss: 0.1872 - val_mean_absolute_error: 0.0161\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1864 - mean_absolute_error: 0.0150 - val_loss: 0.1858 - val_mean_absolute_error: 0.0141\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1853 - mean_absolute_error: 0.0132 - val_loss: 0.1849 - val_mean_absolute_error: 0.0126\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1845 - mean_absolute_error: 0.0120 - val_loss: 0.1843 - val_mean_absolute_error: 0.0116\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 139us/step - loss: 0.1840 - mean_absolute_error: 0.0111 - val_loss: 0.1839 - val_mean_absolute_error: 0.0109\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1837 - mean_absolute_error: 0.0106 - val_loss: 0.1837 - val_mean_absolute_error: 0.0105\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1835 - mean_absolute_error: 0.0103 - val_loss: 0.1835 - val_mean_absolute_error: 0.0102\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1834 - mean_absolute_error: 0.0101 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1834 - val_mean_absolute_error: 0.0100\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_125 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 230us/step - loss: 0.2951 - mean_absolute_error: 0.1106 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0796\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0783\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0784\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0780\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2597 - val_mean_absolute_error: 0.0788\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2597 - val_mean_absolute_error: 0.0783\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0779\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 139us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 140us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_126 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 232us/step - loss: 0.3737 - mean_absolute_error: 0.1432 - val_loss: 0.3264 - val_mean_absolute_error: 0.1030\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.3124 - mean_absolute_error: 0.0897 - val_loss: 0.3025 - val_mean_absolute_error: 0.0797\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2965 - mean_absolute_error: 0.0754 - val_loss: 0.2913 - val_mean_absolute_error: 0.0705\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2872 - mean_absolute_error: 0.0666 - val_loss: 0.2838 - val_mean_absolute_error: 0.0628\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2811 - mean_absolute_error: 0.0601 - val_loss: 0.2789 - val_mean_absolute_error: 0.0579\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2773 - mean_absolute_error: 0.0564 - val_loss: 0.2760 - val_mean_absolute_error: 0.0552\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2749 - mean_absolute_error: 0.0541 - val_loss: 0.2740 - val_mean_absolute_error: 0.0533\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2732 - mean_absolute_error: 0.0526 - val_loss: 0.2725 - val_mean_absolute_error: 0.0518\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2720 - mean_absolute_error: 0.0516 - val_loss: 0.2715 - val_mean_absolute_error: 0.0521\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.2709 - mean_absolute_error: 0.0509 - val_loss: 0.2702 - val_mean_absolute_error: 0.0500\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2697 - mean_absolute_error: 0.0505 - val_loss: 0.2688 - val_mean_absolute_error: 0.0510\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2678 - mean_absolute_error: 0.0497 - val_loss: 0.2664 - val_mean_absolute_error: 0.0499\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2647 - mean_absolute_error: 0.0475 - val_loss: 0.2627 - val_mean_absolute_error: 0.0450\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2609 - mean_absolute_error: 0.0428 - val_loss: 0.2592 - val_mean_absolute_error: 0.0399\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2578 - mean_absolute_error: 0.0375 - val_loss: 0.2568 - val_mean_absolute_error: 0.0353\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2561 - mean_absolute_error: 0.0342 - val_loss: 0.2556 - val_mean_absolute_error: 0.0335\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.2552 - mean_absolute_error: 0.0330 - val_loss: 0.2549 - val_mean_absolute_error: 0.0326\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2546 - mean_absolute_error: 0.0322 - val_loss: 0.2545 - val_mean_absolute_error: 0.0320\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2543 - mean_absolute_error: 0.0317 - val_loss: 0.2542 - val_mean_absolute_error: 0.0315\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2540 - mean_absolute_error: 0.0314 - val_loss: 0.2539 - val_mean_absolute_error: 0.0313\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_118 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.031485\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_1', 9, 46, 0, 46, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_119 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.109630\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_2', 8, 24, 23, 24, 0.25806451612903225, 1.0, 0.5106382978723404, 0.7553191489361701]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_120 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.039663\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_3', 6, 44, 5, 44, 0.5454545454545454, 1.0, 0.8979591836734694, 0.9489795918367347]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_121 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.018412\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_4', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_122 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.029146\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_123 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022883\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_124 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028369\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_125 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100127\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_126 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.045102\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[13, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[13, 0.721555028006641, 1.0000000000000002, 0.9029960920538427, 0.9514980460269216]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_127 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 11s 204us/step - loss: 0.4193 - mean_absolute_error: 0.1526 - val_loss: 0.4079 - val_mean_absolute_error: 0.1415\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1420\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 8s 142us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 8s 145us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 8s 150us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1432\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 8s 147us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1418\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 8s 143us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1418\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1434\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 8s 147us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1424\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 8s 144us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1420\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 8s 145us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1411\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 8s 144us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1406\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 8s 145us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1413\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1421\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1410\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4083 - val_mean_absolute_error: 0.1412\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 8s 152us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1418\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1419\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1426\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 8s 146us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_128 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 10s 200us/step - loss: 0.2187 - mean_absolute_error: 0.0751 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 141us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0521\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0526\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 140us/step - loss: 0.1930 - mean_absolute_error: 0.0516 - val_loss: 0.1932 - val_mean_absolute_error: 0.0537\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 140us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0509\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0511\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 141us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0534\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0508\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 139us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_129 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 217us/step - loss: 0.2183 - mean_absolute_error: 0.0953 - val_loss: 0.1805 - val_mean_absolute_error: 0.0620\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0620\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0620\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1763 - mean_absolute_error: 0.0593 - val_loss: 0.1714 - val_mean_absolute_error: 0.0556\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1672 - mean_absolute_error: 0.0527 - val_loss: 0.1633 - val_mean_absolute_error: 0.0496\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1602 - mean_absolute_error: 0.0469 - val_loss: 0.1575 - val_mean_absolute_error: 0.0449\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1553 - mean_absolute_error: 0.0426 - val_loss: 0.1533 - val_mean_absolute_error: 0.0408\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1518 - mean_absolute_error: 0.0389 - val_loss: 0.1504 - val_mean_absolute_error: 0.0374\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1493 - mean_absolute_error: 0.0363 - val_loss: 0.1484 - val_mean_absolute_error: 0.0358\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1475 - mean_absolute_error: 0.0348 - val_loss: 0.1469 - val_mean_absolute_error: 0.0343\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1464 - mean_absolute_error: 0.0338 - val_loss: 0.1459 - val_mean_absolute_error: 0.0335\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1456 - mean_absolute_error: 0.0331 - val_loss: 0.1453 - val_mean_absolute_error: 0.0327\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1451 - mean_absolute_error: 0.0325 - val_loss: 0.1448 - val_mean_absolute_error: 0.0324\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1446 - mean_absolute_error: 0.0321 - val_loss: 0.1444 - val_mean_absolute_error: 0.0315\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1443 - mean_absolute_error: 0.0317 - val_loss: 0.1441 - val_mean_absolute_error: 0.0314\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 140us/step - loss: 0.1439 - mean_absolute_error: 0.0313 - val_loss: 0.1440 - val_mean_absolute_error: 0.0316\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1437 - mean_absolute_error: 0.0311 - val_loss: 0.1435 - val_mean_absolute_error: 0.0308\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1434 - mean_absolute_error: 0.0308 - val_loss: 0.1433 - val_mean_absolute_error: 0.0305\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1432 - mean_absolute_error: 0.0305 - val_loss: 0.1431 - val_mean_absolute_error: 0.0305\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1430 - mean_absolute_error: 0.0303 - val_loss: 0.1430 - val_mean_absolute_error: 0.0303\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_130 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 221us/step - loss: 0.1946 - mean_absolute_error: 0.0881 - val_loss: 0.1278 - val_mean_absolute_error: 0.0242\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 143us/step - loss: 0.1231 - mean_absolute_error: 0.0198 - val_loss: 0.1200 - val_mean_absolute_error: 0.0162\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1183 - mean_absolute_error: 0.0143 - val_loss: 0.1171 - val_mean_absolute_error: 0.0128\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1163 - mean_absolute_error: 0.0119 - val_loss: 0.1158 - val_mean_absolute_error: 0.0112\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1153 - mean_absolute_error: 0.0106 - val_loss: 0.1150 - val_mean_absolute_error: 0.0101\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1146 - mean_absolute_error: 0.0098 - val_loss: 0.1144 - val_mean_absolute_error: 0.0095\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1141 - mean_absolute_error: 0.0093 - val_loss: 0.1140 - val_mean_absolute_error: 0.0091\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1138 - mean_absolute_error: 0.0089 - val_loss: 0.1138 - val_mean_absolute_error: 0.0092\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1136 - mean_absolute_error: 0.0087 - val_loss: 0.1136 - val_mean_absolute_error: 0.0088\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1134 - mean_absolute_error: 0.0086 - val_loss: 0.1133 - val_mean_absolute_error: 0.0082\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1132 - mean_absolute_error: 0.0082 - val_loss: 0.1131 - val_mean_absolute_error: 0.0078\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1131 - mean_absolute_error: 0.0079 - val_loss: 0.1130 - val_mean_absolute_error: 0.0076\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1129 - mean_absolute_error: 0.0077 - val_loss: 0.1129 - val_mean_absolute_error: 0.0077\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1128 - mean_absolute_error: 0.0075 - val_loss: 0.1128 - val_mean_absolute_error: 0.0074\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1127 - mean_absolute_error: 0.0074 - val_loss: 0.1127 - val_mean_absolute_error: 0.0072\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1126 - mean_absolute_error: 0.0073 - val_loss: 0.1126 - val_mean_absolute_error: 0.0071\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1126 - mean_absolute_error: 0.0072 - val_loss: 0.1126 - val_mean_absolute_error: 0.0074\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 142us/step - loss: 0.1125 - mean_absolute_error: 0.0071 - val_loss: 0.1125 - val_mean_absolute_error: 0.0071\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1124 - mean_absolute_error: 0.0070 - val_loss: 0.1124 - val_mean_absolute_error: 0.0072\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 141us/step - loss: 0.1123 - mean_absolute_error: 0.0069 - val_loss: 0.1123 - val_mean_absolute_error: 0.0071\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_131 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 238us/step - loss: 0.3256 - mean_absolute_error: 0.1234 - val_loss: 0.2504 - val_mean_absolute_error: 0.0470\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2391 - mean_absolute_error: 0.0314 - val_loss: 0.2331 - val_mean_absolute_error: 0.0225\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2313 - mean_absolute_error: 0.0199 - val_loss: 0.2301 - val_mean_absolute_error: 0.0181\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2288 - mean_absolute_error: 0.0165 - val_loss: 0.2279 - val_mean_absolute_error: 0.0153\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2272 - mean_absolute_error: 0.0146 - val_loss: 0.2268 - val_mean_absolute_error: 0.0141\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2265 - mean_absolute_error: 0.0137 - val_loss: 0.2263 - val_mean_absolute_error: 0.0136\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2261 - mean_absolute_error: 0.0133 - val_loss: 0.2261 - val_mean_absolute_error: 0.0137\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2259 - mean_absolute_error: 0.0130 - val_loss: 0.2258 - val_mean_absolute_error: 0.0130\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2257 - mean_absolute_error: 0.0128 - val_loss: 0.2257 - val_mean_absolute_error: 0.0127\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2256 - mean_absolute_error: 0.0127 - val_loss: 0.2257 - val_mean_absolute_error: 0.0126\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2256 - mean_absolute_error: 0.0126 - val_loss: 0.2256 - val_mean_absolute_error: 0.0127\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2255 - mean_absolute_error: 0.0126 - val_loss: 0.2256 - val_mean_absolute_error: 0.0125\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2255 - mean_absolute_error: 0.0125 - val_loss: 0.2255 - val_mean_absolute_error: 0.0125\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2255 - mean_absolute_error: 0.0125 - val_loss: 0.2255 - val_mean_absolute_error: 0.0126\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2254 - mean_absolute_error: 0.0125 - val_loss: 0.2255 - val_mean_absolute_error: 0.0125\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2254 - mean_absolute_error: 0.0125 - val_loss: 0.2254 - val_mean_absolute_error: 0.0127\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2254 - mean_absolute_error: 0.0125 - val_loss: 0.2254 - val_mean_absolute_error: 0.0126\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.2253 - mean_absolute_error: 0.0126 - val_loss: 0.2254 - val_mean_absolute_error: 0.0127\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.2253 - mean_absolute_error: 0.0126 - val_loss: 0.2254 - val_mean_absolute_error: 0.0131\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.2253 - mean_absolute_error: 0.0126 - val_loss: 0.2253 - val_mean_absolute_error: 0.0125\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_132 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 7s 236us/step - loss: 0.1171 - mean_absolute_error: 0.0695 - val_loss: 0.0598 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0200\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 141us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_133 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 227us/step - loss: 0.2892 - mean_absolute_error: 0.1234 - val_loss: 0.2245 - val_mean_absolute_error: 0.0644\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.2098 - mean_absolute_error: 0.0447 - val_loss: 0.1995 - val_mean_absolute_error: 0.0309\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 150us/step - loss: 0.1947 - mean_absolute_error: 0.0252 - val_loss: 0.1911 - val_mean_absolute_error: 0.0210\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1892 - mean_absolute_error: 0.0186 - val_loss: 0.1878 - val_mean_absolute_error: 0.0167\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1868 - mean_absolute_error: 0.0153 - val_loss: 0.1860 - val_mean_absolute_error: 0.0141\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 151us/step - loss: 0.1855 - mean_absolute_error: 0.0132 - val_loss: 0.1850 - val_mean_absolute_error: 0.0125\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1846 - mean_absolute_error: 0.0119 - val_loss: 0.1843 - val_mean_absolute_error: 0.0115\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1841 - mean_absolute_error: 0.0111 - val_loss: 0.1839 - val_mean_absolute_error: 0.0109\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1838 - mean_absolute_error: 0.0106 - val_loss: 0.1836 - val_mean_absolute_error: 0.0105\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 150us/step - loss: 0.1836 - mean_absolute_error: 0.0103 - val_loss: 0.1835 - val_mean_absolute_error: 0.0102\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1834 - mean_absolute_error: 0.0101 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 150us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 143us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1832 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0103\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_134 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 237us/step - loss: 0.2954 - mean_absolute_error: 0.1109 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0780\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0789\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0773\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2597 - val_mean_absolute_error: 0.0791\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 142us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 143us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_135 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 239us/step - loss: 0.3752 - mean_absolute_error: 0.1444 - val_loss: 0.3316 - val_mean_absolute_error: 0.1078\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.3188 - mean_absolute_error: 0.0960 - val_loss: 0.3087 - val_mean_absolute_error: 0.0860\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.3029 - mean_absolute_error: 0.0805 - val_loss: 0.2981 - val_mean_absolute_error: 0.0766\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2948 - mean_absolute_error: 0.0744 - val_loss: 0.2913 - val_mean_absolute_error: 0.0720\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2877 - mean_absolute_error: 0.0684 - val_loss: 0.2845 - val_mean_absolute_error: 0.0653\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2818 - mean_absolute_error: 0.0618 - val_loss: 0.2795 - val_mean_absolute_error: 0.0594\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2778 - mean_absolute_error: 0.0573 - val_loss: 0.2767 - val_mean_absolute_error: 0.0557\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2753 - mean_absolute_error: 0.0546 - val_loss: 0.2749 - val_mean_absolute_error: 0.0539\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2736 - mean_absolute_error: 0.0529 - val_loss: 0.2728 - val_mean_absolute_error: 0.0521\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2724 - mean_absolute_error: 0.0516 - val_loss: 0.2720 - val_mean_absolute_error: 0.0514\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2716 - mean_absolute_error: 0.0508 - val_loss: 0.2713 - val_mean_absolute_error: 0.0506\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.2709 - mean_absolute_error: 0.0501 - val_loss: 0.2705 - val_mean_absolute_error: 0.0499\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2704 - mean_absolute_error: 0.0496 - val_loss: 0.2700 - val_mean_absolute_error: 0.0493\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 144us/step - loss: 0.2700 - mean_absolute_error: 0.0493 - val_loss: 0.2703 - val_mean_absolute_error: 0.0495\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2694 - val_mean_absolute_error: 0.0487\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 146us/step - loss: 0.2694 - mean_absolute_error: 0.0487 - val_loss: 0.2691 - val_mean_absolute_error: 0.0487\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2692 - mean_absolute_error: 0.0485 - val_loss: 0.2688 - val_mean_absolute_error: 0.0481\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2690 - mean_absolute_error: 0.0484 - val_loss: 0.2689 - val_mean_absolute_error: 0.0483\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2688 - mean_absolute_error: 0.0482 - val_loss: 0.2689 - val_mean_absolute_error: 0.0484\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 145us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2682 - val_mean_absolute_error: 0.0477\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_127 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.187491\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_1', 9, 36, 10, 36, 0.47368421052631576, 1.0, 0.782608695652174, 0.8913043478260869]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_128 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_256 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.142031\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_129 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_258 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.037913\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_3', 6, 45, 4, 45, 0.6, 1.0, 0.9183673469387755, 0.9591836734693877]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_130 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.033395\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_4', 6, 42, 7, 42, 0.46153846153846156, 1.0, 0.8571428571428571, 0.9285714285714286]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_131 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_261 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.029362\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_132 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_263 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022806\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_133 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_265 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028760\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_134 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_267 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100855\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_135 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_269 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.068416\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[14, 'fam_9', 5, 42, 8, 42, 0.38461538461538464, 1.0, 0.84, 0.9199999999999999]\n",
      "[14, 0.5640589403747298, 1.0000000000000002, 0.8378090329563832, 0.9189045164781915]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_136 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 11s 208us/step - loss: 0.4194 - mean_absolute_error: 0.1527 - val_loss: 0.4081 - val_mean_absolute_error: 0.1426\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 8s 152us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1421\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 8s 155us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1422\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 8s 152us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4082 - val_mean_absolute_error: 0.1406\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 8s 153us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1418\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 8s 154us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1406\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1411\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1404\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 8s 150us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1422\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1419\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 8s 152us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1420\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 8s 154us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1411\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 8s 155us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1413\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 8s 154us/step - loss: 0.4080 - mean_absolute_error: 0.1415 - val_loss: 0.4079 - val_mean_absolute_error: 0.1424\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 8s 155us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1423\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 8s 152us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1413\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 8s 154us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 8s 153us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 8s 155us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1423\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 8s 157us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1417\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_137 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 10s 211us/step - loss: 0.2186 - mean_absolute_error: 0.0751 - val_loss: 0.1931 - val_mean_absolute_error: 0.0501\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 148us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0519\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0508\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0507\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 145us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0531\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0506\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 143us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1932 - val_mean_absolute_error: 0.0505\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0531\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1931 - val_mean_absolute_error: 0.0510\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 145us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 142us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_138 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 230us/step - loss: 0.2182 - mean_absolute_error: 0.0953 - val_loss: 0.1805 - val_mean_absolute_error: 0.0622\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0616\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1805 - val_mean_absolute_error: 0.0628\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1790 - mean_absolute_error: 0.0612 - val_loss: 0.1748 - val_mean_absolute_error: 0.0589\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1702 - mean_absolute_error: 0.0550 - val_loss: 0.1660 - val_mean_absolute_error: 0.0525\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1625 - mean_absolute_error: 0.0489 - val_loss: 0.1594 - val_mean_absolute_error: 0.0462\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1569 - mean_absolute_error: 0.0441 - val_loss: 0.1547 - val_mean_absolute_error: 0.0419\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1529 - mean_absolute_error: 0.0402 - val_loss: 0.1514 - val_mean_absolute_error: 0.0381\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1501 - mean_absolute_error: 0.0371 - val_loss: 0.1489 - val_mean_absolute_error: 0.0361\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1481 - mean_absolute_error: 0.0353 - val_loss: 0.1473 - val_mean_absolute_error: 0.0345\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1468 - mean_absolute_error: 0.0342 - val_loss: 0.1463 - val_mean_absolute_error: 0.0337\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1459 - mean_absolute_error: 0.0333 - val_loss: 0.1455 - val_mean_absolute_error: 0.0333\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1453 - mean_absolute_error: 0.0327 - val_loss: 0.1449 - val_mean_absolute_error: 0.0326\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1448 - mean_absolute_error: 0.0322 - val_loss: 0.1447 - val_mean_absolute_error: 0.0321\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 143us/step - loss: 0.1444 - mean_absolute_error: 0.0318 - val_loss: 0.1442 - val_mean_absolute_error: 0.0320\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1440 - mean_absolute_error: 0.0315 - val_loss: 0.1439 - val_mean_absolute_error: 0.0315\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1438 - mean_absolute_error: 0.0312 - val_loss: 0.1440 - val_mean_absolute_error: 0.0311\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1435 - mean_absolute_error: 0.0309 - val_loss: 0.1433 - val_mean_absolute_error: 0.0307\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1433 - mean_absolute_error: 0.0306 - val_loss: 0.1432 - val_mean_absolute_error: 0.0304\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1431 - mean_absolute_error: 0.0304 - val_loss: 0.1430 - val_mean_absolute_error: 0.0303\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_139 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 232us/step - loss: 0.1944 - mean_absolute_error: 0.0882 - val_loss: 0.1276 - val_mean_absolute_error: 0.0242\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1235 - mean_absolute_error: 0.0199 - val_loss: 0.1211 - val_mean_absolute_error: 0.0174\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 151us/step - loss: 0.1200 - mean_absolute_error: 0.0162 - val_loss: 0.1191 - val_mean_absolute_error: 0.0153\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1184 - mean_absolute_error: 0.0146 - val_loss: 0.1179 - val_mean_absolute_error: 0.0142\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 150us/step - loss: 0.1175 - mean_absolute_error: 0.0137 - val_loss: 0.1172 - val_mean_absolute_error: 0.0134\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 151us/step - loss: 0.1168 - mean_absolute_error: 0.0130 - val_loss: 0.1165 - val_mean_absolute_error: 0.0126\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1162 - mean_absolute_error: 0.0121 - val_loss: 0.1159 - val_mean_absolute_error: 0.0117\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1157 - mean_absolute_error: 0.0116 - val_loss: 0.1155 - val_mean_absolute_error: 0.0114\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1153 - mean_absolute_error: 0.0110 - val_loss: 0.1151 - val_mean_absolute_error: 0.0108\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1149 - mean_absolute_error: 0.0103 - val_loss: 0.1148 - val_mean_absolute_error: 0.0099\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 154us/step - loss: 0.1147 - mean_absolute_error: 0.0099 - val_loss: 0.1146 - val_mean_absolute_error: 0.0104\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1145 - mean_absolute_error: 0.0097 - val_loss: 0.1144 - val_mean_absolute_error: 0.0097\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1143 - mean_absolute_error: 0.0095 - val_loss: 0.1142 - val_mean_absolute_error: 0.0094\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1142 - mean_absolute_error: 0.0094 - val_loss: 0.1141 - val_mean_absolute_error: 0.0093\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1141 - mean_absolute_error: 0.0092 - val_loss: 0.1140 - val_mean_absolute_error: 0.0091\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1139 - mean_absolute_error: 0.0091 - val_loss: 0.1139 - val_mean_absolute_error: 0.0090\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 150us/step - loss: 0.1139 - mean_absolute_error: 0.0089 - val_loss: 0.1138 - val_mean_absolute_error: 0.0088\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1138 - mean_absolute_error: 0.0088 - val_loss: 0.1137 - val_mean_absolute_error: 0.0087\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1137 - mean_absolute_error: 0.0087 - val_loss: 0.1136 - val_mean_absolute_error: 0.0086\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1136 - mean_absolute_error: 0.0085 - val_loss: 0.1134 - val_mean_absolute_error: 0.0084\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_140 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 258us/step - loss: 0.3257 - mean_absolute_error: 0.1253 - val_loss: 0.2490 - val_mean_absolute_error: 0.0449\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2394 - mean_absolute_error: 0.0317 - val_loss: 0.2346 - val_mean_absolute_error: 0.0248\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2332 - mean_absolute_error: 0.0229 - val_loss: 0.2322 - val_mean_absolute_error: 0.0214\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2318 - mean_absolute_error: 0.0209 - val_loss: 0.2313 - val_mean_absolute_error: 0.0203\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2311 - mean_absolute_error: 0.0199 - val_loss: 0.2308 - val_mean_absolute_error: 0.0195\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2307 - mean_absolute_error: 0.0192 - val_loss: 0.2306 - val_mean_absolute_error: 0.0189\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2303 - mean_absolute_error: 0.0186 - val_loss: 0.2296 - val_mean_absolute_error: 0.0177\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2291 - mean_absolute_error: 0.0171 - val_loss: 0.2286 - val_mean_absolute_error: 0.0166\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.2281 - mean_absolute_error: 0.0161 - val_loss: 0.2278 - val_mean_absolute_error: 0.0155\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.2275 - mean_absolute_error: 0.0154 - val_loss: 0.2271 - val_mean_absolute_error: 0.0149\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.2268 - mean_absolute_error: 0.0145 - val_loss: 0.2265 - val_mean_absolute_error: 0.0145\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.2263 - mean_absolute_error: 0.0138 - val_loss: 0.2261 - val_mean_absolute_error: 0.0135\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2260 - mean_absolute_error: 0.0136 - val_loss: 0.2260 - val_mean_absolute_error: 0.0135\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2259 - mean_absolute_error: 0.0134 - val_loss: 0.2258 - val_mean_absolute_error: 0.0132\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.2258 - mean_absolute_error: 0.0134 - val_loss: 0.2257 - val_mean_absolute_error: 0.0132\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2256 - mean_absolute_error: 0.0133 - val_loss: 0.2257 - val_mean_absolute_error: 0.0132\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.2255 - mean_absolute_error: 0.0130 - val_loss: 0.2254 - val_mean_absolute_error: 0.0128\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.2254 - mean_absolute_error: 0.0129 - val_loss: 0.2253 - val_mean_absolute_error: 0.0126\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.2253 - mean_absolute_error: 0.0128 - val_loss: 0.2252 - val_mean_absolute_error: 0.0127\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.2252 - mean_absolute_error: 0.0127 - val_loss: 0.2251 - val_mean_absolute_error: 0.0124\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_141 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 251us/step - loss: 0.1169 - mean_absolute_error: 0.0694 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0196\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_142 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 8s 234us/step - loss: 0.2931 - mean_absolute_error: 0.1262 - val_loss: 0.2288 - val_mean_absolute_error: 0.0692\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.2135 - mean_absolute_error: 0.0487 - val_loss: 0.2032 - val_mean_absolute_error: 0.0351\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1986 - mean_absolute_error: 0.0296 - val_loss: 0.1953 - val_mean_absolute_error: 0.0259\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1928 - mean_absolute_error: 0.0231 - val_loss: 0.1904 - val_mean_absolute_error: 0.0203\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1888 - mean_absolute_error: 0.0182 - val_loss: 0.1876 - val_mean_absolute_error: 0.0166\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1868 - mean_absolute_error: 0.0154 - val_loss: 0.1860 - val_mean_absolute_error: 0.0143\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1855 - mean_absolute_error: 0.0135 - val_loss: 0.1850 - val_mean_absolute_error: 0.0128\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1847 - mean_absolute_error: 0.0122 - val_loss: 0.1843 - val_mean_absolute_error: 0.0117\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1841 - mean_absolute_error: 0.0113 - val_loss: 0.1839 - val_mean_absolute_error: 0.0110\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1838 - mean_absolute_error: 0.0107 - val_loss: 0.1837 - val_mean_absolute_error: 0.0105\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 144us/step - loss: 0.1836 - mean_absolute_error: 0.0103 - val_loss: 0.1835 - val_mean_absolute_error: 0.0103\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1835 - mean_absolute_error: 0.0101 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 145us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0098\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_143 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 7s 245us/step - loss: 0.2955 - mean_absolute_error: 0.1109 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0778\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 147us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0781\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0782\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_144 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 252us/step - loss: 0.3745 - mean_absolute_error: 0.1439 - val_loss: 0.3310 - val_mean_absolute_error: 0.1083\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.3182 - mean_absolute_error: 0.0955 - val_loss: 0.3084 - val_mean_absolute_error: 0.0859\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.3026 - mean_absolute_error: 0.0803 - val_loss: 0.2979 - val_mean_absolute_error: 0.0762\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2945 - mean_absolute_error: 0.0741 - val_loss: 0.2909 - val_mean_absolute_error: 0.0712\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2872 - mean_absolute_error: 0.0677 - val_loss: 0.2839 - val_mean_absolute_error: 0.0641\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.2815 - mean_absolute_error: 0.0613 - val_loss: 0.2795 - val_mean_absolute_error: 0.0588\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2777 - mean_absolute_error: 0.0570 - val_loss: 0.2762 - val_mean_absolute_error: 0.0555\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2752 - mean_absolute_error: 0.0545 - val_loss: 0.2743 - val_mean_absolute_error: 0.0535\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2735 - mean_absolute_error: 0.0528 - val_loss: 0.2729 - val_mean_absolute_error: 0.0521\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2724 - mean_absolute_error: 0.0516 - val_loss: 0.2719 - val_mean_absolute_error: 0.0511\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2716 - mean_absolute_error: 0.0508 - val_loss: 0.2715 - val_mean_absolute_error: 0.0504\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2710 - mean_absolute_error: 0.0501 - val_loss: 0.2705 - val_mean_absolute_error: 0.0497\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2704 - mean_absolute_error: 0.0497 - val_loss: 0.2700 - val_mean_absolute_error: 0.0494\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2700 - mean_absolute_error: 0.0493 - val_loss: 0.2698 - val_mean_absolute_error: 0.0490\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2700 - val_mean_absolute_error: 0.0493\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2694 - mean_absolute_error: 0.0488 - val_loss: 0.2695 - val_mean_absolute_error: 0.0489\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2692 - mean_absolute_error: 0.0486 - val_loss: 0.2723 - val_mean_absolute_error: 0.0505\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.2690 - mean_absolute_error: 0.0484 - val_loss: 0.2698 - val_mean_absolute_error: 0.0488\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.2688 - mean_absolute_error: 0.0482 - val_loss: 0.2684 - val_mean_absolute_error: 0.0477\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2683 - val_mean_absolute_error: 0.0477\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_136 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.189120\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_1', 9, 36, 10, 36, 0.47368421052631576, 1.0, 0.782608695652174, 0.8913043478260869]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_137 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_273 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.141136\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_138 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_275 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.038899\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_3', 6, 45, 4, 45, 0.6, 1.0, 0.9183673469387755, 0.9591836734693877]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_139 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_277 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.018155\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_4', 6, 48, 1, 48, 0.8571428571428571, 1.0, 0.9795918367346939, 0.9897959183673469]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_140 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_279 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028233\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_141 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_281 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023045\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_142 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_283 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028647\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_143 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_285 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_286 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100733\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_144 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_287 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_288 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.070469\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[15, 'fam_9', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "[15, 0.6049624812782707, 1.0000000000000002, 0.8491922529110318, 0.924596126455516]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_145 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 11s 205us/step - loss: 0.4195 - mean_absolute_error: 0.1527 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1420\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 8s 147us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1420\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1421\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1417\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1428\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1414\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 8s 150us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1420\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 8s 149us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1411\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 8s 152us/step - loss: 0.3976 - mean_absolute_error: 0.1349 - val_loss: 0.3831 - val_mean_absolute_error: 0.1250\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 8s 152us/step - loss: 0.3721 - mean_absolute_error: 0.1174 - val_loss: 0.3625 - val_mean_absolute_error: 0.1097\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 9s 160us/step - loss: 0.3555 - mean_absolute_error: 0.1040 - val_loss: 0.3495 - val_mean_absolute_error: 0.0975\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 8s 153us/step - loss: 0.3445 - mean_absolute_error: 0.0932 - val_loss: 0.3385 - val_mean_absolute_error: 0.0871\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 8s 156us/step - loss: 0.3338 - mean_absolute_error: 0.0826 - val_loss: 0.3288 - val_mean_absolute_error: 0.0793\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 8s 153us/step - loss: 0.3263 - mean_absolute_error: 0.0766 - val_loss: 0.3227 - val_mean_absolute_error: 0.0739\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 8s 150us/step - loss: 0.3219 - mean_absolute_error: 0.0723 - val_loss: 0.3190 - val_mean_absolute_error: 0.0702\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 8s 153us/step - loss: 0.3192 - mean_absolute_error: 0.0696 - val_loss: 0.3169 - val_mean_absolute_error: 0.0684\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.3176 - mean_absolute_error: 0.0680 - val_loss: 0.3150 - val_mean_absolute_error: 0.0664\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 8s 151us/step - loss: 0.3164 - mean_absolute_error: 0.0670 - val_loss: 0.3165 - val_mean_absolute_error: 0.0657\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 8s 154us/step - loss: 0.3155 - mean_absolute_error: 0.0662 - val_loss: 0.3129 - val_mean_absolute_error: 0.0643\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_146 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 11s 223us/step - loss: 0.2185 - mean_absolute_error: 0.0751 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 7s 148us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0526\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 7s 145us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0517\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 7s 148us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0529\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1916 - mean_absolute_error: 0.0513 - val_loss: 0.1871 - val_mean_absolute_error: 0.0501\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1816 - mean_absolute_error: 0.0478 - val_loss: 0.1765 - val_mean_absolute_error: 0.0450\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1720 - mean_absolute_error: 0.0431 - val_loss: 0.1678 - val_mean_absolute_error: 0.0402\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1642 - mean_absolute_error: 0.0381 - val_loss: 0.1610 - val_mean_absolute_error: 0.0362\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1584 - mean_absolute_error: 0.0332 - val_loss: 0.1561 - val_mean_absolute_error: 0.0307\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 146us/step - loss: 0.1543 - mean_absolute_error: 0.0290 - val_loss: 0.1527 - val_mean_absolute_error: 0.0268\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1516 - mean_absolute_error: 0.0258 - val_loss: 0.1506 - val_mean_absolute_error: 0.0244\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 7s 149us/step - loss: 0.1499 - mean_absolute_error: 0.0234 - val_loss: 0.1493 - val_mean_absolute_error: 0.0227\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 7s 147us/step - loss: 0.1489 - mean_absolute_error: 0.0219 - val_loss: 0.1485 - val_mean_absolute_error: 0.0213\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 7s 150us/step - loss: 0.1483 - mean_absolute_error: 0.0210 - val_loss: 0.1481 - val_mean_absolute_error: 0.0208\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 7s 151us/step - loss: 0.1474 - mean_absolute_error: 0.0207 - val_loss: 0.1470 - val_mean_absolute_error: 0.0205\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_147 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 9s 246us/step - loss: 0.2182 - mean_absolute_error: 0.0952 - val_loss: 0.1805 - val_mean_absolute_error: 0.0624\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 154us/step - loss: 0.1786 - mean_absolute_error: 0.0610 - val_loss: 0.1742 - val_mean_absolute_error: 0.0574\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1696 - mean_absolute_error: 0.0545 - val_loss: 0.1655 - val_mean_absolute_error: 0.0510\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1621 - mean_absolute_error: 0.0485 - val_loss: 0.1590 - val_mean_absolute_error: 0.0456\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1566 - mean_absolute_error: 0.0438 - val_loss: 0.1546 - val_mean_absolute_error: 0.0413\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1527 - mean_absolute_error: 0.0399 - val_loss: 0.1511 - val_mean_absolute_error: 0.0381\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 153us/step - loss: 0.1499 - mean_absolute_error: 0.0370 - val_loss: 0.1488 - val_mean_absolute_error: 0.0359\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 154us/step - loss: 0.1480 - mean_absolute_error: 0.0352 - val_loss: 0.1473 - val_mean_absolute_error: 0.0347\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 157us/step - loss: 0.1467 - mean_absolute_error: 0.0341 - val_loss: 0.1462 - val_mean_absolute_error: 0.0335\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1458 - mean_absolute_error: 0.0333 - val_loss: 0.1455 - val_mean_absolute_error: 0.0329\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1452 - mean_absolute_error: 0.0327 - val_loss: 0.1454 - val_mean_absolute_error: 0.0325\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1448 - mean_absolute_error: 0.0322 - val_loss: 0.1445 - val_mean_absolute_error: 0.0319\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1444 - mean_absolute_error: 0.0318 - val_loss: 0.1444 - val_mean_absolute_error: 0.0318\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1440 - mean_absolute_error: 0.0314 - val_loss: 0.1439 - val_mean_absolute_error: 0.0313\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1438 - mean_absolute_error: 0.0311 - val_loss: 0.1436 - val_mean_absolute_error: 0.0310\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1435 - mean_absolute_error: 0.0309 - val_loss: 0.1434 - val_mean_absolute_error: 0.0306\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1433 - mean_absolute_error: 0.0306 - val_loss: 0.1433 - val_mean_absolute_error: 0.0309\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1431 - mean_absolute_error: 0.0304 - val_loss: 0.1430 - val_mean_absolute_error: 0.0301\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1429 - mean_absolute_error: 0.0302 - val_loss: 0.1428 - val_mean_absolute_error: 0.0299\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1428 - mean_absolute_error: 0.0300 - val_loss: 0.1427 - val_mean_absolute_error: 0.0297\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_148 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 9s 238us/step - loss: 0.1938 - mean_absolute_error: 0.0873 - val_loss: 0.1267 - val_mean_absolute_error: 0.0232\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 5s 151us/step - loss: 0.1231 - mean_absolute_error: 0.0194 - val_loss: 0.1210 - val_mean_absolute_error: 0.0171\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1199 - mean_absolute_error: 0.0161 - val_loss: 0.1190 - val_mean_absolute_error: 0.0152\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1184 - mean_absolute_error: 0.0146 - val_loss: 0.1178 - val_mean_absolute_error: 0.0141\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1166 - mean_absolute_error: 0.0122 - val_loss: 0.1158 - val_mean_absolute_error: 0.0112\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1153 - mean_absolute_error: 0.0105 - val_loss: 0.1150 - val_mean_absolute_error: 0.0100\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1147 - mean_absolute_error: 0.0098 - val_loss: 0.1144 - val_mean_absolute_error: 0.0095\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1142 - mean_absolute_error: 0.0096 - val_loss: 0.1140 - val_mean_absolute_error: 0.0095\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1138 - mean_absolute_error: 0.0093 - val_loss: 0.1136 - val_mean_absolute_error: 0.0087\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1136 - mean_absolute_error: 0.0088 - val_loss: 0.1135 - val_mean_absolute_error: 0.0093\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1134 - mean_absolute_error: 0.0085 - val_loss: 0.1134 - val_mean_absolute_error: 0.0091\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1133 - mean_absolute_error: 0.0083 - val_loss: 0.1132 - val_mean_absolute_error: 0.0083\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1132 - mean_absolute_error: 0.0082 - val_loss: 0.1131 - val_mean_absolute_error: 0.0080\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 146us/step - loss: 0.1131 - mean_absolute_error: 0.0082 - val_loss: 0.1131 - val_mean_absolute_error: 0.0082\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1130 - mean_absolute_error: 0.0081 - val_loss: 0.1130 - val_mean_absolute_error: 0.0082\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1129 - mean_absolute_error: 0.0080 - val_loss: 0.1129 - val_mean_absolute_error: 0.0077\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1129 - mean_absolute_error: 0.0079 - val_loss: 0.1128 - val_mean_absolute_error: 0.0081\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1128 - mean_absolute_error: 0.0078 - val_loss: 0.1127 - val_mean_absolute_error: 0.0077\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1127 - mean_absolute_error: 0.0077 - val_loss: 0.1126 - val_mean_absolute_error: 0.0074\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 147us/step - loss: 0.1126 - mean_absolute_error: 0.0075 - val_loss: 0.1124 - val_mean_absolute_error: 0.0071\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_149 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3254 - mean_absolute_error: 0.1258 - val_loss: 0.2505 - val_mean_absolute_error: 0.0476\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2413 - mean_absolute_error: 0.0334 - val_loss: 0.2366 - val_mean_absolute_error: 0.0263\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2352 - mean_absolute_error: 0.0243 - val_loss: 0.2342 - val_mean_absolute_error: 0.0232\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2334 - mean_absolute_error: 0.0223 - val_loss: 0.2326 - val_mean_absolute_error: 0.0214\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2316 - mean_absolute_error: 0.0202 - val_loss: 0.2306 - val_mean_absolute_error: 0.0190\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2297 - mean_absolute_error: 0.0180 - val_loss: 0.2286 - val_mean_absolute_error: 0.0170\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2278 - mean_absolute_error: 0.0158 - val_loss: 0.2273 - val_mean_absolute_error: 0.0152\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2268 - mean_absolute_error: 0.0144 - val_loss: 0.2265 - val_mean_absolute_error: 0.0140\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2263 - mean_absolute_error: 0.0138 - val_loss: 0.2262 - val_mean_absolute_error: 0.0137\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2260 - mean_absolute_error: 0.0136 - val_loss: 0.2259 - val_mean_absolute_error: 0.0136\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2258 - mean_absolute_error: 0.0134 - val_loss: 0.2257 - val_mean_absolute_error: 0.0129\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2256 - mean_absolute_error: 0.0130 - val_loss: 0.2255 - val_mean_absolute_error: 0.0131\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2255 - mean_absolute_error: 0.0129 - val_loss: 0.2254 - val_mean_absolute_error: 0.0127\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2254 - mean_absolute_error: 0.0127 - val_loss: 0.2253 - val_mean_absolute_error: 0.0125\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2253 - mean_absolute_error: 0.0125 - val_loss: 0.2253 - val_mean_absolute_error: 0.0133\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2252 - mean_absolute_error: 0.0125 - val_loss: 0.2251 - val_mean_absolute_error: 0.0125\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2251 - mean_absolute_error: 0.0126 - val_loss: 0.2251 - val_mean_absolute_error: 0.0124\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2250 - mean_absolute_error: 0.0124 - val_loss: 0.2250 - val_mean_absolute_error: 0.0121\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.2250 - mean_absolute_error: 0.0121 - val_loss: 0.2249 - val_mean_absolute_error: 0.0119\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2249 - mean_absolute_error: 0.0120 - val_loss: 0.2250 - val_mean_absolute_error: 0.0120\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_150 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 264us/step - loss: 0.1170 - mean_absolute_error: 0.0694 - val_loss: 0.0598 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_151 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 9s 240us/step - loss: 0.2897 - mean_absolute_error: 0.1239 - val_loss: 0.2262 - val_mean_absolute_error: 0.0670\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.2120 - mean_absolute_error: 0.0471 - val_loss: 0.2021 - val_mean_absolute_error: 0.0338\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1979 - mean_absolute_error: 0.0288 - val_loss: 0.1949 - val_mean_absolute_error: 0.0256\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1931 - mean_absolute_error: 0.0234 - val_loss: 0.1911 - val_mean_absolute_error: 0.0211\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 5s 150us/step - loss: 0.1893 - mean_absolute_error: 0.0187 - val_loss: 0.1878 - val_mean_absolute_error: 0.0166\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1866 - mean_absolute_error: 0.0148 - val_loss: 0.1854 - val_mean_absolute_error: 0.0131\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 5s 150us/step - loss: 0.1847 - mean_absolute_error: 0.0120 - val_loss: 0.1841 - val_mean_absolute_error: 0.0112\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1838 - mean_absolute_error: 0.0107 - val_loss: 0.1836 - val_mean_absolute_error: 0.0103\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 5s 151us/step - loss: 0.1835 - mean_absolute_error: 0.0101 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0098\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1833 - mean_absolute_error: 0.0098 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1832 - mean_absolute_error: 0.0098 - val_loss: 0.1831 - val_mean_absolute_error: 0.0098\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1831 - mean_absolute_error: 0.0098 - val_loss: 0.1831 - val_mean_absolute_error: 0.0098\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 5s 151us/step - loss: 0.1831 - mean_absolute_error: 0.0098 - val_loss: 0.1831 - val_mean_absolute_error: 0.0098\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1831 - mean_absolute_error: 0.0097 - val_loss: 0.1830 - val_mean_absolute_error: 0.0098\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1830 - mean_absolute_error: 0.0097 - val_loss: 0.1830 - val_mean_absolute_error: 0.0098\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 5s 150us/step - loss: 0.1830 - mean_absolute_error: 0.0097 - val_loss: 0.1830 - val_mean_absolute_error: 0.0097\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 5s 151us/step - loss: 0.1830 - mean_absolute_error: 0.0097 - val_loss: 0.1830 - val_mean_absolute_error: 0.0097\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 5s 149us/step - loss: 0.1830 - mean_absolute_error: 0.0097 - val_loss: 0.1830 - val_mean_absolute_error: 0.0097\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 5s 148us/step - loss: 0.1830 - mean_absolute_error: 0.0097 - val_loss: 0.1829 - val_mean_absolute_error: 0.0098\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_152 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 260us/step - loss: 0.2954 - mean_absolute_error: 0.1108 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0793\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 4s 148us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0786\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 4s 149us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 4s 150us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0793\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0792\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0782\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0792\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_153 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 257us/step - loss: 0.3778 - mean_absolute_error: 0.1462 - val_loss: 0.3386 - val_mean_absolute_error: 0.1126\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 150us/step - loss: 0.3279 - mean_absolute_error: 0.1042 - val_loss: 0.3186 - val_mean_absolute_error: 0.0956\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 152us/step - loss: 0.3121 - mean_absolute_error: 0.0897 - val_loss: 0.3068 - val_mean_absolute_error: 0.0846\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.3030 - mean_absolute_error: 0.0806 - val_loss: 0.2999 - val_mean_absolute_error: 0.0783\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.2978 - mean_absolute_error: 0.0758 - val_loss: 0.2959 - val_mean_absolute_error: 0.0739\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.2947 - mean_absolute_error: 0.0737 - val_loss: 0.2938 - val_mean_absolute_error: 0.0720\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2925 - mean_absolute_error: 0.0726 - val_loss: 0.2913 - val_mean_absolute_error: 0.0732\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2899 - mean_absolute_error: 0.0711 - val_loss: 0.2885 - val_mean_absolute_error: 0.0712\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.2865 - mean_absolute_error: 0.0686 - val_loss: 0.2844 - val_mean_absolute_error: 0.0664\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2825 - mean_absolute_error: 0.0648 - val_loss: 0.2801 - val_mean_absolute_error: 0.0622\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2787 - mean_absolute_error: 0.0603 - val_loss: 0.2771 - val_mean_absolute_error: 0.0580\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.2761 - mean_absolute_error: 0.0565 - val_loss: 0.2750 - val_mean_absolute_error: 0.0550\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.2742 - mean_absolute_error: 0.0540 - val_loss: 0.2733 - val_mean_absolute_error: 0.0530\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.2729 - mean_absolute_error: 0.0524 - val_loss: 0.2721 - val_mean_absolute_error: 0.0516\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2719 - mean_absolute_error: 0.0513 - val_loss: 0.2713 - val_mean_absolute_error: 0.0507\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2712 - mean_absolute_error: 0.0506 - val_loss: 0.2706 - val_mean_absolute_error: 0.0500\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 151us/step - loss: 0.2707 - mean_absolute_error: 0.0500 - val_loss: 0.2707 - val_mean_absolute_error: 0.0500\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 153us/step - loss: 0.2702 - mean_absolute_error: 0.0496 - val_loss: 0.2706 - val_mean_absolute_error: 0.0497\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.2699 - mean_absolute_error: 0.0492 - val_loss: 0.2694 - val_mean_absolute_error: 0.0487\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 154us/step - loss: 0.2696 - mean_absolute_error: 0.0489 - val_loss: 0.2691 - val_mean_absolute_error: 0.0485\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_145 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_289 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_290 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.101951\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_1', 9, 28, 18, 28, 0.3333333333333333, 1.0, 0.6086956521739131, 0.8043478260869565]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_146 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_291 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_292 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.038207\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_2', 8, 46, 1, 46, 0.8888888888888888, 1.0, 0.9787234042553191, 0.9893617021276595]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_147 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_293 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_294 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.039322\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_3', 6, 44, 5, 44, 0.5454545454545454, 1.0, 0.8979591836734694, 0.9489795918367347]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_148 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_295 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_296 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.021422\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_4', 6, 46, 3, 46, 0.6666666666666666, 1.0, 0.9387755102040817, 0.9693877551020409]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_149 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_297 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_298 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.031731\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_150 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_299 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_300 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022849\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_151 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_301 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_302 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028649\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_152 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_303 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_304 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100130\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_153 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_305 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_306 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.072190\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[16, 'fam_9', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "[16, 0.6368847202180535, 1.0000000000000002, 0.8892597137529079, 0.944629856876454]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_154 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 13s 239us/step - loss: 0.4194 - mean_absolute_error: 0.1526 - val_loss: 0.4079 - val_mean_absolute_error: 0.1410\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 9s 168us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1410\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 9s 172us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1415\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 9s 172us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1409\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 11s 206us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1417\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 11s 195us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1410\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 10s 188us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1425\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 10s 186us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1414\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 9s 174us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1415\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 10s 181us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1413\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1409\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 10s 177us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1416\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 9s 162us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1412\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 10s 179us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1423\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 10s 186us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1425\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 10s 179us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1410\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 9s 165us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1419\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 10s 178us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1425\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 9s 167us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1433\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 9s 169us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1417\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_155 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 12s 241us/step - loss: 0.2187 - mean_absolute_error: 0.0752 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 156us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0513\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 7s 156us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0521\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 8s 166us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 8s 177us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0516\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0527\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1931 - val_mean_absolute_error: 0.0503\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.1930 - mean_absolute_error: 0.0516 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0528\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0517\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0505\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 8s 170us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1931 - val_mean_absolute_error: 0.0502\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0515\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0514\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0527\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0520\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_156 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 10s 270us/step - loss: 0.2183 - mean_absolute_error: 0.0953 - val_loss: 0.1806 - val_mean_absolute_error: 0.0627\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1805 - mean_absolute_error: 0.0622 - val_loss: 0.1805 - val_mean_absolute_error: 0.0632\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1806 - val_mean_absolute_error: 0.0633\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1769 - mean_absolute_error: 0.0597 - val_loss: 0.1719 - val_mean_absolute_error: 0.0566\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1677 - mean_absolute_error: 0.0531 - val_loss: 0.1638 - val_mean_absolute_error: 0.0501\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1606 - mean_absolute_error: 0.0473 - val_loss: 0.1578 - val_mean_absolute_error: 0.0450\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1556 - mean_absolute_error: 0.0428 - val_loss: 0.1536 - val_mean_absolute_error: 0.0411\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1519 - mean_absolute_error: 0.0391 - val_loss: 0.1505 - val_mean_absolute_error: 0.0379\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1494 - mean_absolute_error: 0.0365 - val_loss: 0.1484 - val_mean_absolute_error: 0.0357\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1476 - mean_absolute_error: 0.0349 - val_loss: 0.1472 - val_mean_absolute_error: 0.0347\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1465 - mean_absolute_error: 0.0339 - val_loss: 0.1460 - val_mean_absolute_error: 0.0332\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1457 - mean_absolute_error: 0.0331 - val_loss: 0.1453 - val_mean_absolute_error: 0.0326\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1451 - mean_absolute_error: 0.0326 - val_loss: 0.1448 - val_mean_absolute_error: 0.0321\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1446 - mean_absolute_error: 0.0321 - val_loss: 0.1448 - val_mean_absolute_error: 0.0326\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1443 - mean_absolute_error: 0.0317 - val_loss: 0.1442 - val_mean_absolute_error: 0.0318\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1440 - mean_absolute_error: 0.0314 - val_loss: 0.1438 - val_mean_absolute_error: 0.0309\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1437 - mean_absolute_error: 0.0311 - val_loss: 0.1436 - val_mean_absolute_error: 0.0310\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 153us/step - loss: 0.1435 - mean_absolute_error: 0.0308 - val_loss: 0.1435 - val_mean_absolute_error: 0.0310\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 154us/step - loss: 0.1432 - mean_absolute_error: 0.0306 - val_loss: 0.1432 - val_mean_absolute_error: 0.0306\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1431 - mean_absolute_error: 0.0303 - val_loss: 0.1433 - val_mean_absolute_error: 0.0302\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_157 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 9s 262us/step - loss: 0.1955 - mean_absolute_error: 0.0895 - val_loss: 0.1302 - val_mean_absolute_error: 0.0271\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1256 - mean_absolute_error: 0.0223 - val_loss: 0.1229 - val_mean_absolute_error: 0.0195\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1216 - mean_absolute_error: 0.0179 - val_loss: 0.1205 - val_mean_absolute_error: 0.0166\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 157us/step - loss: 0.1198 - mean_absolute_error: 0.0159 - val_loss: 0.1193 - val_mean_absolute_error: 0.0151\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1189 - mean_absolute_error: 0.0147 - val_loss: 0.1186 - val_mean_absolute_error: 0.0144\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1184 - mean_absolute_error: 0.0142 - val_loss: 0.1182 - val_mean_absolute_error: 0.0141\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1180 - mean_absolute_error: 0.0141 - val_loss: 0.1178 - val_mean_absolute_error: 0.0139\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1175 - mean_absolute_error: 0.0138 - val_loss: 0.1172 - val_mean_absolute_error: 0.0135\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1168 - mean_absolute_error: 0.0130 - val_loss: 0.1162 - val_mean_absolute_error: 0.0123\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1158 - mean_absolute_error: 0.0117 - val_loss: 0.1154 - val_mean_absolute_error: 0.0110\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1151 - mean_absolute_error: 0.0105 - val_loss: 0.1149 - val_mean_absolute_error: 0.0108\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1147 - mean_absolute_error: 0.0097 - val_loss: 0.1145 - val_mean_absolute_error: 0.0095\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1144 - mean_absolute_error: 0.0093 - val_loss: 0.1144 - val_mean_absolute_error: 0.0096\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1143 - mean_absolute_error: 0.0091 - val_loss: 0.1143 - val_mean_absolute_error: 0.0089\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1142 - mean_absolute_error: 0.0089 - val_loss: 0.1142 - val_mean_absolute_error: 0.0088\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1141 - mean_absolute_error: 0.0087 - val_loss: 0.1141 - val_mean_absolute_error: 0.0089\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 168us/step - loss: 0.1141 - mean_absolute_error: 0.0087 - val_loss: 0.1141 - val_mean_absolute_error: 0.0086\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1140 - val_mean_absolute_error: 0.0086\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1141 - val_mean_absolute_error: 0.0088\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1140 - mean_absolute_error: 0.0086 - val_loss: 0.1140 - val_mean_absolute_error: 0.0086\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_158 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.3240 - mean_absolute_error: 0.1222 - val_loss: 0.2473 - val_mean_absolute_error: 0.0424\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.2381 - mean_absolute_error: 0.0295 - val_loss: 0.2332 - val_mean_absolute_error: 0.0226\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2313 - mean_absolute_error: 0.0197 - val_loss: 0.2299 - val_mean_absolute_error: 0.0179\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2291 - mean_absolute_error: 0.0168 - val_loss: 0.2284 - val_mean_absolute_error: 0.0160\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2279 - mean_absolute_error: 0.0155 - val_loss: 0.2274 - val_mean_absolute_error: 0.0149\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2269 - mean_absolute_error: 0.0143 - val_loss: 0.2266 - val_mean_absolute_error: 0.0139\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2263 - mean_absolute_error: 0.0135 - val_loss: 0.2262 - val_mean_absolute_error: 0.0132\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2261 - mean_absolute_error: 0.0131 - val_loss: 0.2261 - val_mean_absolute_error: 0.0131\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2260 - mean_absolute_error: 0.0130 - val_loss: 0.2260 - val_mean_absolute_error: 0.0129\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2259 - mean_absolute_error: 0.0130 - val_loss: 0.2259 - val_mean_absolute_error: 0.0133\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2259 - mean_absolute_error: 0.0130 - val_loss: 0.2259 - val_mean_absolute_error: 0.0130\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2258 - mean_absolute_error: 0.0131 - val_loss: 0.2258 - val_mean_absolute_error: 0.0129\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2258 - mean_absolute_error: 0.0132 - val_loss: 0.2258 - val_mean_absolute_error: 0.0131\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.2257 - mean_absolute_error: 0.0133 - val_loss: 0.2259 - val_mean_absolute_error: 0.0141\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2256 - mean_absolute_error: 0.0134 - val_loss: 0.2256 - val_mean_absolute_error: 0.0136\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2255 - mean_absolute_error: 0.0133 - val_loss: 0.2257 - val_mean_absolute_error: 0.0141\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.2253 - mean_absolute_error: 0.0130 - val_loss: 0.2254 - val_mean_absolute_error: 0.0133\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2252 - mean_absolute_error: 0.0127 - val_loss: 0.2252 - val_mean_absolute_error: 0.0125\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2251 - mean_absolute_error: 0.0126 - val_loss: 0.2251 - val_mean_absolute_error: 0.0123\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2251 - mean_absolute_error: 0.0125 - val_loss: 0.2250 - val_mean_absolute_error: 0.0124\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_159 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 291us/step - loss: 0.1172 - mean_absolute_error: 0.0695 - val_loss: 0.0598 - val_mean_absolute_error: 0.0200\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 178us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_160 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 10s 272us/step - loss: 0.2966 - mean_absolute_error: 0.1304 - val_loss: 0.2334 - val_mean_absolute_error: 0.0771\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.2123 - mean_absolute_error: 0.0539 - val_loss: 0.1998 - val_mean_absolute_error: 0.0379\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1939 - mean_absolute_error: 0.0279 - val_loss: 0.1892 - val_mean_absolute_error: 0.0200\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1866 - mean_absolute_error: 0.0156 - val_loss: 0.1850 - val_mean_absolute_error: 0.0128\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1843 - mean_absolute_error: 0.0116 - val_loss: 0.1839 - val_mean_absolute_error: 0.0109\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1836 - mean_absolute_error: 0.0105 - val_loss: 0.1835 - val_mean_absolute_error: 0.0103\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1834 - mean_absolute_error: 0.0101 - val_loss: 0.1834 - val_mean_absolute_error: 0.0100\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1833 - mean_absolute_error: 0.0099 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1831 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0101\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1831 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0103\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1831 - mean_absolute_error: 0.0101 - val_loss: 0.1833 - val_mean_absolute_error: 0.0110\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1830 - mean_absolute_error: 0.0100 - val_loss: 0.1830 - val_mean_absolute_error: 0.0099\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1830 - mean_absolute_error: 0.0100 - val_loss: 0.1830 - val_mean_absolute_error: 0.0098\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 157us/step - loss: 0.1830 - mean_absolute_error: 0.0100 - val_loss: 0.1830 - val_mean_absolute_error: 0.0099\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_161 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 8s 276us/step - loss: 0.2957 - mean_absolute_error: 0.1112 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0793\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 6s 190us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0790\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0785\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 155us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 156us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2597 - val_mean_absolute_error: 0.0784\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0785\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2594 - val_mean_absolute_error: 0.0785\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 157us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_162 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.3710 - mean_absolute_error: 0.1411 - val_loss: 0.3199 - val_mean_absolute_error: 0.0964\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 6s 187us/step - loss: 0.3065 - mean_absolute_error: 0.0842 - val_loss: 0.2970 - val_mean_absolute_error: 0.0755\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.2913 - mean_absolute_error: 0.0700 - val_loss: 0.2867 - val_mean_absolute_error: 0.0653\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.2835 - mean_absolute_error: 0.0621 - val_loss: 0.2807 - val_mean_absolute_error: 0.0595\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.2786 - mean_absolute_error: 0.0577 - val_loss: 0.2768 - val_mean_absolute_error: 0.0561\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2753 - mean_absolute_error: 0.0552 - val_loss: 0.2737 - val_mean_absolute_error: 0.0552\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.2717 - mean_absolute_error: 0.0531 - val_loss: 0.2691 - val_mean_absolute_error: 0.0514\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.2666 - mean_absolute_error: 0.0484 - val_loss: 0.2640 - val_mean_absolute_error: 0.0454\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2619 - mean_absolute_error: 0.0424 - val_loss: 0.2600 - val_mean_absolute_error: 0.0396\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.2587 - mean_absolute_error: 0.0379 - val_loss: 0.2577 - val_mean_absolute_error: 0.0365\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2569 - mean_absolute_error: 0.0355 - val_loss: 0.2562 - val_mean_absolute_error: 0.0346\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2558 - mean_absolute_error: 0.0339 - val_loss: 0.2553 - val_mean_absolute_error: 0.0333\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2550 - mean_absolute_error: 0.0328 - val_loss: 0.2547 - val_mean_absolute_error: 0.0325\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.2545 - mean_absolute_error: 0.0321 - val_loss: 0.2543 - val_mean_absolute_error: 0.0319\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2542 - mean_absolute_error: 0.0317 - val_loss: 0.2541 - val_mean_absolute_error: 0.0314\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2540 - mean_absolute_error: 0.0313 - val_loss: 0.2539 - val_mean_absolute_error: 0.0313\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2538 - mean_absolute_error: 0.0311 - val_loss: 0.2537 - val_mean_absolute_error: 0.0309\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2537 - mean_absolute_error: 0.0309 - val_loss: 0.2535 - val_mean_absolute_error: 0.0307\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2536 - mean_absolute_error: 0.0308 - val_loss: 0.2535 - val_mean_absolute_error: 0.0308\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2535 - mean_absolute_error: 0.0306 - val_loss: 0.2536 - val_mean_absolute_error: 0.0308\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_154 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_307 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_308 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.187938\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_1', 9, 36, 10, 36, 0.47368421052631576, 1.0, 0.782608695652174, 0.8913043478260869]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_155 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_309 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_310 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.140726\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_2', 8, 18, 29, 18, 0.21621621621621623, 1.0, 0.3829787234042553, 0.6914893617021276]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_156 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_311 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_312 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.040774\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_3', 6, 43, 6, 43, 0.5, 1.0, 0.8775510204081632, 0.9387755102040816]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_157 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_314 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022425\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_4', 6, 44, 5, 44, 0.5454545454545454, 1.0, 0.8979591836734694, 0.9489795918367347]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_158 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_316 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.031129\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_159 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_318 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023062\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_160 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028649\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_161 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_322 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.101029\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_162 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_324 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.043920\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[17, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[17, 0.6306479069636963, 1.0000000000000002, 0.8555868107341611, 0.9277934053670804]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_163 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 13s 236us/step - loss: 0.4194 - mean_absolute_error: 0.1526 - val_loss: 0.4079 - val_mean_absolute_error: 0.1417\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 9s 163us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1411\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 9s 166us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1408\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 9s 166us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4081 - val_mean_absolute_error: 0.1418\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 9s 165us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1410\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 9s 162us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1417\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 9s 169us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4080 - val_mean_absolute_error: 0.1408\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 9s 166us/step - loss: 0.4080 - mean_absolute_error: 0.1416 - val_loss: 0.4079 - val_mean_absolute_error: 0.1406\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 9s 169us/step - loss: 0.3966 - mean_absolute_error: 0.1343 - val_loss: 0.3821 - val_mean_absolute_error: 0.1248\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 9s 166us/step - loss: 0.3714 - mean_absolute_error: 0.1169 - val_loss: 0.3619 - val_mean_absolute_error: 0.1099\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 9s 168us/step - loss: 0.3549 - mean_absolute_error: 0.1034 - val_loss: 0.3476 - val_mean_absolute_error: 0.0970\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 9s 166us/step - loss: 0.3405 - mean_absolute_error: 0.0895 - val_loss: 0.3346 - val_mean_absolute_error: 0.0840\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 9s 168us/step - loss: 0.3306 - mean_absolute_error: 0.0798 - val_loss: 0.3275 - val_mean_absolute_error: 0.0781\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 9s 169us/step - loss: 0.3244 - mean_absolute_error: 0.0744 - val_loss: 0.3212 - val_mean_absolute_error: 0.0719\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 9s 171us/step - loss: 0.3208 - mean_absolute_error: 0.0709 - val_loss: 0.3192 - val_mean_absolute_error: 0.0690\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 9s 173us/step - loss: 0.3186 - mean_absolute_error: 0.0688 - val_loss: 0.3161 - val_mean_absolute_error: 0.0674\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 9s 175us/step - loss: 0.3172 - mean_absolute_error: 0.0676 - val_loss: 0.3172 - val_mean_absolute_error: 0.0665\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 9s 171us/step - loss: 0.3161 - mean_absolute_error: 0.0667 - val_loss: 0.3142 - val_mean_absolute_error: 0.0658\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 11s 194us/step - loss: 0.3154 - mean_absolute_error: 0.0661 - val_loss: 0.3188 - val_mean_absolute_error: 0.0672\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 10s 185us/step - loss: 0.3147 - mean_absolute_error: 0.0655 - val_loss: 0.3172 - val_mean_absolute_error: 0.0660\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_164 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 12s 252us/step - loss: 0.2187 - mean_absolute_error: 0.0751 - val_loss: 0.1930 - val_mean_absolute_error: 0.0518\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1931 - val_mean_absolute_error: 0.0507\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 7s 155us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0509\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 8s 156us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1932 - val_mean_absolute_error: 0.0498\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0507\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 7s 155us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0525\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 7s 154us/step - loss: 0.1892 - mean_absolute_error: 0.0505 - val_loss: 0.1836 - val_mean_absolute_error: 0.0481\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 7s 154us/step - loss: 0.1785 - mean_absolute_error: 0.0464 - val_loss: 0.1736 - val_mean_absolute_error: 0.0446\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.1694 - mean_absolute_error: 0.0416 - val_loss: 0.1655 - val_mean_absolute_error: 0.0399\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 7s 155us/step - loss: 0.1622 - mean_absolute_error: 0.0365 - val_loss: 0.1593 - val_mean_absolute_error: 0.0339\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.1570 - mean_absolute_error: 0.0318 - val_loss: 0.1549 - val_mean_absolute_error: 0.0297\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.1533 - mean_absolute_error: 0.0279 - val_loss: 0.1519 - val_mean_absolute_error: 0.0261\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.1509 - mean_absolute_error: 0.0249 - val_loss: 0.1501 - val_mean_absolute_error: 0.0238\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1495 - mean_absolute_error: 0.0229 - val_loss: 0.1490 - val_mean_absolute_error: 0.0221\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1487 - mean_absolute_error: 0.0216 - val_loss: 0.1484 - val_mean_absolute_error: 0.0206\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_165 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 9s 263us/step - loss: 0.2183 - mean_absolute_error: 0.0953 - val_loss: 0.1805 - val_mean_absolute_error: 0.0625\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0616\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1783 - mean_absolute_error: 0.0607 - val_loss: 0.1737 - val_mean_absolute_error: 0.0579\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1692 - mean_absolute_error: 0.0542 - val_loss: 0.1651 - val_mean_absolute_error: 0.0510\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1618 - mean_absolute_error: 0.0483 - val_loss: 0.1587 - val_mean_absolute_error: 0.0458\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1564 - mean_absolute_error: 0.0436 - val_loss: 0.1543 - val_mean_absolute_error: 0.0419\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1525 - mean_absolute_error: 0.0398 - val_loss: 0.1510 - val_mean_absolute_error: 0.0383\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1498 - mean_absolute_error: 0.0369 - val_loss: 0.1487 - val_mean_absolute_error: 0.0359\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1479 - mean_absolute_error: 0.0351 - val_loss: 0.1473 - val_mean_absolute_error: 0.0347\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1466 - mean_absolute_error: 0.0340 - val_loss: 0.1462 - val_mean_absolute_error: 0.0335\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1458 - mean_absolute_error: 0.0332 - val_loss: 0.1454 - val_mean_absolute_error: 0.0327\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 157us/step - loss: 0.1452 - mean_absolute_error: 0.0327 - val_loss: 0.1449 - val_mean_absolute_error: 0.0324\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.1447 - mean_absolute_error: 0.0322 - val_loss: 0.1445 - val_mean_absolute_error: 0.0320\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1443 - mean_absolute_error: 0.0318 - val_loss: 0.1441 - val_mean_absolute_error: 0.0316\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1440 - mean_absolute_error: 0.0314 - val_loss: 0.1438 - val_mean_absolute_error: 0.0313\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1437 - mean_absolute_error: 0.0311 - val_loss: 0.1435 - val_mean_absolute_error: 0.0308\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.1435 - mean_absolute_error: 0.0308 - val_loss: 0.1433 - val_mean_absolute_error: 0.0307\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1433 - mean_absolute_error: 0.0306 - val_loss: 0.1432 - val_mean_absolute_error: 0.0304\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.1431 - mean_absolute_error: 0.0304 - val_loss: 0.1429 - val_mean_absolute_error: 0.0301\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_166 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 10s 286us/step - loss: 0.1946 - mean_absolute_error: 0.0884 - val_loss: 0.1286 - val_mean_absolute_error: 0.0251\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.1243 - mean_absolute_error: 0.0210 - val_loss: 0.1215 - val_mean_absolute_error: 0.0181\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1201 - mean_absolute_error: 0.0165 - val_loss: 0.1190 - val_mean_absolute_error: 0.0153\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1178 - mean_absolute_error: 0.0138 - val_loss: 0.1167 - val_mean_absolute_error: 0.0126\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1159 - mean_absolute_error: 0.0115 - val_loss: 0.1152 - val_mean_absolute_error: 0.0106\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1148 - mean_absolute_error: 0.0100 - val_loss: 0.1144 - val_mean_absolute_error: 0.0095\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1141 - mean_absolute_error: 0.0093 - val_loss: 0.1139 - val_mean_absolute_error: 0.0092\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1137 - mean_absolute_error: 0.0090 - val_loss: 0.1135 - val_mean_absolute_error: 0.0084\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1133 - mean_absolute_error: 0.0084 - val_loss: 0.1132 - val_mean_absolute_error: 0.0079\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.1130 - mean_absolute_error: 0.0079 - val_loss: 0.1128 - val_mean_absolute_error: 0.0075\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1127 - mean_absolute_error: 0.0074 - val_loss: 0.1126 - val_mean_absolute_error: 0.0070\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1125 - mean_absolute_error: 0.0070 - val_loss: 0.1125 - val_mean_absolute_error: 0.0068\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.1124 - mean_absolute_error: 0.0068 - val_loss: 0.1124 - val_mean_absolute_error: 0.0066\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 0.1123 - mean_absolute_error: 0.0067 - val_loss: 0.1123 - val_mean_absolute_error: 0.0066\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1123 - mean_absolute_error: 0.0065 - val_loss: 0.1122 - val_mean_absolute_error: 0.0063\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1122 - mean_absolute_error: 0.0064 - val_loss: 0.1122 - val_mean_absolute_error: 0.0063\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1122 - mean_absolute_error: 0.0063 - val_loss: 0.1122 - val_mean_absolute_error: 0.0063\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1122 - mean_absolute_error: 0.0063 - val_loss: 0.1121 - val_mean_absolute_error: 0.0063\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1121 - mean_absolute_error: 0.0062 - val_loss: 0.1121 - val_mean_absolute_error: 0.0062\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 157us/step - loss: 0.1121 - mean_absolute_error: 0.0062 - val_loss: 0.1121 - val_mean_absolute_error: 0.0063\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_167 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 287us/step - loss: 0.3244 - mean_absolute_error: 0.1221 - val_loss: 0.2479 - val_mean_absolute_error: 0.0436\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2386 - mean_absolute_error: 0.0302 - val_loss: 0.2333 - val_mean_absolute_error: 0.0224\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.2314 - mean_absolute_error: 0.0200 - val_loss: 0.2299 - val_mean_absolute_error: 0.0179\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2287 - mean_absolute_error: 0.0164 - val_loss: 0.2278 - val_mean_absolute_error: 0.0152\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2272 - mean_absolute_error: 0.0145 - val_loss: 0.2267 - val_mean_absolute_error: 0.0139\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2265 - mean_absolute_error: 0.0136 - val_loss: 0.2263 - val_mean_absolute_error: 0.0142\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2261 - mean_absolute_error: 0.0132 - val_loss: 0.2260 - val_mean_absolute_error: 0.0132\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2260 - mean_absolute_error: 0.0131 - val_loss: 0.2259 - val_mean_absolute_error: 0.0131\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2258 - mean_absolute_error: 0.0131 - val_loss: 0.2258 - val_mean_absolute_error: 0.0130\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2257 - mean_absolute_error: 0.0130 - val_loss: 0.2257 - val_mean_absolute_error: 0.0129\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2256 - mean_absolute_error: 0.0129 - val_loss: 0.2256 - val_mean_absolute_error: 0.0130\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2256 - mean_absolute_error: 0.0129 - val_loss: 0.2255 - val_mean_absolute_error: 0.0128\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2255 - mean_absolute_error: 0.0129 - val_loss: 0.2254 - val_mean_absolute_error: 0.0128\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2254 - mean_absolute_error: 0.0129 - val_loss: 0.2255 - val_mean_absolute_error: 0.0127\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2253 - mean_absolute_error: 0.0126 - val_loss: 0.2253 - val_mean_absolute_error: 0.0123\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2252 - mean_absolute_error: 0.0123 - val_loss: 0.2252 - val_mean_absolute_error: 0.0122\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2252 - mean_absolute_error: 0.0122 - val_loss: 0.2252 - val_mean_absolute_error: 0.0121\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2251 - mean_absolute_error: 0.0121 - val_loss: 0.2251 - val_mean_absolute_error: 0.0120\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2251 - mean_absolute_error: 0.0121 - val_loss: 0.2251 - val_mean_absolute_error: 0.0121\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2251 - mean_absolute_error: 0.0120 - val_loss: 0.2251 - val_mean_absolute_error: 0.0120\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_168 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000/30000 [==============================] - 9s 294us/step - loss: 0.1170 - mean_absolute_error: 0.0694 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 158us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0199\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_169 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 10s 275us/step - loss: 0.2938 - mean_absolute_error: 0.1268 - val_loss: 0.2313 - val_mean_absolute_error: 0.0716\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 171us/step - loss: 0.2147 - mean_absolute_error: 0.0501 - val_loss: 0.2046 - val_mean_absolute_error: 0.0368\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.1995 - mean_absolute_error: 0.0309 - val_loss: 0.1955 - val_mean_absolute_error: 0.0265\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1928 - mean_absolute_error: 0.0232 - val_loss: 0.1905 - val_mean_absolute_error: 0.0205\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.1890 - mean_absolute_error: 0.0185 - val_loss: 0.1876 - val_mean_absolute_error: 0.0167\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 180us/step - loss: 0.1867 - mean_absolute_error: 0.0154 - val_loss: 0.1858 - val_mean_absolute_error: 0.0142\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.1853 - mean_absolute_error: 0.0132 - val_loss: 0.1848 - val_mean_absolute_error: 0.0126\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.1845 - mean_absolute_error: 0.0119 - val_loss: 0.1842 - val_mean_absolute_error: 0.0115\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.1840 - mean_absolute_error: 0.0111 - val_loss: 0.1838 - val_mean_absolute_error: 0.0108\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 168us/step - loss: 0.1837 - mean_absolute_error: 0.0107 - val_loss: 0.1836 - val_mean_absolute_error: 0.0106\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1835 - mean_absolute_error: 0.0104 - val_loss: 0.1834 - val_mean_absolute_error: 0.0103\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1834 - mean_absolute_error: 0.0102 - val_loss: 0.1834 - val_mean_absolute_error: 0.0102\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1834 - mean_absolute_error: 0.0101 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1833 - mean_absolute_error: 0.0101 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 172us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0102\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0102\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 7s 201us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1832 - val_mean_absolute_error: 0.0100\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_170 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 10s 342us/step - loss: 0.2952 - mean_absolute_error: 0.1107 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0783\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0783\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0784\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 159us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0782\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0789\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0791\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2596 - val_mean_absolute_error: 0.0784\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0780\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0793\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_171 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 290us/step - loss: 0.3749 - mean_absolute_error: 0.1441 - val_loss: 0.3314 - val_mean_absolute_error: 0.1078\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.3186 - mean_absolute_error: 0.0958 - val_loss: 0.3086 - val_mean_absolute_error: 0.0860\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.3028 - mean_absolute_error: 0.0804 - val_loss: 0.2982 - val_mean_absolute_error: 0.0764\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2948 - mean_absolute_error: 0.0743 - val_loss: 0.2914 - val_mean_absolute_error: 0.0714\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2876 - mean_absolute_error: 0.0681 - val_loss: 0.2844 - val_mean_absolute_error: 0.0649\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2818 - mean_absolute_error: 0.0617 - val_loss: 0.2796 - val_mean_absolute_error: 0.0590\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 160us/step - loss: 0.2779 - mean_absolute_error: 0.0572 - val_loss: 0.2767 - val_mean_absolute_error: 0.0559\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.2753 - mean_absolute_error: 0.0547 - val_loss: 0.2745 - val_mean_absolute_error: 0.0535\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2736 - mean_absolute_error: 0.0529 - val_loss: 0.2729 - val_mean_absolute_error: 0.0522\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.2725 - mean_absolute_error: 0.0517 - val_loss: 0.2722 - val_mean_absolute_error: 0.0512\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2717 - mean_absolute_error: 0.0508 - val_loss: 0.2712 - val_mean_absolute_error: 0.0503\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.2710 - mean_absolute_error: 0.0502 - val_loss: 0.2709 - val_mean_absolute_error: 0.0501\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.2705 - mean_absolute_error: 0.0497 - val_loss: 0.2700 - val_mean_absolute_error: 0.0493\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 176us/step - loss: 0.2700 - mean_absolute_error: 0.0493 - val_loss: 0.2696 - val_mean_absolute_error: 0.0490\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2697 - mean_absolute_error: 0.0490 - val_loss: 0.2694 - val_mean_absolute_error: 0.0488\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.2694 - mean_absolute_error: 0.0487 - val_loss: 0.2690 - val_mean_absolute_error: 0.0483\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.2692 - mean_absolute_error: 0.0485 - val_loss: 0.2688 - val_mean_absolute_error: 0.0484\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.2690 - mean_absolute_error: 0.0483 - val_loss: 0.2686 - val_mean_absolute_error: 0.0481\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2688 - mean_absolute_error: 0.0482 - val_loss: 0.2684 - val_mean_absolute_error: 0.0479\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2687 - mean_absolute_error: 0.0481 - val_loss: 0.2683 - val_mean_absolute_error: 0.0480\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_163 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_326 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.110198\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_1', 9, 23, 23, 23, 0.28125, 1.0, 0.5, 0.75]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_164 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_328 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.040706\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_2', 8, 46, 1, 46, 0.8888888888888888, 1.0, 0.9787234042553191, 0.9893617021276595]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_165 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_330 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.041949\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_3', 6, 43, 6, 43, 0.5, 1.0, 0.8775510204081632, 0.9387755102040816]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_166 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_332 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.018092\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_4', 6, 49, 0, 49, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_167 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_334 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.026858\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_168 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_336 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023113\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_169 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028739\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_170 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_339 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100697\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_171 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_341 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.071950\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[18, 'fam_9', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "[18, 0.6630842151675485, 1.0000000000000002, 0.8817175664592078, 0.9408587832296038]\n",
      "../dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "../dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Training for family fam_1\n",
      "train: (54000, 2004)\n",
      "test(13500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_172 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 54000 samples, validate on 13500 samples\n",
      "Epoch 1/20\n",
      "54000/54000 [==============================] - 14s 252us/step - loss: 0.4060 - mean_absolute_error: 0.1440 - val_loss: 0.3750 - val_mean_absolute_error: 0.1190\n",
      "Epoch 2/20\n",
      "54000/54000 [==============================] - 12s 215us/step - loss: 0.3517 - mean_absolute_error: 0.1018 - val_loss: 0.3308 - val_mean_absolute_error: 0.0842\n",
      "Epoch 3/20\n",
      "54000/54000 [==============================] - 10s 184us/step - loss: 0.3204 - mean_absolute_error: 0.0737 - val_loss: 0.3128 - val_mean_absolute_error: 0.0659\n",
      "Epoch 4/20\n",
      "54000/54000 [==============================] - 9s 168us/step - loss: 0.3090 - mean_absolute_error: 0.0619 - val_loss: 0.3058 - val_mean_absolute_error: 0.0588\n",
      "Epoch 5/20\n",
      "54000/54000 [==============================] - 9s 174us/step - loss: 0.3039 - mean_absolute_error: 0.0565 - val_loss: 0.3021 - val_mean_absolute_error: 0.0542\n",
      "Epoch 6/20\n",
      "54000/54000 [==============================] - 10s 193us/step - loss: 0.3006 - mean_absolute_error: 0.0528 - val_loss: 0.2991 - val_mean_absolute_error: 0.0510\n",
      "Epoch 7/20\n",
      "54000/54000 [==============================] - 12s 227us/step - loss: 0.2981 - mean_absolute_error: 0.0499 - val_loss: 0.2968 - val_mean_absolute_error: 0.0484\n",
      "Epoch 8/20\n",
      "54000/54000 [==============================] - 12s 229us/step - loss: 0.2961 - mean_absolute_error: 0.0473 - val_loss: 0.2953 - val_mean_absolute_error: 0.0462\n",
      "Epoch 9/20\n",
      "54000/54000 [==============================] - 9s 169us/step - loss: 0.2946 - mean_absolute_error: 0.0452 - val_loss: 0.2940 - val_mean_absolute_error: 0.0443\n",
      "Epoch 10/20\n",
      "54000/54000 [==============================] - 9s 168us/step - loss: 0.2935 - mean_absolute_error: 0.0436 - val_loss: 0.2929 - val_mean_absolute_error: 0.0426\n",
      "Epoch 11/20\n",
      "54000/54000 [==============================] - 9s 166us/step - loss: 0.2928 - mean_absolute_error: 0.0424 - val_loss: 0.2924 - val_mean_absolute_error: 0.0419\n",
      "Epoch 12/20\n",
      "54000/54000 [==============================] - 9s 162us/step - loss: 0.2923 - mean_absolute_error: 0.0416 - val_loss: 0.2940 - val_mean_absolute_error: 0.0427\n",
      "Epoch 13/20\n",
      "54000/54000 [==============================] - 9s 163us/step - loss: 0.2918 - mean_absolute_error: 0.0409 - val_loss: 0.2911 - val_mean_absolute_error: 0.0403\n",
      "Epoch 14/20\n",
      "54000/54000 [==============================] - 9s 165us/step - loss: 0.2914 - mean_absolute_error: 0.0404 - val_loss: 0.2911 - val_mean_absolute_error: 0.0404\n",
      "Epoch 15/20\n",
      "54000/54000 [==============================] - 9s 164us/step - loss: 0.2911 - mean_absolute_error: 0.0399 - val_loss: 0.2916 - val_mean_absolute_error: 0.0408\n",
      "Epoch 16/20\n",
      "54000/54000 [==============================] - 9s 163us/step - loss: 0.2908 - mean_absolute_error: 0.0395 - val_loss: 0.2904 - val_mean_absolute_error: 0.0390\n",
      "Epoch 17/20\n",
      "54000/54000 [==============================] - 9s 168us/step - loss: 0.2905 - mean_absolute_error: 0.0391 - val_loss: 0.2907 - val_mean_absolute_error: 0.0390\n",
      "Epoch 18/20\n",
      "54000/54000 [==============================] - 9s 166us/step - loss: 0.2903 - mean_absolute_error: 0.0387 - val_loss: 0.2906 - val_mean_absolute_error: 0.0388\n",
      "Epoch 19/20\n",
      "54000/54000 [==============================] - 9s 170us/step - loss: 0.2901 - mean_absolute_error: 0.0383 - val_loss: 0.2906 - val_mean_absolute_error: 0.0393\n",
      "Epoch 20/20\n",
      "54000/54000 [==============================] - 9s 174us/step - loss: 0.2899 - mean_absolute_error: 0.0381 - val_loss: 0.2894 - val_mean_absolute_error: 0.0372\n",
      "Training for family fam_2\n",
      "train: (48000, 2004)\n",
      "test(12000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_173 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 12s 249us/step - loss: 0.2187 - mean_absolute_error: 0.0752 - val_loss: 0.1931 - val_mean_absolute_error: 0.0506\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0510\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 8s 171us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0529\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 9s 181us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0526\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0522\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 8s 169us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0524\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0528\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 8s 167us/step - loss: 0.1930 - mean_absolute_error: 0.0517 - val_loss: 0.1930 - val_mean_absolute_error: 0.0512\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1932 - val_mean_absolute_error: 0.0497\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 9s 182us/step - loss: 0.1930 - mean_absolute_error: 0.0516 - val_loss: 0.1932 - val_mean_absolute_error: 0.0537\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 8s 172us/step - loss: 0.1930 - mean_absolute_error: 0.0518 - val_loss: 0.1930 - val_mean_absolute_error: 0.0523\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 8s 165us/step - loss: 0.1926 - mean_absolute_error: 0.0516 - val_loss: 0.1895 - val_mean_absolute_error: 0.0516\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 0.1839 - mean_absolute_error: 0.0486 - val_loss: 0.1785 - val_mean_absolute_error: 0.0458\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 0.1738 - mean_absolute_error: 0.0441 - val_loss: 0.1694 - val_mean_absolute_error: 0.0412\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 0.1656 - mean_absolute_error: 0.0391 - val_loss: 0.1622 - val_mean_absolute_error: 0.0365\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.1594 - mean_absolute_error: 0.0341 - val_loss: 0.1569 - val_mean_absolute_error: 0.0316\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 9s 181us/step - loss: 0.1550 - mean_absolute_error: 0.0298 - val_loss: 0.1533 - val_mean_absolute_error: 0.0275\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.1520 - mean_absolute_error: 0.0263 - val_loss: 0.1510 - val_mean_absolute_error: 0.0257\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 0.1501 - mean_absolute_error: 0.0238 - val_loss: 0.1495 - val_mean_absolute_error: 0.0230\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 0.1490 - mean_absolute_error: 0.0221 - val_loss: 0.1486 - val_mean_absolute_error: 0.0215\n",
      "Training for family fam_3\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_174 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_348 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 10s 285us/step - loss: 0.2182 - mean_absolute_error: 0.0953 - val_loss: 0.1806 - val_mean_absolute_error: 0.0616\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1805 - mean_absolute_error: 0.0623 - val_loss: 0.1805 - val_mean_absolute_error: 0.0623\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1784 - mean_absolute_error: 0.0608 - val_loss: 0.1740 - val_mean_absolute_error: 0.0582\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1694 - mean_absolute_error: 0.0544 - val_loss: 0.1652 - val_mean_absolute_error: 0.0516\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1619 - mean_absolute_error: 0.0484 - val_loss: 0.1589 - val_mean_absolute_error: 0.0459\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1564 - mean_absolute_error: 0.0437 - val_loss: 0.1543 - val_mean_absolute_error: 0.0418\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1526 - mean_absolute_error: 0.0398 - val_loss: 0.1510 - val_mean_absolute_error: 0.0382\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 0.1498 - mean_absolute_error: 0.0369 - val_loss: 0.1487 - val_mean_absolute_error: 0.0359\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1479 - mean_absolute_error: 0.0352 - val_loss: 0.1472 - val_mean_absolute_error: 0.0343\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1467 - mean_absolute_error: 0.0341 - val_loss: 0.1464 - val_mean_absolute_error: 0.0333\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.1458 - mean_absolute_error: 0.0333 - val_loss: 0.1454 - val_mean_absolute_error: 0.0330\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.1452 - mean_absolute_error: 0.0327 - val_loss: 0.1450 - val_mean_absolute_error: 0.0327\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.1447 - mean_absolute_error: 0.0322 - val_loss: 0.1445 - val_mean_absolute_error: 0.0321\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.1443 - mean_absolute_error: 0.0318 - val_loss: 0.1441 - val_mean_absolute_error: 0.0314\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.1440 - mean_absolute_error: 0.0314 - val_loss: 0.1439 - val_mean_absolute_error: 0.0311\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1437 - mean_absolute_error: 0.0311 - val_loss: 0.1436 - val_mean_absolute_error: 0.0309\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1435 - mean_absolute_error: 0.0309 - val_loss: 0.1434 - val_mean_absolute_error: 0.0308\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1433 - mean_absolute_error: 0.0306 - val_loss: 0.1431 - val_mean_absolute_error: 0.0306\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1431 - mean_absolute_error: 0.0304 - val_loss: 0.1433 - val_mean_absolute_error: 0.0305\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.1429 - mean_absolute_error: 0.0302 - val_loss: 0.1428 - val_mean_absolute_error: 0.0300\n",
      "Training for family fam_4\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_175 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 10s 278us/step - loss: 0.1943 - mean_absolute_error: 0.0879 - val_loss: 0.1277 - val_mean_absolute_error: 0.0248\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.1239 - mean_absolute_error: 0.0206 - val_loss: 0.1216 - val_mean_absolute_error: 0.0179\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1202 - mean_absolute_error: 0.0164 - val_loss: 0.1191 - val_mean_absolute_error: 0.0152\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1181 - mean_absolute_error: 0.0140 - val_loss: 0.1173 - val_mean_absolute_error: 0.0130\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1168 - mean_absolute_error: 0.0123 - val_loss: 0.1163 - val_mean_absolute_error: 0.0116\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1159 - mean_absolute_error: 0.0111 - val_loss: 0.1156 - val_mean_absolute_error: 0.0107\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.1154 - mean_absolute_error: 0.0104 - val_loss: 0.1152 - val_mean_absolute_error: 0.0101\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1150 - mean_absolute_error: 0.0099 - val_loss: 0.1149 - val_mean_absolute_error: 0.0097\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.1148 - mean_absolute_error: 0.0096 - val_loss: 0.1147 - val_mean_absolute_error: 0.0095\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1146 - mean_absolute_error: 0.0094 - val_loss: 0.1145 - val_mean_absolute_error: 0.0095\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1145 - mean_absolute_error: 0.0093 - val_loss: 0.1144 - val_mean_absolute_error: 0.0095\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.1143 - mean_absolute_error: 0.0093 - val_loss: 0.1143 - val_mean_absolute_error: 0.0092\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.1142 - mean_absolute_error: 0.0093 - val_loss: 0.1141 - val_mean_absolute_error: 0.0094\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1140 - mean_absolute_error: 0.0091 - val_loss: 0.1139 - val_mean_absolute_error: 0.0088\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1138 - mean_absolute_error: 0.0086 - val_loss: 0.1137 - val_mean_absolute_error: 0.0083\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1135 - mean_absolute_error: 0.0082 - val_loss: 0.1134 - val_mean_absolute_error: 0.0082\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.1133 - mean_absolute_error: 0.0079 - val_loss: 0.1132 - val_mean_absolute_error: 0.0078\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.1130 - mean_absolute_error: 0.0076 - val_loss: 0.1129 - val_mean_absolute_error: 0.0074\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.1128 - mean_absolute_error: 0.0074 - val_loss: 0.1128 - val_mean_absolute_error: 0.0072\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.1127 - mean_absolute_error: 0.0072 - val_loss: 0.1127 - val_mean_absolute_error: 0.0072\n",
      "Training for family fam_5\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_176 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 300us/step - loss: 0.3257 - mean_absolute_error: 0.1248 - val_loss: 0.2497 - val_mean_absolute_error: 0.0444\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2405 - mean_absolute_error: 0.0317 - val_loss: 0.2360 - val_mean_absolute_error: 0.0248\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2348 - mean_absolute_error: 0.0233 - val_loss: 0.2339 - val_mean_absolute_error: 0.0223\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2332 - mean_absolute_error: 0.0217 - val_loss: 0.2321 - val_mean_absolute_error: 0.0212\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2315 - mean_absolute_error: 0.0201 - val_loss: 0.2311 - val_mean_absolute_error: 0.0194\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2307 - mean_absolute_error: 0.0192 - val_loss: 0.2304 - val_mean_absolute_error: 0.0189\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2299 - mean_absolute_error: 0.0184 - val_loss: 0.2293 - val_mean_absolute_error: 0.0177\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 6s 185us/step - loss: 0.2288 - mean_absolute_error: 0.0172 - val_loss: 0.2284 - val_mean_absolute_error: 0.0166\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 6s 186us/step - loss: 0.2280 - mean_absolute_error: 0.0163 - val_loss: 0.2278 - val_mean_absolute_error: 0.0165\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 6s 197us/step - loss: 0.2275 - mean_absolute_error: 0.0157 - val_loss: 0.2273 - val_mean_absolute_error: 0.0160\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 6s 188us/step - loss: 0.2270 - mean_absolute_error: 0.0153 - val_loss: 0.2267 - val_mean_absolute_error: 0.0147\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 183us/step - loss: 0.2264 - mean_absolute_error: 0.0143 - val_loss: 0.2261 - val_mean_absolute_error: 0.0137\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2260 - mean_absolute_error: 0.0137 - val_loss: 0.2259 - val_mean_absolute_error: 0.0134\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2258 - mean_absolute_error: 0.0132 - val_loss: 0.2258 - val_mean_absolute_error: 0.0133\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2256 - mean_absolute_error: 0.0129 - val_loss: 0.2257 - val_mean_absolute_error: 0.0130\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2256 - mean_absolute_error: 0.0128 - val_loss: 0.2255 - val_mean_absolute_error: 0.0129\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2255 - mean_absolute_error: 0.0128 - val_loss: 0.2256 - val_mean_absolute_error: 0.0132\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2254 - mean_absolute_error: 0.0127 - val_loss: 0.2254 - val_mean_absolute_error: 0.0125\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.2253 - mean_absolute_error: 0.0126 - val_loss: 0.2255 - val_mean_absolute_error: 0.0131\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2252 - mean_absolute_error: 0.0125 - val_loss: 0.2252 - val_mean_absolute_error: 0.0124\n",
      "Training for family fam_6\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_177 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 298us/step - loss: 0.1172 - mean_absolute_error: 0.0696 - val_loss: 0.0598 - val_mean_absolute_error: 0.0199\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0197\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 174us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 173us/step - loss: 0.0597 - mean_absolute_error: 0.0198 - val_loss: 0.0597 - val_mean_absolute_error: 0.0198\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0197\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0199\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 164us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.0596 - mean_absolute_error: 0.0198 - val_loss: 0.0596 - val_mean_absolute_error: 0.0198\n",
      "Training for family fam_7\n",
      "train: (36000, 2004)\n",
      "test(9000, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_178 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 36000 samples, validate on 9000 samples\n",
      "Epoch 1/20\n",
      "36000/36000 [==============================] - 11s 301us/step - loss: 0.2967 - mean_absolute_error: 0.1306 - val_loss: 0.2332 - val_mean_absolute_error: 0.0769\n",
      "Epoch 2/20\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.2130 - mean_absolute_error: 0.0549 - val_loss: 0.2012 - val_mean_absolute_error: 0.0395\n",
      "Epoch 3/20\n",
      "36000/36000 [==============================] - 6s 180us/step - loss: 0.1952 - mean_absolute_error: 0.0298 - val_loss: 0.1908 - val_mean_absolute_error: 0.0220\n",
      "Epoch 4/20\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.1886 - mean_absolute_error: 0.0180 - val_loss: 0.1869 - val_mean_absolute_error: 0.0152\n",
      "Epoch 5/20\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.1858 - mean_absolute_error: 0.0138 - val_loss: 0.1850 - val_mean_absolute_error: 0.0126\n",
      "Epoch 6/20\n",
      "36000/36000 [==============================] - 6s 172us/step - loss: 0.1844 - mean_absolute_error: 0.0117 - val_loss: 0.1840 - val_mean_absolute_error: 0.0111\n",
      "Epoch 7/20\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.1838 - mean_absolute_error: 0.0107 - val_loss: 0.1836 - val_mean_absolute_error: 0.0104\n",
      "Epoch 8/20\n",
      "36000/36000 [==============================] - 7s 187us/step - loss: 0.1835 - mean_absolute_error: 0.0102 - val_loss: 0.1834 - val_mean_absolute_error: 0.0101\n",
      "Epoch 9/20\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.1834 - mean_absolute_error: 0.0100 - val_loss: 0.1834 - val_mean_absolute_error: 0.0100\n",
      "Epoch 10/20\n",
      "36000/36000 [==============================] - 7s 197us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 11/20\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.1833 - mean_absolute_error: 0.0100 - val_loss: 0.1833 - val_mean_absolute_error: 0.0100\n",
      "Epoch 12/20\n",
      "36000/36000 [==============================] - 6s 179us/step - loss: 0.1832 - mean_absolute_error: 0.0099 - val_loss: 0.1832 - val_mean_absolute_error: 0.0099\n",
      "Epoch 13/20\n",
      "36000/36000 [==============================] - 6s 174us/step - loss: 0.1831 - mean_absolute_error: 0.0099 - val_loss: 0.1831 - val_mean_absolute_error: 0.0099\n",
      "Epoch 14/20\n",
      "36000/36000 [==============================] - 7s 181us/step - loss: 0.1831 - mean_absolute_error: 0.0099 - val_loss: 0.1831 - val_mean_absolute_error: 0.0099\n",
      "Epoch 15/20\n",
      "36000/36000 [==============================] - 7s 182us/step - loss: 0.1830 - mean_absolute_error: 0.0099 - val_loss: 0.1830 - val_mean_absolute_error: 0.0099\n",
      "Epoch 16/20\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.1830 - mean_absolute_error: 0.0099 - val_loss: 0.1830 - val_mean_absolute_error: 0.0099\n",
      "Epoch 17/20\n",
      "36000/36000 [==============================] - 7s 193us/step - loss: 0.1829 - mean_absolute_error: 0.0098 - val_loss: 0.1829 - val_mean_absolute_error: 0.0099\n",
      "Epoch 18/20\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 0.1829 - mean_absolute_error: 0.0098 - val_loss: 0.1829 - val_mean_absolute_error: 0.0098\n",
      "Epoch 19/20\n",
      "36000/36000 [==============================] - 6s 174us/step - loss: 0.1828 - mean_absolute_error: 0.0097 - val_loss: 0.1828 - val_mean_absolute_error: 0.0097\n",
      "Epoch 20/20\n",
      "36000/36000 [==============================] - 6s 177us/step - loss: 0.1828 - mean_absolute_error: 0.0097 - val_loss: 0.1828 - val_mean_absolute_error: 0.0097\n",
      "Training for family fam_8\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_179 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 312us/step - loss: 0.2954 - mean_absolute_error: 0.1109 - val_loss: 0.2596 - val_mean_absolute_error: 0.0784\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 181us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0784\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 177us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 171us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2596 - val_mean_absolute_error: 0.0793\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 179us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0789\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0781\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2597 - val_mean_absolute_error: 0.0770\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0783\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 175us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0787\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0786\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2595 - mean_absolute_error: 0.0786 - val_loss: 0.2595 - val_mean_absolute_error: 0.0785\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 161us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2595 - val_mean_absolute_error: 0.0788\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0787\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.2595 - mean_absolute_error: 0.0785 - val_loss: 0.2594 - val_mean_absolute_error: 0.0788\n",
      "Training for family fam_9\n",
      "train: (30000, 2004)\n",
      "test(7500, 2004)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_180 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_360 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 30000 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "30000/30000 [==============================] - 9s 306us/step - loss: 0.3732 - mean_absolute_error: 0.1428 - val_loss: 0.3256 - val_mean_absolute_error: 0.1019\n",
      "Epoch 2/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.3121 - mean_absolute_error: 0.0894 - val_loss: 0.3025 - val_mean_absolute_error: 0.0794\n",
      "Epoch 3/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2965 - mean_absolute_error: 0.0753 - val_loss: 0.2913 - val_mean_absolute_error: 0.0710\n",
      "Epoch 4/20\n",
      "30000/30000 [==============================] - 5s 162us/step - loss: 0.2872 - mean_absolute_error: 0.0665 - val_loss: 0.2839 - val_mean_absolute_error: 0.0630\n",
      "Epoch 5/20\n",
      "30000/30000 [==============================] - 5s 165us/step - loss: 0.2812 - mean_absolute_error: 0.0602 - val_loss: 0.2790 - val_mean_absolute_error: 0.0580\n",
      "Epoch 6/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2774 - mean_absolute_error: 0.0564 - val_loss: 0.2760 - val_mean_absolute_error: 0.0551\n",
      "Epoch 7/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2749 - mean_absolute_error: 0.0542 - val_loss: 0.2739 - val_mean_absolute_error: 0.0533\n",
      "Epoch 8/20\n",
      "30000/30000 [==============================] - 5s 170us/step - loss: 0.2732 - mean_absolute_error: 0.0526 - val_loss: 0.2724 - val_mean_absolute_error: 0.0519\n",
      "Epoch 9/20\n",
      "30000/30000 [==============================] - 5s 172us/step - loss: 0.2719 - mean_absolute_error: 0.0516 - val_loss: 0.2712 - val_mean_absolute_error: 0.0512\n",
      "Epoch 10/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2707 - mean_absolute_error: 0.0509 - val_loss: 0.2699 - val_mean_absolute_error: 0.0502\n",
      "Epoch 11/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.2693 - mean_absolute_error: 0.0504 - val_loss: 0.2680 - val_mean_absolute_error: 0.0503\n",
      "Epoch 12/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2669 - mean_absolute_error: 0.0492 - val_loss: 0.2651 - val_mean_absolute_error: 0.0481\n",
      "Epoch 13/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2634 - mean_absolute_error: 0.0460 - val_loss: 0.2619 - val_mean_absolute_error: 0.0447\n",
      "Epoch 14/20\n",
      "30000/30000 [==============================] - 5s 169us/step - loss: 0.2598 - mean_absolute_error: 0.0408 - val_loss: 0.2584 - val_mean_absolute_error: 0.0381\n",
      "Epoch 15/20\n",
      "30000/30000 [==============================] - 5s 167us/step - loss: 0.2572 - mean_absolute_error: 0.0361 - val_loss: 0.2564 - val_mean_absolute_error: 0.0346\n",
      "Epoch 16/20\n",
      "30000/30000 [==============================] - 5s 166us/step - loss: 0.2558 - mean_absolute_error: 0.0338 - val_loss: 0.2554 - val_mean_absolute_error: 0.0332\n",
      "Epoch 17/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2550 - mean_absolute_error: 0.0328 - val_loss: 0.2548 - val_mean_absolute_error: 0.0324\n",
      "Epoch 18/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2545 - mean_absolute_error: 0.0321 - val_loss: 0.2544 - val_mean_absolute_error: 0.0320\n",
      "Epoch 19/20\n",
      "30000/30000 [==============================] - 5s 168us/step - loss: 0.2542 - mean_absolute_error: 0.0317 - val_loss: 0.2541 - val_mean_absolute_error: 0.0314\n",
      "Epoch 20/20\n",
      "30000/30000 [==============================] - 5s 163us/step - loss: 0.2540 - mean_absolute_error: 0.0313 - val_loss: 0.2540 - val_mean_absolute_error: 0.0313\n",
      "Evaluating family fam_1\n",
      "Test for autoencoder on fam fam_1\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_172 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_343 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.064131\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_1', 9, 43, 3, 43, 0.75, 1.0, 0.9347826086956522, 0.9673913043478262]\n",
      "Evaluating family fam_2\n",
      "Test for autoencoder on fam fam_2\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_173 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_345 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.039531\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_2', 8, 46, 1, 46, 0.8888888888888888, 1.0, 0.9787234042553191, 0.9893617021276595]\n",
      "Evaluating family fam_3\n",
      "Test for autoencoder on fam fam_3\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_174 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_347 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_348 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.040269\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_3', 6, 43, 6, 43, 0.5, 1.0, 0.8775510204081632, 0.9387755102040816]\n",
      "Evaluating family fam_4\n",
      "Test for autoencoder on fam fam_4\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_175 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_349 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.022794\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_4', 6, 44, 5, 44, 0.5454545454545454, 1.0, 0.8979591836734694, 0.9489795918367347]\n",
      "Evaluating family fam_5\n",
      "Test for autoencoder on fam fam_5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_176 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_351 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.031396\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_5', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "Evaluating family fam_6\n",
      "Test for autoencoder on fam fam_6\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_177 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_353 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.023245\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_6', 5, 49, 1, 49, 0.8333333333333334, 1.0, 0.98, 0.99]\n",
      "Evaluating family fam_7\n",
      "Test for autoencoder on fam fam_7\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_178 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_355 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.028358\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_7', 6, 47, 2, 47, 0.75, 1.0, 0.9591836734693877, 0.9795918367346939]\n",
      "Evaluating family fam_8\n",
      "Test for autoencoder on fam fam_8\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_179 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_357 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Max loss is 0.100649\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_8', 5, 41, 9, 41, 0.35714285714285715, 1.0, 0.82, 0.9099999999999999]\n",
      "Evaluating family fam_9\n",
      "Test for autoencoder on fam fam_9\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_180 (InputLayer)       (None, 2004)              0         \n",
      "_________________________________________________________________\n",
      "dense_359 (Dense)            (None, 25)                50125     \n",
      "_________________________________________________________________\n",
      "dense_360 (Dense)            (None, 2004)              52104     \n",
      "=================================================================\n",
      "Total params: 102,229\n",
      "Trainable params: 102,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max loss is 0.042697\n",
      "Test for fam fam_1\n",
      "Test for fam fam_2\n",
      "Test for fam fam_3\n",
      "Test for fam fam_4\n",
      "Test for fam fam_5\n",
      "Test for fam fam_6\n",
      "Test for fam fam_7\n",
      "Test for fam fam_8\n",
      "Test for fam fam_9\n",
      "[19, 'fam_9', 5, 50, 0, 50, 1.0, 1.0, 1.0, 1.0]\n",
      "[19, 0.7360910694244027, 1.0000000000000002, 0.9386888767224435, 0.9693444383612217]\n"
     ]
    }
   ],
   "source": [
    "res_fam = open('res_fam_conf_prot.csv', mode='w')\n",
    "res_avg = open('res_avg_conf_prot.csv', mode='w')\n",
    "writer_fam = csv.writer(res_fam, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "writer_fam.writerow(['Iteration', 'Superfamily', 'TP', 'TN', 'FP', 'FN', 'Prec', 'Recall', 'Spec', 'AUC'])\n",
    "writer_avg = csv.writer(res_avg, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "writer_avg.writerow(['Iteration', 'Prec', 'Recall', 'Spec', 'AUC'])\n",
    "for i in range(0,20):\n",
    "    \n",
    "    # serialize data\n",
    "    for f in pre.families:\n",
    "        proteins = glob.glob(os.path.join(pre.family_paths[f], \"*.out\"))\n",
    "        for p in proteins:\n",
    "            print(p)\n",
    "            proteins_conf = []\n",
    "            with open(p) as in_file:\n",
    "                for line in in_file:\n",
    "                    proteins_conf.append(line.strip())\n",
    "            print(len(proteins_conf))\n",
    "            test_size = int(0.25 * len(proteins_conf))\n",
    "            val_size = int(0.15 * len(proteins_conf))\n",
    "            train_all_p, test_p = train_test_split(proteins_conf, test_size=test_size, random_state=i)\n",
    "            train_p, val_p = train_test_split(train_all_p, test_size = val_size, random_state=i)\n",
    "\n",
    "            #preprocess\n",
    "            train_p = pre.process_conf(train_p, categorical=categorical, use_angles=use_angles, padding=padding, max_length=max_length, flatten=flatten)\n",
    "            val_p = pre.process_conf(val_p, categorical=categorical, use_angles=use_angles, padding=padding, max_length=max_length, flatten=flatten)\n",
    "            test_p = pre.process_conf(test_p, categorical=categorical, use_angles=use_angles, padding=padding, max_length=max_length, flatten=flatten)\n",
    "            print(\"train: \" + repr(train_p.shape))\n",
    "            print(\"val: \" + repr(val_p.shape))\n",
    "            print(\"test: \" + repr(test_p.shape))\n",
    "            del train_all_p\n",
    "            del proteins_conf\n",
    "\n",
    "            p_name = os.path.basename(p).split('.')[0]\n",
    "            train_filename = os.path.join(path, f, \"train\", \"train_\"+ p_name +\".npy\")\n",
    "            val_filename = os.path.join(path, f, \"val\", \"val_\"+ p_name +\".npy\")\n",
    "            test_filename = os.path.join(path, f, \"test\", \"test_\"+ p_name +\".npy\")\n",
    "            np.save(train_filename, train_p)\n",
    "            np.save(val_filename, val_p)\n",
    "            np.save(test_filename, test_p)\n",
    "\n",
    "            del train_p\n",
    "            del test_p\n",
    "            del val_p\n",
    "            \n",
    "    # train autoencoders\n",
    "    for f in pre.families:\n",
    "        print(\"Training for family %s\" %f)\n",
    "        train = read_set_for_family(f,\"train\")\n",
    "        test = read_set_for_family(f,\"val\")\n",
    "        print(\"train: \" + repr(train.shape))\n",
    "        print(\"test\" + repr(test.shape))\n",
    "        ae = get_ae()\n",
    "        ae.fit(train, train,\n",
    "               shuffle=True,\n",
    "               epochs=epochs,\n",
    "               batch_size=batch_size,\n",
    "               validation_data=(test, test),\n",
    "               callbacks=create_checkpoints(f),\n",
    "               verbose=1)\n",
    "        del train\n",
    "        del test\n",
    "    \n",
    "    # evaluate autoencoders\n",
    "    tp, tn, fp, fn = {}, {}, {}, {}\n",
    "    tp_p, tn_p, fp_p, fn_p = {}, {}, {}, {}\n",
    "    prec, recall, spec, auc = {}, {}, {}, {}\n",
    "    prec_p, recall_p, spec_p, auc_p = {}, {}, {}, {}\n",
    "    for f in pre.families:\n",
    "        print(\"Evaluating family %s\" %f)\n",
    "        [tp[f], tn[f], fp[f], fn[f]], [tp_p[f], tn_p[f], fp_p[f], fn_p[f]] = evaluate_for_fam(f)\n",
    "        prec_p[f] = (1.0* tp_p[f] / (tp_p[f] + fp_p[f]))\n",
    "        recall_p[f] = (1.0* tp_p[f] / (tp_p[f] + fn_p[f]))\n",
    "        spec_p[f] = (1.0* tn_p[f] / (tn_p[f] + fp_p[f]))\n",
    "        auc_p[f] = (recall_p[f] + spec_p[f]) / 2\n",
    "        # write to csv \n",
    "        print([i, f, tp_p[f], tn_p[f], fp_p[f], tn_p[f], prec_p[f], recall_p[f], spec_p[f], auc_p[f]])\n",
    "        writer_fam.writerow([i, f, tp_p[f], tn_p[f], fp_p[f], tn_p[f], prec_p[f], recall_p[f], spec_p[f], auc_p[f]])\n",
    "    prec_wavg_p, recall_wavg_p, spec_wavg_p, auc_wavg_p = 0, 0, 0, 0\n",
    "    for f in pre.families:\n",
    "        prec_wavg_p += lengths[f] * prec_p[f] / total\n",
    "        recall_wavg_p += lengths[f] * recall_p[f] / total\n",
    "        spec_wavg_p += lengths[f] * spec_p[f] / total\n",
    "        auc_wavg_p += lengths[f] * auc_p[f] / total\n",
    "    # write to csv\n",
    "    print([i, prec_wavg_p, recall_wavg_p, spec_wavg_p, auc_wavg_p])\n",
    "    writer_avg.writerow([i, prec_wavg_p, recall_wavg_p, spec_wavg_p, auc_wavg_p])\n",
    "res_fam.close()\n",
    "res_avg.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dizy",
   "language": "python",
   "name": "dizy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
