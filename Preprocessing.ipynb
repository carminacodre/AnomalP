{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import string\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tempfile import TemporaryFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "families = [\"fam_1\", \"fam_2\", \"fam_3\", \"fam_4\", \"fam_5\", \"fam_6\", \"fam_7\", \"fam_8\", \"fam_9\"]\n",
    "ds_path = \"../dataset/families\"\n",
    "\n",
    "family_paths = {}\n",
    "for f in families:\n",
    "    family_paths[f]= os.path.join(ds_path, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_di=dict(zip(string.ascii_letters,[ord(c)%32 -1 for c in string.ascii_letters]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = {'A': [122.4, 119.4,-164.2],\n",
    "          'B': [129.8, 135.6, -176.6],\n",
    "          'C': [117.1, 111.0, -142.2],\n",
    "          'D': [118.4, 126.9, -146.1],\n",
    "          'E': [116.7, 138.6, 168.7],\n",
    "          'F': [115.6, 112.9, -117.9],\n",
    "          'G': [135.3, 118.6, -148.5],\n",
    "          'H': [120.1, 114.3, -90.7],\n",
    "          'I': [133.6, 117.1, -120.8],\n",
    "          'J': [115.9, 91.4, -134.6],\n",
    "          'K': [119.7, 90.4, -105.9],\n",
    "          'L': [110.0, 90.8, -158.8],\n",
    "          'M': [110.0, 100.8, 177.0],\n",
    "          'N': [90.1, 138.2, 19.6],\n",
    "          'O': [92.4, 91.2, -127.4],\n",
    "          'P': [91.8, 96.7, -104.8],\n",
    "          'Q': [95.9, 117.7, 136.0],\n",
    "          'R': [94.5, 112.6, 115.0],\n",
    "          'S': [96.3, 94.7, 112.0],\n",
    "          'T': [93.0, 92.8, 83.1],\n",
    "          'U': [91.4, 90.7, 49.8],\n",
    "          'V': [93.3, 89.1, 68.3],\n",
    "          'W': [93.8, 105.2, 32.3],\n",
    "          'X': [111.4, 94.6, 21.8],\n",
    "          'Y': [89.0, 95.1, -54.4]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in angles:\n",
    "    angles[v] = [(x + 180) / 360 for x in angles[v]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_angles(conf):\n",
    "    return [angles[str(l)] for l in conf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_conf(configurations, use_angles ,categorical, padding, max_length, flatten, num_classes=25):\n",
    "    if categorical:\n",
    "        # tranforms data to one hot encodings\n",
    "        configurations = [[letters_di[l] for l in p] for p in configurations]\n",
    "        configurations = np.array([to_categorical(p, num_classes=num_classes) for p in configurations])\n",
    "    elif use_angles:\n",
    "        # use angles\n",
    "        configurations = np.array([to_angles(p) for p in configurations])\n",
    "    else:\n",
    "        configurations = np.array([[letters_di[l] for l in p] for p in configurations])\n",
    "    if padding:\n",
    "        # pad sequences if less than max length\n",
    "        if categorical:\n",
    "            new_families_conf = np.zeros((configurations.shape[0], max_length, num_classes))\n",
    "            for i,f in enumerate(configurations):\n",
    "                new_families_conf[i,:f.shape[0], :f.shape[1]] += f\n",
    "            configurations = new_families_conf\n",
    "        elif to_angles:\n",
    "            new_families_conf = np.zeros((configurations.shape[0], max_length, 3))\n",
    "            for i,f in enumerate(configurations):\n",
    "                new_f = np.array(f)\n",
    "                new_families_conf[i,:new_f.shape[0], :new_f.shape[1]] += new_f\n",
    "            configurations = new_families_conf\n",
    "        del new_families_conf\n",
    "    print(configurations.shape)\n",
    "    if flatten:\n",
    "        if categorical:\n",
    "            configurations = configurations.reshape(-1, num_classes * max_length)\n",
    "        elif use_angles:\n",
    "            configurations = configurations.reshape(-1, 3 * max_length)\n",
    "    print(configurations.shape)\n",
    "    return configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_family(f):\n",
    "    proteins = glob.glob(os.path.join(family_paths[f], \"*.out\"))\n",
    "    print(\"Proteins for family %s\" %f)\n",
    "    for p in proteins:\n",
    "        print(p)\n",
    "    proteins_conf = []\n",
    "    for p in proteins:\n",
    "        with open(p) as in_file:\n",
    "            for line in in_file:\n",
    "                proteins_conf.append(line.strip())\n",
    "    l = [len(p) for p in proteins_conf]\n",
    "    print(Counter(l))\n",
    "    return proteins_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data and serialize trian/ test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in families:\n",
    "#     families_conf = load_family(f)\n",
    "#     families_conf = process_conf(families_conf, categorical=categorical, angles=angles, padding=padding, max_length=max_length,normalize=normalize, flatten=flatten)  \n",
    "#     test_size = int(0.25 * families_conf.shape[0])\n",
    "#     val_size = int(0.15 * families_conf.shape[0])\n",
    "#     train_all, test = train_test_split(families_conf, test_size=test_size, random_state=42)\n",
    "#     train, val = train_test_split(train_all, test_size = val_size, random_state=42)\n",
    "#     del families_conf\n",
    "#     del train_all\n",
    "#     print(\"train: \" + repr(train.shape))\n",
    "#     print(\"val: \" + repr(val.shape))\n",
    "#     print(\"test: \" + repr(test.shape))\n",
    "#     train_filename = os.path.join(\"data_serialized_angles\", f, \"train.npy\")\n",
    "#     val_filename = os.path.join(\"data_serialized_angles\", f, \"val.npy\")\n",
    "#     test_filename = os.path.join(\"data_serialized_angles\", f, \"test.npy\")\n",
    "#     np.save(train_filename, train)\n",
    "#     np.save(val_filename, val)\n",
    "#     np.save(test_filename, test)\n",
    "#     del train\n",
    "#     del test\n",
    "#     del val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in families:\n",
    "#     proteins = glob.glob(os.path.join(family_paths[f], \"*.out\"))\n",
    "#     print(\"Proteins for family %s\" %f)\n",
    "    \n",
    "#     for p in proteins:\n",
    "#         print(p)\n",
    "#         proteins_conf = []\n",
    "#         with open(p) as in_file:\n",
    "#             for line in in_file:\n",
    "#                 proteins_conf.append(line.strip())\n",
    "#         print(len(proteins_conf))\n",
    "#         test_size = int(0.25 * len(proteins_conf))\n",
    "#         val_size = int(0.15 * len(proteins_conf))\n",
    "#         train_all_p, test_p = train_test_split(proteins_conf, test_size=test_size, random_state=42)\n",
    "#         train_p, val_p = train_test_split(train_all_p, test_size = val_size, random_state=42)\n",
    "        \n",
    "#         #preprocess\n",
    "#         train_p = process_conf(train_p, categorical=categorical, angles=angles, padding=padding, max_length=max_length,normalize=normalize, flatten=flatten)\n",
    "#         val_p = process_conf(val_p, categorical=categorical, angles=angles, padding=padding, max_length=max_length,normalize=normalize, flatten=flatten)\n",
    "#         test_p = process_conf(test_p, categorical=categorical, angles=angles, padding=padding, max_length=max_length,normalize=normalize, flatten=flatten)\n",
    "#         print(\"train: \" + repr(train_p.shape))\n",
    "#         print(\"val: \" + repr(val_p.shape))\n",
    "#         print(\"test: \" + repr(test_p.shape))\n",
    "#         del train_all_p\n",
    "#         del proteins_conf\n",
    "\n",
    "#         p_name = os.path.basename(p).split('.')[0]\n",
    "#         train_filename = os.path.join(\"data_serialized_angles_protein\", f, \"train\", \"train_\"+ p_name +\".npy\")\n",
    "#         val_filename = os.path.join(\"data_serialized_angles_protein\", f, \"val\", \"val_\"+ p_name +\".npy\")\n",
    "#         test_filename = os.path.join(\"data_serialized_angles_protein\", f, \"test\", \"test_\"+ p_name +\".npy\")\n",
    "#         np.save(train_filename, train_p)\n",
    "#         np.save(val_filename, val_p)\n",
    "#         np.save(test_filename, test_p)\n",
    "\n",
    "#         del train_p\n",
    "#         del test_p\n",
    "#         del val_p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dizy",
   "language": "python",
   "name": "dizy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
