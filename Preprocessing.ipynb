{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import string\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from tempfile import TemporaryFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "families = [\"fam_1\", \"fam_2\", \"fam_3\", \"fam_4\", \"fam_5\", \"fam_6\", \"fam_7\", \"fam_8\", \"fam_9\"]\n",
    "ds_path = \"Dataset/families\"\n",
    "\n",
    "prepare_dirs = False\n",
    "\n",
    "family_paths = {}\n",
    "for f in families:\n",
    "    family_paths[f]= os.path.join(ds_path, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dirs\n",
    "if prepare_dirs:\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.mkdir(\"models\")\n",
    "    if not os.path.exists(\"models_proteins\"):\n",
    "        os.mkdir(\"models_proteins\")\n",
    "    if not os.path.exists(\"logs\"):\n",
    "        os.mkdir(\"logs\")\n",
    "    if not os.path.exists(\"data_serialized\"):\n",
    "        os.mkdir(\"data_serialized\")\n",
    "    if not os.path.exists(\"data_serialized_protein\"):\n",
    "        os.mkdir(\"data_serialized_protein\")\n",
    "    for f in families:\n",
    "        if not os.path.exists(os.path.join(\"models\", f)):\n",
    "            os.mkdir(os.path.join(\"models\", f))\n",
    "\n",
    "        if not os.path.exists(os.path.join(\"models_proteins\", f)):\n",
    "            os.mkdir(os.path.join(\"models_proteins\", f))\n",
    "\n",
    "        if not os.path.exists(os.path.join(\"logs\", f)):\n",
    "            os.mkdir(os.path.join(\"logs\", f))\n",
    "\n",
    "        if not os.path.exists(os.path.join(\"data_serialized\", f)):\n",
    "            os.mkdir(os.path.join(\"data_serialized\", f))\n",
    "\n",
    "        if not os.path.exists(os.path.join(\"data_serialized_protein\", f)):\n",
    "            os.mkdir(os.path.join(\"data_serialized_protein\", f))\n",
    "        if not os.path.exists(os.path.join(\"data_serialized_protein\", f, 'train')):\n",
    "            os.mkdir(os.path.join(\"data_serialized_protein\", f, 'train'))\n",
    "        if not os.path.exists(os.path.join(\"data_serialized_protein\", f, 'val')):\n",
    "            os.mkdir(os.path.join(\"data_serialized_protein\", f, 'val'))\n",
    "        if not os.path.exists(os.path.join(\"data_serialized_protein\", f, 'test')):\n",
    "            os.mkdir(os.path.join(\"data_serialized_protein\", f, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters_di=dict(zip(string.ascii_letters,[ord(c)%32 -1 for c in string.ascii_letters]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = {'A': [122.4, 119.4,-164.2],\n",
    "          'B': [129.8, 135.6, -176.6],\n",
    "          'C': [117.1, 111.0, -142.2],\n",
    "          'D': [118.4, 126.9, -146.1],\n",
    "          'E': [116.7, 138.6, 168.7],\n",
    "          'F': [115.6, 112.9, -117.9],\n",
    "          'G': [135.3, 118.6, -148.5],\n",
    "          'H': [120.1, 114.3, -90.7],\n",
    "          'I': [133.6, 117.1, -120.8],\n",
    "          'J': [115.9, 91.4, -134.6],\n",
    "          'K': [119.7, 90.4, -105.9],\n",
    "          'L': [110.0, 90.8, -158.8],\n",
    "          'M': [110.0, 100.8, 177.0],\n",
    "          'N': [90.1, 138.2, 19.6],\n",
    "          'O': [92.4, 91.2, -127.4],\n",
    "          'P': [91.8, 96.7, -104.8],\n",
    "          'Q': [95.9, 117.7, 136.0],\n",
    "          'R': [94.5, 112.6, 115.0],\n",
    "          'S': [96.3, 94.7, 112.0],\n",
    "          'T': [93.0, 92.8, 83.1],\n",
    "          'U': [91.4, 90.7, 49.8],\n",
    "          'V': [93.3, 89.1, 68.3],\n",
    "          'W': [93.8, 105.2, 32.3],\n",
    "          'X': [111.4, 94.6, 21.8],\n",
    "          'Y': [89.0, 95.1, -54.4]\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_angles(conf):\n",
    "    return [angles[str(l)] for l in conf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_conf(configurations, angles ,categorical, padding, max_length, normalize, flatten, num_classes=25):\n",
    "    if categorical:\n",
    "        # tranforms data to one hot encodings\n",
    "        configurations = [[letters_di[l] for l in p] for p in configurations]\n",
    "        configurations = [to_categorical(p, num_classes=num_classes) for p in configurations]  \n",
    "    elif angles:\n",
    "        # use angles\n",
    "        configurations = [to_angles(p) for p in configurations] \n",
    "    else:\n",
    "        configurations = [[letters_di[l] for l in p] for p in configurations]\n",
    "    configurations = np.array(configurations)\n",
    "    if padding:\n",
    "        # pad sequences if less than max length\n",
    "        if categorical:\n",
    "            new_families_conf = np.zeros((configurations.shape[0], max_length, num_classes))\n",
    "            for i,f in enumerate(configurations):\n",
    "                new_families_conf[i,:f.shape[0], :f.shape[1]] += f\n",
    "            configurations = new_families_conf\n",
    "        elif angles:\n",
    "            new_families_conf = np.zeros((configurations.shape[0], max_length, 3))\n",
    "            for i,f in enumerate(configurations):\n",
    "                new_f = np.array(f)\n",
    "                new_families_conf[i,:new_f.shape[0], :new_f.shape[1]] += new_f\n",
    "            configurations = new_families_conf\n",
    "        del new_families_conf\n",
    "    print(configurations.shape)\n",
    "    if flatten:\n",
    "        if categorical:\n",
    "            configurations = configurations.reshape(-1, num_classes * max_length)\n",
    "        elif angles:\n",
    "            configurations = configurations.reshape(-1, 3 * max_length)\n",
    "    if normalize:\n",
    "        if categorical:\n",
    "            configurations = configurations.astype('float32') / (letters_di['Y'] * 1.0)\n",
    "        elif angles:\n",
    "            configurations = configurations.astype('float32') + 180 / 360\n",
    "    print(configurations.shape)\n",
    "    return configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_family(f):\n",
    "    proteins = glob.glob(os.path.join(family_paths[f], \"*.out\"))\n",
    "    print(\"Proteins for family %s\" %f)\n",
    "    for p in proteins:\n",
    "        print(p)\n",
    "    proteins_conf = []\n",
    "    for p in proteins:\n",
    "        with open(p) as in_file:\n",
    "            for line in in_file:\n",
    "                proteins_conf.append(line.strip())\n",
    "    l = [len(p) for p in proteins_conf]\n",
    "    print(Counter(l))\n",
    "    return proteins_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data and serialize trian/ test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins for family fam_1\n",
      "Dataset/families/fam_1/2EBN.lf_str.out\n",
      "Dataset/families/fam_1/1JFX.lf_str.out\n",
      "Dataset/families/fam_1/1ITX.lf_str.out\n",
      "Dataset/families/fam_1/1NAR.lf_str.out\n",
      "Dataset/families/fam_1/1KFW.lf_str.out\n",
      "Dataset/families/fam_1/1B1Y.lf_str.out\n",
      "Dataset/families/fam_1/1VFF.lf_str.out\n",
      "Dataset/families/fam_1/1EDG.lf_str.out\n",
      "Dataset/families/fam_1/1CNV.lf_str.out\n",
      "Counter({282: 10000, 214: 10000, 416: 10000, 286: 10000, 432: 10000, 497: 10000, 420: 10000, 377: 10000, 280: 10000})\n",
      "(90000, 668, 3)\n",
      "(90000, 2004)\n",
      "train: (54000, 2004)\n",
      "val: (13500, 2004)\n",
      "test: (22500, 2004)\n",
      "Proteins for family fam_2\n",
      "Dataset/families/fam_2/1HLB.lf_str.out\n",
      "Dataset/families/fam_2/2LHB.lf_str.out\n",
      "Dataset/families/fam_2/1DLW.lf_str.out\n",
      "Dataset/families/fam_2/1ITH.lf_str.out\n",
      "Dataset/families/fam_2/1ECA.lf_str.out\n",
      "Dataset/families/fam_2/1ASH.lf_str.out\n",
      "Dataset/families/fam_2/1MBA.lf_str.out\n",
      "Dataset/families/fam_2/2HBG.lf_str.out\n",
      "Counter({144: 20000, 154: 10000, 146: 10000, 113: 10000, 279: 10000, 133: 10000, 143: 10000})\n",
      "(80000, 668, 3)\n",
      "(80000, 2004)\n",
      "train: (48000, 2004)\n",
      "val: (12000, 2004)\n",
      "test: (20000, 2004)\n",
      "Proteins for family fam_3\n",
      "Dataset/families/fam_3/2SAS.lf_str.out\n",
      "Dataset/families/fam_3/1OMR.lf_str.out\n",
      "Dataset/families/fam_3/1SRA.lf_str.out\n",
      "Dataset/families/fam_3/1CB1.lf_str.out\n",
      "Dataset/families/fam_3/1IQ3.lf_str.out\n",
      "Dataset/families/fam_3/1UHN.lf_str.out\n",
      "Counter({182: 10000, 198: 10000, 148: 10000, 75: 10000, 107: 10000, 186: 10000})\n",
      "(60000, 668, 3)\n",
      "(60000, 2004)\n",
      "train: (36000, 2004)\n",
      "val: (9000, 2004)\n",
      "test: (15000, 2004)\n",
      "Proteins for family fam_4\n",
      "Dataset/families/fam_4/1AH9.lf_str.out\n",
      "Dataset/families/fam_4/1KRS.lf_str.out\n",
      "Dataset/families/fam_4/1YVC.lf_str.out\n",
      "Dataset/families/fam_4/1EOV.lf_str.out\n",
      "Dataset/families/fam_4/1JT8.lf_str.out\n",
      "Dataset/families/fam_4/1SLJ.lf_str.out\n",
      "Counter({68: 10000, 107: 10000, 67: 10000, 484: 10000, 99: 10000, 93: 10000})\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4bf1b2e563e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfamilies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfamilies_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_family\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mfamilies_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_conf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfamilies_conf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mangles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mangles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfamilies_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.15\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfamilies_conf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-df2431175c56>\u001b[0m in \u001b[0;36mprocess_conf\u001b[0;34m(configurations, angles, categorical, padding, max_length, normalize, flatten)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mnew_families_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigurations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigurations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mnew_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mnew_families_conf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnew_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mnew_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnew_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mconfigurations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_families_conf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for f in families:\n",
    "#     families_conf = load_family(f)\n",
    "#     families_conf = process_conf(families_conf, categorical=categorical, angles=angles, padding=padding, max_length=max_length,normalize=normalize, flatten=flatten)  \n",
    "#     test_size = int(0.25 * families_conf.shape[0])\n",
    "#     val_size = int(0.15 * families_conf.shape[0])\n",
    "#     train_all, test = train_test_split(families_conf, test_size=test_size, random_state=42)\n",
    "#     train, val = train_test_split(train_all, test_size = val_size, random_state=42)\n",
    "#     del families_conf\n",
    "#     del train_all\n",
    "#     print(\"train: \" + repr(train.shape))\n",
    "#     print(\"val: \" + repr(val.shape))\n",
    "#     print(\"test: \" + repr(test.shape))\n",
    "#     train_filename = os.path.join(\"data_serialized_angles\", f, \"train.npy\")\n",
    "#     val_filename = os.path.join(\"data_serialized_angles\", f, \"val.npy\")\n",
    "#     test_filename = os.path.join(\"data_serialized_angles\", f, \"test.npy\")\n",
    "#     np.save(train_filename, train)\n",
    "#     np.save(val_filename, val)\n",
    "#     np.save(test_filename, test)\n",
    "#     del train\n",
    "#     del test\n",
    "#     del val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proteins for family fam_1\n",
      "Dataset/families/fam_1/2EBN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_1/1JFX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_1/1ITX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_1/1NAR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_1/1KFW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_1/1B1Y.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_1/1VFF.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_1/1EDG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_1/1CNV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Proteins for family fam_2\n",
      "Dataset/families/fam_2/1HLB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_2/2LHB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_2/1DLW.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_2/1ITH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_2/1ECA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_2/1ASH.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_2/1MBA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_2/2HBG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Proteins for family fam_3\n",
      "Dataset/families/fam_3/2SAS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_3/1OMR.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_3/1SRA.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_3/1CB1.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_3/1IQ3.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_3/1UHN.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Proteins for family fam_4\n",
      "Dataset/families/fam_4/1AH9.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_4/1KRS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_4/1YVC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_4/1EOV.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_4/1JT8.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_4/1SLJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Proteins for family fam_5\n",
      "Dataset/families/fam_5/1GUI.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_5/1I5P.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_5/1K45.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_5/1NKG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_5/1ULO.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Proteins for family fam_6\n",
      "Dataset/families/fam_6/1BCG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_6/1JXC.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_6/1GPT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_6/1I2U.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_6/1SEG.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Proteins for family fam_7\n",
      "Dataset/families/fam_7/1JBJ.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_7/1NCT.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_7/1R6V.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_7/1JE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_7/2FCB.lf_str.out\n",
      "10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_7/1OLL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Proteins for family fam_8\n",
      "Dataset/families/fam_8/1AF7.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_8/1Y8C.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_8/1DUS.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_8/1F3L.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_8/1YUB.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Proteins for family fam_9\n",
      "Dataset/families/fam_9/1EE6.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_9/1VBL.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_9/1BHE.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_9/1RU4.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n",
      "Dataset/families/fam_9/1QCX.lf_str.out\n",
      "10000\n",
      "(6000, 668, 3)\n",
      "(6000, 2004)\n",
      "(1500, 668, 3)\n",
      "(1500, 2004)\n",
      "(2500, 668, 3)\n",
      "(2500, 2004)\n",
      "train: (6000, 2004)\n",
      "val: (1500, 2004)\n",
      "test: (2500, 2004)\n"
     ]
    }
   ],
   "source": [
    "# for f in families:\n",
    "#     proteins = glob.glob(os.path.join(family_paths[f], \"*.out\"))\n",
    "#     print(\"Proteins for family %s\" %f)\n",
    "    \n",
    "#     for p in proteins:\n",
    "#         print(p)\n",
    "#         proteins_conf = []\n",
    "#         with open(p) as in_file:\n",
    "#             for line in in_file:\n",
    "#                 proteins_conf.append(line.strip())\n",
    "#         print(len(proteins_conf))\n",
    "#         test_size = int(0.25 * len(proteins_conf))\n",
    "#         val_size = int(0.15 * len(proteins_conf))\n",
    "#         train_all_p, test_p = train_test_split(proteins_conf, test_size=test_size, random_state=42)\n",
    "#         train_p, val_p = train_test_split(train_all_p, test_size = val_size, random_state=42)\n",
    "        \n",
    "#         #preprocess\n",
    "#         train_p = process_conf(train_p, categorical=categorical, angles=angles, padding=padding, max_length=max_length,normalize=normalize, flatten=flatten)\n",
    "#         val_p = process_conf(val_p, categorical=categorical, angles=angles, padding=padding, max_length=max_length,normalize=normalize, flatten=flatten)\n",
    "#         test_p = process_conf(test_p, categorical=categorical, angles=angles, padding=padding, max_length=max_length,normalize=normalize, flatten=flatten)\n",
    "#         print(\"train: \" + repr(train_p.shape))\n",
    "#         print(\"val: \" + repr(val_p.shape))\n",
    "#         print(\"test: \" + repr(test_p.shape))\n",
    "#         del train_all_p\n",
    "#         del proteins_conf\n",
    "\n",
    "#         p_name = os.path.basename(p).split('.')[0]\n",
    "#         train_filename = os.path.join(\"data_serialized_angles_protein\", f, \"train\", \"train_\"+ p_name +\".npy\")\n",
    "#         val_filename = os.path.join(\"data_serialized_angles_protein\", f, \"val\", \"val_\"+ p_name +\".npy\")\n",
    "#         test_filename = os.path.join(\"data_serialized_angles_protein\", f, \"test\", \"test_\"+ p_name +\".npy\")\n",
    "#         np.save(train_filename, train_p)\n",
    "#         np.save(val_filename, val_p)\n",
    "#         np.save(test_filename, test_p)\n",
    "\n",
    "#         del train_p\n",
    "#         del test_p\n",
    "#         del val_p"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dizy",
   "language": "python",
   "name": "dizy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
